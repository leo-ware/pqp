{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract\n",
    "Causal inference under Pearl’s framework of structural causal models has been the subject of intense theoretical study, but performant open-source implementations of many of the key algorithms are still lacking or, where they exist, are not widely adopted or maintained. I present a performant implementation of Shpitser’s IDC algorithm for identification of conditional causal effects in semi-Markovian causal models."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Executive Summary\n",
    "\n",
    "Causal inference is a fundamental task in many fields, including epidemiology, economics, and data science. One popular framework for causal inference is Pearl's structural causal modeling framework, which utilizes directed acyclic graphs (DAGs) and the do-calculus to explicitly model potential causal relationships. This approach allows for a clear and intuitive representation of causal assumptions, while also helping to avoid common biases that can arise with other methodologies. However, a crucial step in this framework is identification: translating a causal question into an abstract statistical estimator that can be estimated using a combination of a model and parametric assumptions.\n",
    "\n",
    "One important algorithm for identification in the structural causal modeling framework is Shpitser's algorithm for conditional interventional effects. This algorithm is polynomial time and guarantees a result when one is possible. However, existing open-source implementations of this algorithm are often incorrect, slow, or unmaintained. In this paper, I present a novel implementation of Shpitser's algorithm, written in Rust for efficient cross-functional use. Our implementation is production-quality code and includes extensive testing routines to ensure performance and correctness.\n",
    "\n",
    "To bridge the gap between theoretical algorithm and practical tool, I developed two techniques as subroutines to the algorithm. I developed an implemented a heuristic symbolic simplification algorithm. To protect the speed and memory efficiency of the program, I developed a memory-sharing graph datastructure which allows similar graphs to share memory via a system of references and immutable data.\n",
    "\n",
    "To aid in adoption of this algorithm, I designed and implemented a user-friendly Python wrapper. This wrapper allows for the specification and visualization of causal graphs using a concise and elegant API, as well as giving the user full access to the underlying algorithms. This is available as a Python package on PyPi, and documentation is available via a Sphinx-generated website."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "The paper is organized as follows: in the first section, I provide an overview of the background and motivation behind the algorithm. I review the literature on available implementations of the algorithm and justify the need for this implementation.\n",
    "\n",
    "In the second section, I describe my implementation. I detail techniques I developed for simplication and memory-sharing, and I describe the extensive testing procedures I used to ensure correctness. I describe the Python wrapper I developed to make the algorithm accessible to a wider audience. I outline plans to complete this project before the final deadline.\n",
    "\n",
    "In the third section, I provide examples to demonstrate the utility of our implementation. Appendices include code and HC/LO footnotes."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contributions\n",
    "\n",
    "In this work, we present a novel implementation of Shpitser's ID algorithm, including a comprehensive set of graph routines and a heuristic-based simplification algorithm. The implementation is written in Rust and the code is provided in the appendix. Additionally, we have developed Python bindings to facilitate usage of the algorithm. It is important to note that while this implementation and techniques for simplification and memory-sharing are novel, the underlying algorithm and all the material covered in the Background section is not a contribution of this paper and is instead a summary of the current state of the field."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Links\n",
    "\n",
    "- Documentation: [https://leo-ware.github.io/pqp/index.html](https://leo-ware.github.io/pqp/index.html)\n",
    "- Source code: [https://github.com/leo-ware/pqp](https://github.com/leo-ware/pqp)\n",
    "- PyPI Distribution: [https://pypi.org/project/pqp/](https://pypi.org/project/pqp/)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note on this text\n",
    "\n",
    "AI text generation algorithms were used in the production of this text. Specifically, the OpenAI model ChatPGT was used extensively to edit for tone and concision."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structural Causal Models\n",
    "\n",
    "### Overview\n",
    "\n",
    "Structural Causal Models (SCM) provide a framework for modeling the generating process of a distribution. A structural causal model has four components: a set of observed variables $\\textbf{V} = {v_1, v_2, ..., v_n}$, a set of unobserved variables $\\textbf{U} = {u_1, u_2, ..., u_m}$, a distribution $P(U)$ over unobserved variables, and a set of functions $\\textbf{F} = {f_1, f_2...f_n}$ such that each $f_i$ is a function from a subset of $\\textbf{U} \\cup \\textbf{V} \\backslash V_i$ to $v_i$. The arguments to $f_i$ are called the parents of $v_i$ or $pa(v_i)$ and they uniquely determine the value of $v_i$. Together, $P(\\textbf{U})$ and $\\textbf{F}$ induce $P(\\textbf{V})$, a distribution over $\\textbf{V}$.\n",
    "\n",
    "We represent the causal assumptions in an SCM via a causal diagram. This is a directed acyclic graph (DAG) where each node corresponds to a variable in the model. A directed edge from $x_i$ to $x_j$ indicates that the value of $x_j$ depends on the value of $x_i$, or $x_i \\in pa(x_j)$. To ensure the validity of an SCM, we restrict the set of valid models to those that can be represented by acyclic graphs, to prevent circular definitions between variables [1]. Algebraically, we can interpret a causal diagram as defining a set of conditional independence assumptions. In particular, as the parents of $v_i$ completely determine its value, $v_i$ will be independent of every other variable in the model, conditional on its parents.\n",
    "\n",
    "Note the acyclicity assumption does not restrict the class of distributions that can be represented by an SCM because by the definition of joint probability any joint distribution $P(x_1, x2…x_n)$ can be factorized as $P(x_1 | x_2…x_n)P(x_2 | x_3…x_n)...P(x_n-1 | x_n) P(x_n)$. But, this can be represented as an SCM where $pa(x_i) = \\{x_{i+1}, x_{i+2}…x_n\\}$ without violating the acyclicity assumption. However, the any given causal graph may be consistent with only a subset of all possible distributions over the variables in the graph.\n",
    "\n",
    "For the purposes of this paper, we make the additional assumption that each unobserved variable is the parent of at most two observed variables. This simplifies the graphical representation by replacing each unobserved variable and its outgoing edges with a single undirected edge connecting its two children. This can be interpreted as representing potential confounding between the two variables. An example of such a simplified graph is shown in Figure 1."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Figure 1. Using Bidirected Edges to Represent Confounding**\n",
    "![](2023-01-14-13-06-10.png)\n",
    "*This figure shows an unobserved variable $C$ with two children being replaced with a bidirected, dashed edge. The bidirected edge represents the same information as $C$ did in the first diagram, but it is only possible to represent confounders with bidirected edges if they have exactly two children.*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conditional Independence Properties of Causal Diagrams\n",
    "\n",
    "One of the key properties of causal diagrams is that they can provide insight into the conditional independence properties of a distribution $P(\\textbf{U} \\cup \\textbf{V})$. As previously discussed, a variable $v_i$ is independent of all other variables in the model, conditional on its parents. This concept of a \"flow of dependence\" along edges connecting a node to its parent is a useful tool for understanding the conditional independence assumptions encoded in a causal diagram.\n",
    "\n",
    "However, it is important to note that dependence does not flow along every path in the diagram. Paths can be blocked by conditioning on certain variables, which alters the conditional independence properties of the distribution. We can view a path as a collection of vertices, each of which must have one of the following forms:\n",
    "\n",
    "$$X \\leftarrow Y \\leftarrow Z$$\n",
    "$$X \\rightarrow Y \\rightarrow Z$$\n",
    "$$X \\leftarrow Y \\rightarrow Z$$\n",
    "$$X \\rightarrow Y \\leftarrow Z$$\n",
    "\n",
    "In the first three cases, dependence will flow through the vertex as long as we do not condition on $Y$. In this case, we call the vertex unblocked. Conditioning on $Y$ blocks the path and prevents dependence from traveling along it. This means that, as long as this is the only path connecting $X$ and $Y$, the causal diagram is predicting that $X$ and $Z$ will be independent conditional on $Y$.\n",
    "\n",
    "The third case, known as a collider, is slightly different. The last vertex will be unblocked if and only if we condition on $Y$.\n",
    "\n",
    "To illustrate the concept of colliders, consider the example of college admissions. Without knowledge of whether a student was admitted, learning her SAT scores tells us nothing about her admissions essays. However, if we know that the student was admitted, and we observe that her SAT scores were low, we can infer that her essays must have been good.\n",
    "\n",
    "A path is considered blocked if any vertex along it is blocked. If, after conditioning on a set of variables $\\textbf{Z}$, there are no unblocked paths connecting two variables $v_i$ and $v_j$, then the model predicts that $v_i$ and $v_j$ are independent conditional on $\\textbf{Z}$. In this case, we say that $v_i$ and $v_j$ are d-separated by $\\textbf{Z}$. This concept of d-separation provides a means to connect the ideas of statistical association in the joint distribution with properties of the graph, and allows us to use graphical models of causal relationships to make testable predictions about datasets."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Figure 2. Examples of D-Separation**\n",
    "\n",
    "![](2023-01-14-13-52-24.png)\n",
    "\n",
    "*The figure shows an example of a causal graphical model. Nodes represent random variables, and edges represent direct causal influence.*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, in figure 2 we can make the following predictions about distribution $P(\\textbf{V})$ based on the causal diagram:\n",
    "\n",
    "- $A \\perp\\!\\!\\!\\!\\perp C$ but not $A \\perp\\!\\!\\!\\!\\perp C | D$\n",
    "- $A \\perp\\!\\!\\!\\!\\perp B | C$ but not $A \\perp\\!\\!\\!\\!\\perp B | C, D$\n",
    "- $B \\perp\\!\\!\\!\\!\\perp D | C$ but not $B \\perp\\!\\!\\!\\!\\perp D$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph Surgery and Causal Effects\n",
    "\n",
    "In causal inference, a fundamental task is to measure the causal effect of one set of variables, $X$, on another, $Y$. To operationalize this task within the Structural Causal Model (SCM) framework, we utilize the concept of interventions. Specifically, in the SCM, the values of $X$ are determined by its parents, $pa(X)$. However, we are interested in understanding the effect of altering the value of $X$ through intervention, rather than allowing it to be set by its natural causes. To model this intervention process, we perform \"graph surgery\" by cutting all incoming edges into $X$, and examining the resulting interventional distribution. This allows us to isolate any remaining conditional effect of $X$ on $Y$, which can then be interpreted as a causal effect.\n",
    "\n",
    "To gain further insight into this process, we can consider two types of paths that may connect $X$ and $Y$: backdoor paths and frontdoor paths. Backdoor paths are those that connect to $X$ through its parents, while frontdoor paths connect through its children. These paths represent different mechanisms through which $X$ may affect $Y$; frontdoor paths indicate direct causal effects, while backdoor paths indicate indirect effects through other variables (i.e. confounding). By performing graph surgery and cutting all backdoor paths, we effectively isolate any causal effects flowing through frontdoor paths.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Do-Calculus\n",
    "\n",
    "In the Structural Causal Model (SCM) framework, causal queries are represented by the use of the \"do-operator.\" The do-operator is indicated by its placement behind the conditioning bar in a probability expression, and it represents a modification of the underlying generating process. To illustrate, for sets of variables $X$, $Y$, and $Z$, the expression $P(Y | do(X), Z)$ represents the conditional probability $P(Y | X, Z)$ in the model that results from performing graph surgery on $X$. This represents a hypothetical scenario in which $X$ is fixed through intervention, rather than being determined by \"nature.\" A \"do-expression\" is any probability expression containing the do-operator.\n",
    "\n",
    "Both the average treatment effect (ATE) and the conditional average treatment effect (CATE) can be expressed in terms of do-expressions. The ATE is given by:\n",
    "\n",
    "$ATE = E(P(y | do(x = 1))) - E(P(y | do(x = 0)))$\n",
    "\n",
    "while the CATE is given by:\n",
    "\n",
    "$CATE = E(P(y | z, do(x = 1))) - E(P(y | z, do(x = 0)))$\n",
    "\n",
    "The manipulation of do-expressions is facilitated by Pearl's \"do-calculus\", which references properties of the model in which the do-expression is evaluated. The do-calculus provides conditions under which do-operators can be removed from an expression or replaced with conditioning. This is advantageous because it allows us to transform do-expressions, which cannot be estimated from the data, into traditional statistical estimands (e.g., $P(Y | X, Z)$), which can be estimated using parametric assumptions.\n",
    "\n",
    "$\n",
    "\\textbf{Rule 1 } \\text{Insertion/deletion of observations:}\\\\\n",
    "P(Y | do(X), Z, W) = P(Y | do(X), W) \\\\\n",
    "\\text{if } (Y \\perp\\!\\!\\!\\!\\perp Z | X, W)_{G_{\\overline{X}}}\n",
    "$\n",
    "\n",
    "$\n",
    "\\textbf{Rule 2 } \\text{Action/observation interchange:}\\\\\n",
    "P(Y | do(X), do(Z), W) = P(Y | do(X), Z, W) \\\\\n",
    "\\text{if } (Y \\perp\\!\\!\\!\\!\\perp Z | X, W)_{G_{\\overline{X} \\underline{Z}}}\n",
    "$\n",
    "\n",
    "$\n",
    "\\textbf{Rule 3 } \\text{Insertion/deletion of actions:}\\\\\n",
    "P(Y | do(X), do(Z), W) = P(Y | do(X), W) \\\\\n",
    "\\text{if } (Y \\perp\\!\\!\\!\\!\\perp Z | X, W)_{G_{\\overline{X} \\overline{Z(W)}}}\n",
    "$\n",
    "\n",
    "The task of removing the do-operators from a do-expression and turning it into a statistical estimand is called \"identification.\" It is a crucial step in the process of causal inference in the SCM framework. General procedures for identification allow us to express causal queries in the rich language of do-expressions and then algorithmically translate these queries into statistical estimands that can be directly estimated from the data. Additionally, because identification does not make any parametric assumptions about the data, it allows us to decouple our causal assumptions from our parametric assumptions during modeling."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Four Stages of Causal Inference\n",
    "\n",
    "Structured causal effect estimation is a four-step process consisting of modeling, identification, estimation, and robustness checks.\n",
    "\n",
    "1. Modeling: This step involves identifying plausible causal relationships in the form of a directed acyclic graph (DAG). The DAG serves as a representation of the causal structure of the system being studied.\n",
    "\n",
    "2. Identification: Once the causal structure is represented in the form of a DAG, the next step is to translate a causal query into an abstract estimator in the context of these assumptions. This process is known as identification, and it is a crucial step in the process of causal inference.\n",
    "\n",
    "3. Estimation: After the abstract estimator has been derived, the next step is to add parametric assumptions and pick a specific model to represent the abstract estimator. This model is then fitted to the data, and an estimate of the causal effect is extracted.\n",
    "\n",
    "4. Robustness checks: The final step is to assess the robustness of the analysis to the specifics of the assumptions made in the modeling process. This is done by perturbing the assumptions of the modeling process and determining the sensitivity of the analysis to these perturbations. These robustness checks are important for ensuring the validity and generalizability of the causal estimates.\n",
    "\n",
    "It's important to note that the modeling, identification, estimation and robustness checks are interrelated, and that making progress in one step may require revisiting the others."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Problem of Identification\n",
    "\n",
    "### Overview\n",
    "\n",
    "It is important to note that not every causal estimand can be unambiguously estimated in every model. Identification, or the process of determining the causal estimand from the joint distribution, may fail when it is impossible to unambiguously determine $P(Y | do(X))$ from $P$. Identification is always possible in a graph with no confounding, but in some cases it is not possible because it is not possible to disentangle the effect from possible confounding. For example, in a model with a bidirected edge between variables, it may be impossible to identify $P(Y | do(X))$ because any observed effect could be explained by confounding along the bidirected edge, and there is no way to control for this."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Figure 4. The Bow Graph**\n",
    "\n",
    "![](2023-01-14-14-22-06.png)\n",
    "\n",
    "*The bow graph is the simplest example of a graph with a non-identifiable interventional distribution.*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rules of the do-calculus provide complete conditions for identification of causal estimands; if it is possible to convert the causal estimand to a statistical estimand, then it is possible using the do-calculus. However, manually applying the rules of the do-calculus to derive an abstract estimator is time-consuming and requires the researcher to make reference to complex properties of the causal graph, which is a task humans are ill-suited to, especially as the complexity of the graph grows. In the general case, it is too complex a task to be performed by hand.\n",
    "\n",
    "Thus, it is necessary to find algorithms by which identification can be performed automatically. This is a nontrivial problem; naive approaches often have exponential time complexity in the size of the graph, and the best algorithms, while polynomial time, rest on complex graph theory.\n",
    "\n",
    "Some researchers have simplified this problem by sidestepping direct application of the do-calculus and instead using the concept of adjustment sets. These methods rely on finding a set of variables which, when controlled for, block all backdoor-paths from the intervention set to the outcome set. However, these approaches face two distinct challenges. First, naive approaches to adjustment set search, such as those implemented in Knupple (2010), Breitling (2010), and Sharma (2020) rely on enumerating the set of all possible adjustment sets and then checking whether each successfully blocks all backdoor paths. This is an issue because the number of possible adjustment sets grows exponentially in the number of nodes in the graph. This makes these approaches infeasible for even fairly small graphs.\n",
    "\n",
    "More efficient algorithms exist for adjustment set search, such as the one proposed in Textor and Liskiewicz (2011), which works in polynomial time. However, the drawback of these algorithms is that although every valid adjustment set corresponds to a valid statistical estimator for the query, not every valid statistical estimator can be represented as an adjustment set. Because these algorithms are only searching among adjustment sets, they fail in cases where other classes of estimator are needed.\n",
    "\n",
    "To illustrate, in the famous front-door model, the interventional distribution $P(Y | do(X))$ is identified by the simple statistical estimator $P(Y | do(X)) = \\sum_z P(Z | X) \\sum_x P(Y | Z, X) P(X)$. This estimator works by breaking the problem into two subproblems: first identifying the interventional distributions $P(M | do(X))$ and $P(Y | do(M))$ and then combining these to identify $P(Y | do(X))$. Each subproblem can be solved using an adjustment set operator, but there is no adjustment set estimator which identifies $P(Y | do(X))$."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C-components\n",
    "\n",
    "Front-door estimation is an interesting technique, but it also illustrates a larger concept in causal inference known as c-component factorization. C-components, or connected components, are subsets of the graph that are connected via bidirectional (confounding) edges. Two nodes, $A$ and $B$, in a causal graph are in the same c-component if and only if there is a path from $A$ to $B$ that only follows bidirectional edges. It has been shown that any causal graph can be uniquely partitioned into a minimal set of c-components (Tian, 2002).\n",
    "\n",
    "More importantly, Tian (2002) showed that for any c-component $C$ in a graph $G$, the interventional distribution $P(C | do(V \\backslash C))$ is identifiable, where $V$ denotes the set of nodes in $G$ and $\\backslash$ represents set difference. This means that the problem of identifying $P(Y | do(X))$ can be broken down into a set of subproblems, one for each c-component in the graph $G \\backslash X$. This is the first critical insight that enables efficient identification and is known as c-component factorization.\n",
    "\n",
    "C-components also allow for the introduction of more complex graphical structures, such as the c-tree. A $Y$-rooted c-tree is a graph $G$ that contains both directed and bidirected edges, where the entire graph is a single c-component and every node has at most one child. Additionally, there is a single node $Y$ that has no children. If there are multiple nodes with no children, these nodes are referred to as the root-set of $G$, and the graph is called a c-forest."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Figure 4. A C-Tree and  C-Forest**\n",
    "\n",
    "![](2023-01-14-15-01-52.png)\n",
    "\n",
    "*This figure shows a c-tree (left) and a c-forest (right). Note that both are c-components because they are completely connected by bidirectional edges. In addition, in both, no node has more than one child. However, in the c-tree, C is the only node without children. This makes this a $C$-rooted c-tree. On the other hand, the graph on the right has two nodes without children: $C$ and $G$. This makes it a $\\{C, G\\}$-rooted c-forest.*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By utilizing c-forests, the concept of a hedge can be defined. Hedges are graphical structures that prevent the identification of interventional distributions. In a causal graphical model with graph $G$, if an interventional distribution $P(Y | do(X))$ is sought for two sets of random variables $X$ and $Y$, and if there exist two subgraphs $F$ and $F'$ such that the intersection of $F$ and $X$ is non-empty, but the intersection of $F'$ and $X$ is empty, and if $F'$ is a subgraph of $F$, and both form $Z$-rooted c-forests, where $Z$ is a subset of $Y$, the interventional distribution $P(Y | do(X))$ will be identifiable if and only if such $F$, $F'$, and $Z$ do not exist.\n",
    "\n",
    "In other words, if two nested c-forests are found, where at least some elements from $Y$ are in their root set, and the smaller one does not contain any elements from $X$ but the bigger one does, the interventional distribution is not identifiable."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shpitser's Algorithm\n",
    "\n",
    "Shpitser’s ID algorithm exploits the properties of c-components to identify interventional distributions. It is polynomial time and can always derive an estimator if one exists. The algorithm works as follows (Shpitser, 2008):\n",
    "\n",
    "$\n",
    "\\text{function }\\textbf{ID}(y, x, P, G)\\\\\n",
    "\\text{INPUT: x, y value assignments, P a probability distribution, G a causal diagram}\\\\\n",
    "\\text{OUTPUT: Expression for } P_x(y) \\text{in terms of } P \\text{ or } \\textbf{FAIL}\n",
    "$\n",
    "\n",
    "$\n",
    "\\text{1. if } x = \\emptyset \\text{ return } \\sum_{v \\setminus y} P(v)\\\\ \\\\\n",
    "$\n",
    "\n",
    "$\n",
    "\\text{2. if } V \\setminus An(Y)_G \\ne \\emptyset \\\\ \\text{ return } \\textbf{ID}(y, x \\cap An(Y)_G, \\sum_{v \\setminus An(Y)_G} P, G_{An(Y)})\n",
    "$\n",
    "\n",
    "$\n",
    "\\text{3. let } W = (V \\setminus X) \\setminus An(Y)_{G_{\\overline{x}}} \\\\\n",
    "\\text{if } W \\ne \\emptyset \\text{, return } \\textbf{ID}(y, x\\cup w, P, G)\n",
    "$\n",
    "\n",
    "$\n",
    "\\text{4. if } C(G \\setminus X) = {S_1...S_k}\\\\\n",
    "\\text{return } \\sum_{v \\setminus (y \\cup x)} \\prod_{i} \\textbf{ID}(s_i, v \\setminus s_i, P, G)\n",
    "$\n",
    "\n",
    "If line 4 does not return, then $C(G \\setminus X) = {S}$\n",
    "\n",
    "$\n",
    "\\text{5. if } C(G) = {G} \\text{, throw } \\textbf{FAIL}\n",
    "$\n",
    "\n",
    "$\n",
    "\\text{6. } S \\isin C(G) \\text{ return } \\sum_{s \\setminus y}\\prod_{ \\{i | V_i \\subset S \\} } P(v_i | v_\\pi^{(i - 1)})\n",
    "$\n",
    "\n",
    "$\n",
    "\\text{7. if } (\\exists S') S \\subset S' \\in C(G) \\\\\n",
    "\\text{ return } \\textbf{ID}(y, x \\cap S', \\prod_{ \\{i | V_i \\subset S' \\} }P(V_i | V_\\pi^{(i - 1)} \\cap S', v_\\pi^{(i - 1)} \\setminus S'), G_{S'})\n",
    "$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ID works by breaking up the identification problem into subproblems. Considering the subgraph $G’ = G \\setminus X$, we find the c-components $\\{s_i\\}$ of $G’$. If there is more than one, then we can identify $P(Y | do(X))$ by finding the interventional distribution $P(s_i | do(G \\ s_i))$ for each $s_i$. Because of c-component factorization, we know that all such terms will be identifiable if and only if $P(Y | do(X))$ is identifiable. We can then take the product of all such terms to get a joint interventional distribution over the nodes in $G’$. By marginalizing all variables other than those in $X$ and $Y$, we can identify the interventional distribution.\n",
    " \n",
    "After repeated application of the above step, we will be in a position where $G’$ consists of a single c-component. There are three possible ways in which $X$ could relate to $G’$. (1) $X$ and $G’$ could together form a single c-component. In this case, we have discovered a hedge, proving the interventional distribution is not identifiable. (2) There could be no bidirectional edges connecting elements of $G’$ to elements of $X$. In this case, there are no backdoor paths from $X$ to $G’$ and we can identify the interventional distribution by conditioning on $X$. (3) It could be that some elements $Z \\subset X$ are connected via bidirectional edges to elements in $G’$, while others $W \\subset X$ are not. In this case, we can condition on $W$ and make a recursive call to the algorithm, attempting to identify the interventional distribution $P(G’ | do(Z))$.\n",
    " \n",
    "The algorithm as described so far can only deal with queries of the form $P(Y | do(X))$, but often we will wish to calculate conditional interventional effects of the form $P(Y | do(X), Z)$. Thankfully, queries of this form can be mapped to queries without a conditional term with only a minimal transformation. This modification of the algorithm is known as IDC, or ID with conditioning, and it eliminates conditional variables in two ways. The first way is using Rule 22 of the do-calculus: if a conditional variable $z \\in Z$ has no back door paths to $Y$ when conditioning on $X$ and $Z \\ z$, then conditioning on z is equivalent to intervening on it, and it can be put inside the do operator. The second way is to treat $z$ as an outcome, run the algorithm, and then condition on $z$. Together, these two techniques can be used to eliminate all conditional variables from the query."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-existing Implementations\n",
    "\n",
    "A number of open source implementations of the ID algorithm existed prior to my work. Dowhy is a popular python library developed by Microsoft Research, but its implementation is too slow. Researchers working on the dowhy project explicitly asked me to create a faster implementation and integrate it with their library. There is also an implementation in Clojure called Whittemore which is quite fast, but because Clojure is a JVM language it is not possible to integrate this implementation with Python, R, or Javascript code. I based my implementation on Whittemore. Ananke is a causal inference library developed by Shpitser’s team, and it has an implementation of a related algorithm, but Ananke has not seen widespread adoption, and it is unmaintained. FInally, the Javascript/R tool Daggity has an implementation of adjustment set operators, which suffer from the drawbacks discussed above."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation\n",
    "\n",
    "## Technical Challenges\n",
    "\n",
    "### Graph Representation and Subroutines\n",
    "As a prerequisite to the rest of the work I did for this project, I implemented a set of graph routines to capture key operations that need to be performed during the algorithm. There are two kinds of graphs that I implemented: directed and bidirected graphs. The most important operations for the directed graph are to find ancestors of a given element or determine $\\text{d-separation}$. The most important operation for the bidirected graph is to find connected components.\n",
    "\n",
    "The tricky thing about these routines is that, as the algorithm runs, they are repeatedly called on slightly modified versions of the original graph. So, for example, a common question we might ask while executing the algorithm is: if we removed node $X$, would nodes $Y$ and $W$ still be in the same connected component? Or, if we intervened on $G$, would $A$ still be an ancestor of $B$? The most naive implementations of subroutines like these would be to copy the data from the original graph, modify the copy to reflect the operation, and then run the subroutine.\n",
    "\n",
    "In the context of ID specifically, the algorithm starts in possesion of the entire graph and then successively partitions it into smaller subgraphs as it reduces the problem to subproblems. So, I deve\n",
    "\n",
    "Instead, I implemented a set of routines that allows small modifications to be performed to the original graphs in such a way that a new data structure is created which is logically distinct inside the program but which uses most of the same memory. This reduces the memory footprint of the algorithm as well as reducing time spent copying data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simplification\n",
    "Simplification is an important step in computational identification because the ID algorithm tends to return symbolic expressions that are quite complex and require simplification. The complexity of these outputs is not indicative of the complexity of the \"answer\", but they tend to contain many elements which are algebraically redundant. E.g., frequently identical terms will appear in the numerator and denominator of a quotient. A few lines of mathematical manipulation can reduce the complexity of these expressions significantly, but it is a nontrivial problem to write a program that can do this.\n",
    "\n",
    "It is important to simplify the results for a couple of reasons. Simpler expressions are easier for humans to understand. They make it easier to test the program because they reduce the number of “correct” answers to an identification problem. And, maybe most importantly, simpler expressions are easier to evaluate numerically. It is both computationally cheaper and more accurate to simplify an expression before applying numerical estimation techniques.\n",
    "\n",
    "Whittemore, which I have borrowed from extensively, uses a heuristic-based simplification algorithm with just a couple of rules. My original plan was to just use this, but their algorithm contains idiosyncracies that I think may indicate a mathematical error. I plan to present an example failure case in the next iteration of this report.\n",
    "\n",
    "Tikka and Karvanen (2017) describe a simplification routine that uses properties of the graphical model to find ways to reduce conditional terms. I was originally optimistic about this approach as it has nice guarantees on the degree of simplification. However, this approach has a time complexity that gorws significantly faster than exponential in the number of variables, and so would not prove practical for real problems.\n",
    "\n",
    "Instead of relying on these solutions, I developed my own heuritsitc simplification algorithm. This algorithm relis on an observation that most of the redundancy in the estimands generated by the algorithm can be remedied by fairly simple algebra. I implemented a simple recursive algorithm that applies a series of transformations on elements in the symbolic expression. It traverses the expression tree, replacing each node with a simplified version.\n",
    "\n",
    "For each possible type of subexpression, the following transformations are applied:\n",
    "\n",
    "expression type | transformations | example | example (simplified)\n",
    "---|---|---|---\n",
    "Quotient | Merge nested quotients and products. Cancel identical terms. | ${P(a)(P(b)P(c)) \\over {P(b) \\over P(d))}}$ | $P(a)P(c)P(d)$\n",
    "Product | Merge nested products and quotients. | ${P(a) \\over P(b)} P(c)$ | $P(a)P(c) \\over P(b)$\n",
    "Marginal | Convert sum over joint distribution to marginal distribution. | $\\sum_{a} P(a,b)$ | $P(b)$\n",
    "Conditional Probability | Convert to quotient. | $P(a \\| b)$ | ${P(a, b) \\over P(b)}$\n",
    "\n",
    "This scheme has the disadvantage that no conditional probability expressions are left in the final result, which can make the formulas less readable. But, this is worth it because in quotient form it is much easier to identify redundant terms and cancel them. So, the formulas end up simpler on balance."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To demonstrate the effectiveness of this technique, I apply this algorithm to the front door estimator. This expression is unsimplified expression, and it represents the form of the expression that is derived using ID. \n",
    "\n",
    "$$\n",
    "P(y | do(x)) = \\sum_{Z} \\big(\\sum_{} \\big(\\sum_{X} \\big({\\sum_{} \\big(P(X, Z, Y)\\big) \\over \\sum_{Y} \\big(P(X, Z, Y)\\big)} {\\sum_{Z, Y} \\big(P(X, Z, Y)\\big) \\over \\sum_{Z, Y, X} \\big(P(X, Z, Y)\\big)}\\big)\\big) \\sum_{} \\big({\\sum_{} \\big(\\sum_{Y} \\big(P(X, Z, Y)\\big)\\big) \\over \\sum_{Z} \\big(\\sum_{Y} \\big(P(X, Z, Y)\\big)\\big)}\\big)\\big)\n",
    "$$\n",
    "\n",
    "After simplification, the expression is reduced to the following form. This example highlights the need for a simplification algorithm, and it shows that the heuristic simplification algorithm is surprisingly effective for outputs of this size.\n",
    "\n",
    "$$\n",
    "P(y | do(x)) = \\sum_{Z} \\big({\\sum_{X} \\big({P(X) P(X, Z, Y) \\over P(X, Z)}\\big) P(X, Z) \\over P(X)}\\big)\n",
    "$$\n",
    "\n",
    "Both of the above expressions were generated by `pqp`."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "\n",
    "The primary goals for this implementation were correctness, performance, and ease of use. In this section, I examine the library in light of each of these goals in turn."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correctness\n",
    "\n",
    "One of the main impetus for this project was to improve on the many correctness issues with existing implementations of the algorithm. To this end, I implemented a large number of tests. I used hand derived answers to test the algorithm on a number of famous examples (backdoor, frontdoor, IV, bowgraph). Then, I copied all of the other examples of identification from Shpitser's dissertation (Shpitser, 2008). He gives 15 examples of identifiable and nonidentifiable graphs, and I test the algorithm the on each of these examples."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Figure 5. Examples of identifiable graphs**\n",
    "![](2023-02-25-09-07-36.png)\n",
    "\n",
    "*This figure, taken from Shpitser (2008) shows several examples of identifiable graphs. My implementation recovers the correct estimator for each.*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To demonstrate typical output from the algorithm, I apply the algorithm to find estimators for each of these graphs. These estimators are shown below. The algorithm successfully recovers the estimator in each case. The only issue highlighted by this example is that the simplification routine still stuggles to achieve an acceptable outcome as graphs get larger. This is an area of active work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\textbf{Model a: } P(y | do(x)) = {P(x, y) \\over P(x)}$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\textbf{Model b: } P(y | do(x)) = \\sum_{z} \\big({P(z, y, x) \\over P(x)}\\big)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\textbf{Model c: } P(y | do(x)) = \\sum_{z} \\big({P(x, y, z) P(z) \\over P(x, z)}\\big)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\textbf{Model d: } P(y | do(x)) = \\sum_{z} \\big({P(z) P(z, y, x) \\over P(z, x)}\\big)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\textbf{Model e: } P(y | do(x)) = \\sum_{z} \\big({\\sum_{x} \\big({P(z, y, x) P(x) \\over P(z, x)}\\big) P(z, x) \\over P(x)}\\big)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\textbf{Model f: } P(y | do(x)) = \\sum_{z2, z1} \\big({\\sum_{x} \\big({P(z1, z2, x) P(x) \\over P(z1, x)}\\big) P(z1, z2, x, y) P(z1, x) \\over P(z1, z2, x) P(x)}\\big)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\textbf{Model g: } P(y | do(x)) = \\sum_{z3, z2, z1} \\big({\\sum_{z1, x} \\big({P(z3, y, z1, z2, x) P(z3, z2, x) \\over P(z3, z1, z2, x)}\\big) \\sum_{z1, z3, x, y} \\big({P(z3, y, z1, z2, x) P(z3, z2, x) \\over P(z3, z1, z2, x)}\\big) P(z3, z2) P(z1, z2, x) \\over \\sum_{z1, y, x} \\big({P(z3, y, z1, z2, x) P(z3, z2, x) \\over P(z3, z1, z2, x)}\\big) \\sum_{z3, z2, x, z1, y} \\big({P(z3, y, z1, z2, x) P(z3, z2, x) \\over P(z3, z1, z2, x)}\\big) P(z2) P(z2, x)}\\big)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Math\n",
    "from string import ascii_lowercase\n",
    "from supplement import g1, g2, g3, g4, g5, g6, g7, x, y\n",
    "\n",
    "for i, g in enumerate([g1, g2, g3, g4, g5, g6, g7]):\n",
    "    estimand = g.idc([y], [x])\n",
    "    display(Math(\"\\\\textbf{Model \" + ascii_lowercase[i] + \": } P(y | do(x)) = \" + estimand.to_latex()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, Shpitser (2008) supplies of a number of examples of nonidentifiable graphs. The algorithm correctly identifies these as nonidentifiable. The examples from Shpitser (2008), along with estimators derived by the algorithm, are shown below.\n",
    "\n",
    "**Figure 6. Examples of nonidentifiable graphs**\n",
    "![](2023-02-25-09-22-50.png)\n",
    "\n",
    "*This figure, taken from Shpitser (2008) shows several examples of nonidentifiable graphs. My implementation correctly identifies these as nonidentifiable.*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When run on each of these graphs, the algorithm successfully recovers a hedge, demonstrating non identifiability of each graph."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance\n",
    "\n",
    "To test to performance of the implementation, I designed a set of benchmarks to compare it to other existing implementations. For these benchmanrks, I randomly generated a large number of graphs with different properties. Then, I timed my algorithm at identifying these graphs.\n",
    "\n",
    "TODO: Actually benchmark\n",
    "- w & w/o simplification\n",
    "- talk about different random generating processes for queries"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ease of Use\n",
    "The Rust code underlying the library is extremely fast, but Rust is a language used by few in the causal inference community. To make the library more accessible, I created a Python library that wraps the Rust code. Although Python is definitely second to R in terms of adoption in the community, it is much more common among industrial practicioners.\n",
    "\n",
    "While the focus of the Rust implementation is correctness and performance, the focus of the Python bindings is on elegance and usability. I used Python's magic methods to create an API for specifying and querying causal models that is extremely simple and readable. I created a website with documentation for the python library, and I have published the library on PyPI.\n",
    "\n",
    "By utilizing Python's infix operators, I was able to create an API in which graphs can be created via an intuitive embedded syntax. It is possible to create a new causal model using the library in just a few lines. The `<=` operator creates a directed edge in the graph, while the `&` operator creates a bidirected edge. See the following example, which implements the front-door model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pqp.variable import make_vars\n",
    "from pqp.graph import Graph\n",
    "\n",
    "x, y, z = make_vars(\"xyz\")\n",
    "g = Graph([\n",
    "    z <= x,\n",
    "    y <= z,\n",
    "    x & y\n",
    "])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identification is accessed through a method, and several output formats are available. As demonstrated below, Latex is available inside Jupyter notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\sum_{z} \\big({\\sum_{x} \\big({P(x) P(x, z, y) \\over P(x, z)}\\big) P(x, z) \\over P(x)}\\big)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "estimand = g.idc([y], [x])\n",
    "estimand.display()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The library also supports visualization using the `networkx` library as an optional dependency. Although this feature is not entirely polished yet, it is useful to quickly visualize the model. Bidirected edges are indicated using a dashed line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "g.draw()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examples"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, I show how my code can be used to identify interventional distributions in two toy examples."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next Steps\n",
    "- prove Whittemore broken\n",
    "- randomly generated tests for correctness and benchmarking\n",
    "- educational materials\n",
    "- estimation code\n",
    "- end-to-end demo"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendices"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix 1: HC and LO Applications"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HC Applications"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#confidenceintervals\n",
    "\n",
    "\n",
    "In the final project, I will explain how bootstrapping can be used to estimate confidence intervals for causal effect estimates. A stretch goal is to implement this in code.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#induction\n",
    "\n",
    "Structural causal modeling is all about principled approaches to induction. I carefully explain how inference is conceptualized within this framework, and I draw connections between the framework and predictions that result on actual datasets. I show a deep understanding of the nuances of inductive reasoning.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#algorithms\n",
    "\n",
    "\n",
    "I explain the tradeoffs between a number of approaches to identification. I carefully explain how each alternative works, and I provide a high-level overview of Shpitser’s identification algorithm. I use asymptotic complexity to characterize tradeoffs. I implement Shpitser’s identification algorithm.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#variables\n",
    "\n",
    "I carefully handle distinctions between treatment, outcome, and control variables. I provide a subtle discussion of the relationships between treatment and outcome variables in the structural causal modeling framework. I explain how treatment variables in a causal estimand may be converted to control variables or excluded via identification.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#probability\n",
    "\n",
    "I show a deep understanding of probabilistic expressions and how they can be manipulated via the two rules of probability. I show how an extension to the basic logic of probability (do-expressions) can be incorporated into probabilistic reasoning."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#deduction\n",
    "\n",
    "The do-calculus is a framework for using formal mathematics to reason about the very hairy and complex inductive problem of causal inference. I present the key intuitions behind the do-calculus, and then leverage an algorithm based on the do-calculus to perform identification. In addition, I make use of mathematical reasoning to prove a number of small supporting points."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#organization\n",
    "\n",
    "\n",
    "Structural causal modeling is a complex framework for reasoning about inductive reasoning. I break down this highly complex and interconnected topic into a series of short digestible insights, each of which I present in a subsection. I present the idea in an order which allows the reader to build an intuition for the field.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#professionalism\n",
    "\n",
    "\n",
    "For the final project, I will reformat this report using Latex.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#composition\n",
    "\n",
    "I explain a complex, technically rigorous topic in a way that is accessible to someone educated in mathematics or computer science. I carefully handle jargon—using it only when necessary and being careful to define my terms. I condense most of the information I have learned over the course of a year-long literature review into 8 pages of background information. I balance concision with clarity in a highly difficult explanation."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#regression\n",
    "\n",
    "\n",
    "I explain how regression modeling (under the name estimation) fits into the framework of structural causal modeling. I show a deep understanding of the role of regression in larger causal inference through my explanation of the role of abstract statistical estimators. For the final capstone, I will implement a regressions model to estimate causal effects, using abstract estimators derived from my implementation of identification.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#correlation\n",
    "\n",
    "\n",
    "Rather than referring to correlation directly, I discuss the more general notion of statistical estimation. I explain how association in the joint distribution of a dataset relates to d-separation and live paths in the causal model. I explain how statistical association can change as a result of conditioning, and I present a complete account (based on Pearl’s work) of when this occurs.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#sampling\n",
    "\n",
    "\n",
    "All of the difficulties of observational research fundamentally result from biased samples. In the final deliverable, I will explain how sampling bias in a real dataset can be controlled for using structural causal models."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#observationalstudy\n",
    "\n",
    "\n",
    "I implement a complex software library aimed to help researchers working with observational data. I show a deep understanding of the pitfalls of observational research through my explanation of confounding and collider bias. I explain how identification can be used to remove biases from estimation of causal effects.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#modeling\n",
    "\n",
    "\n",
    "I show a deeply researched and incredibly rigorous understanding of the structural causal modeling approach to causal inference. I explain how the “moving parts” of the model relate to changes in its predictions for the data. I implement a tool to aid in using structural causal modeling on real data.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#comparisongroups\n",
    "\n",
    "\n",
    "In observational research, proper control groups are rarely available. The marginalization and control operations called for in the abstract estimator returned from identification can be interpreted as reweighting and excluding existing data in a way that synthetically generates a proper control group from available data. I will develop this analogy further in the final deliverable.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LO Applications"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#search\n",
    "\n",
    "\n",
    "Deriving an abstract estimator using the do-calculus is fundamentally a search problem. I explain the workings of two approaches to solving this problem: adjustment set search, which relies on backtracking, and Shpitser’s identification algorithm, which can be interpreted as a dynamic programming solution. I will further develop these connections in the final deliverable.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#aicoding\n",
    "\n",
    "\n",
    "Structural causal modeling was originally developed as a framework for building smart AI’s. Identification is fundamentally a search problem, and search is a traditional task for AI systems. I provide a performant and well-tested implementation of Shpitser’s identification algorithm.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#datamodel\n",
    "\n",
    "\n",
    "I provide an explanation of structural causal modeling which demonstrates deep understanding. I provide extensive discussion of benefits and pitfalls. I implement a challenging subroutine of the structural causal modeling workflow. For the final deliverable, I will apply structural causal modeling (and my code) to a data analysis.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#quantprofessionalism\n",
    "\n",
    "\n",
    "For the final deliverable, I will format this report using latex, following conventional guidelines for the reporting of figures. I will make my code available as a well-formatted and commented GitHub repository.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#numimplementation\n",
    "\n",
    "\n",
    "For the final project, a stretch goal is to implement estimation. This is a classic numerical algorithm, where issues of convergence, numerical precision, and iterative solving will come into play.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Capstone LO Applications"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- #qualitydeliverables\n",
    "- #curation\n",
    "- #navigation\n",
    "- #outcomeanalysis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix 2: Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bbbf304047aac1d8dfa956a63cc2cea0a93c42bcd915750832b2326b8115e97d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
