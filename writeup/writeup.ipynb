{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract\n",
    "Causal inference under Pearl’s framework of structural causal models has been the subject of intense theoretical study, but performant open-source implementations of many of the key algorithms are still lacking or, where they exist, are not widely adopted or maintained. I present a performant implementation of Shpitser’s IDC algorithm for identification of conditional causal effects in semi-Markovian causal models."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Executive Summary\n",
    "\n",
    "Causal inference is a fundamental task in many fields, including epidemiology, economics, and data science. One popular framework for causal inference is Pearl's structural causal modeling framework, which utilizes directed acyclic graphs (DAGs) and the do-calculus to explicitly model potential causal relationships. This approach allows for a clear and intuitive representation of causal assumptions, while also helping to avoid common biases that can arise with other methodologies. However, a crucial step in this framework is identification: translating a causal question into an abstract statistical estimator that can be estimated using a combination of a model and parametric assumptions.\n",
    "\n",
    "One important algorithm for identification in the structural causal modeling framework is Shpitser's algorithm for conditional interventional effects. This algorithm is polynomial time and guarantees a result when one is possible. However, existing open-source implementations of this algorithm are often incorrect, slow, or unmaintained. In this paper, I present a novel implementation of Shpitser's algorithm, written in Rust for efficient cross-functional use. Our implementation is production-quality code and includes extensive testing routines to ensure performance and correctness.\n",
    "\n",
    "To bridge the gap between theoretical algorithm and practical tool, I developed two techniques as subroutines to the algorithm. I developed and implemented a heuristic symbolic simplification algorithm. To protect the speed and memory efficiency of the program, I designed a memory-sharing graph datastructure which allows similar graphs to share memory via a system of references and immutable data. Further, I am close to finishing an implementation of a estimation technique which will extend the work in Brule (2018).\n",
    "\n",
    "To aid in adoption of this algorithm, I designed and implemented a user-friendly Python wrapper. This wrapper allows for the specification and visualization of causal graphs using a concise and elegant API, as well as giving the user full access to the underlying algorithms. This is available as a Python package on PyPi, and I created a website with documentation."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "The paper is organized as follows: in the first section, I provide an overview of the background and motivation behind the algorithm. I review the literature on available implementations of the algorithm and justify the need for this implementation.\n",
    "\n",
    "In the Implementation section, I describe technical insights I employed and analysis I performed on my implementation. I detail techniques I developed for simplication and memory-sharing, and I describe the extensive testing procedures I used to ensure correctness. I describe the Python wrapper I developed to make the algorithm accessible to a wider audience. I evaluate my implementation on correctness, performance, and ease of use.\n",
    "\n",
    "In Next Steps, I outline plans to complete this project before the final deadline. In Examples, I provide examples to demonstrate the utility of our implementation.\n",
    "\n",
    "Appendices include HC/LO footnotes, documentation, and code."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contributions\n",
    "\n",
    "In this work, we present a novel implementation of Shpitser's ID algorithm, including a comprehensive set of graph routines and a heuristic-based simplification algorithm. The implementation is written in Rust and the code is provided in the appendix. Additionally, we have developed Python bindings to facilitate usage of the algorithm. It is important to note that while this implementation and techniques for simplification and memory-sharing are novel, the underlying algorithm and all the material covered in the Background section is not a contribution of this paper and is instead a summary of the current state of the field."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Links\n",
    "\n",
    "- Documentation: [https://leo-ware.github.io/pqp/index.html](https://leo-ware.github.io/pqp/index.html)\n",
    "- Source code: [https://github.com/leo-ware/pqp](https://github.com/leo-ware/pqp)\n",
    "- PyPI Distribution: [https://pypi.org/project/pqp/](https://pypi.org/project/pqp/)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note on this text\n",
    "\n",
    "AI text generation algorithms were used in the production of this text. Specifically, the OpenAI model ChatPGT was used extensively to edit for tone and concision."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structural Causal Models\n",
    "\n",
    "### Overview\n",
    "\n",
    "Structural Causal Models (SCM) provide a framework for modeling the generating process of a distribution. A structural causal model has four components: a set of observed variables $\\textbf{V} = {v_1, v_2, ..., v_n}$, a set of unobserved variables $\\textbf{U} = {u_1, u_2, ..., u_m}$, a distribution $P(U)$ over unobserved variables, and a set of functions $\\textbf{F} = {f_1, f_2...f_n}$ such that each $f_i$ is a function from a subset of $\\textbf{U} \\cup \\textbf{V} \\backslash V_i$ to $v_i$. The arguments to $f_i$ are called the parents of $v_i$ or $pa(v_i)$ and they uniquely determine the value of $v_i$. Together, $P(\\textbf{U})$ and $\\textbf{F}$ induce $P(\\textbf{V})$, a distribution over $\\textbf{V}$.\n",
    "\n",
    "We represent the causal assumptions in an SCM via a causal diagram. This is a directed acyclic graph (DAG) where each node corresponds to a variable in the model. A directed edge from $x_i$ to $x_j$ indicates that the value of $x_j$ depends on the value of $x_i$, or $x_i \\in pa(x_j)$. To ensure the validity of an SCM, we restrict the set of valid models to those that can be represented by acyclic graphs, to prevent circular definitions between variables [1]. Algebraically, we can interpret a causal diagram as defining a set of conditional independence assumptions. In particular, as the parents of $v_i$ completely determine its value, $v_i$ will be independent of every other variable in the model, conditional on its parents.\n",
    "\n",
    "Note the acyclicity assumption does not restrict the class of distributions that can be represented by an SCM because by the definition of joint probability any joint distribution $P(x_1, x2…x_n)$ can be factorized as $P(x_1 | x_2…x_n)P(x_2 | x_3…x_n)...P(x_n-1 | x_n) P(x_n)$. But, this can be represented as an SCM where $pa(x_i) = \\{x_{i+1}, x_{i+2}…x_n\\}$ without violating the acyclicity assumption. However, the any given causal graph may be consistent with only a subset of all possible distributions over the variables in the graph.\n",
    "\n",
    "For the purposes of this paper, we make the additional assumption that each unobserved variable is the parent of at most two observed variables. This simplifies the graphical representation by replacing each unobserved variable and its outgoing edges with a single undirected edge connecting its two children. This can be interpreted as representing potential confounding between the two variables. An example of such a simplified graph is shown in Figure 1."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Figure 1. Using Bidirected Edges to Represent Confounding**\n",
    "![](2023-01-14-13-06-10.png)\n",
    "*This figure shows an unobserved variable $C$ with two children being replaced with a bidirected, dashed edge. The bidirected edge represents the same information as $C$ did in the first diagram, but it is only possible to represent confounders with bidirected edges if they have exactly two children.*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conditional Independence Properties of Causal Diagrams\n",
    "\n",
    "One of the key properties of causal diagrams is that they can provide insight into the conditional independence properties of a distribution $P(\\textbf{U} \\cup \\textbf{V})$. As previously discussed, a variable $v_i$ is independent of all other variables in the model, conditional on its parents. This concept of a \"flow of dependence\" along edges connecting a node to its parent is a useful tool for understanding the conditional independence assumptions encoded in a causal diagram.\n",
    "\n",
    "However, it is important to note that dependence does not flow along every path in the diagram. Paths can be blocked by conditioning on certain variables, which alters the conditional independence properties of the distribution. We can view a path as a collection of vertices, each of which must have one of the following forms:\n",
    "\n",
    "$$X \\leftarrow Y \\leftarrow Z$$\n",
    "$$X \\rightarrow Y \\rightarrow Z$$\n",
    "$$X \\leftarrow Y \\rightarrow Z$$\n",
    "$$X \\rightarrow Y \\leftarrow Z$$\n",
    "\n",
    "In the first three cases, dependence will flow through the vertex as long as we do not condition on $Y$. In this case, we call the vertex unblocked. Conditioning on $Y$ blocks the path and prevents dependence from traveling along it. This means that, as long as this is the only path connecting $X$ and $Y$, the causal diagram is predicting that $X$ and $Z$ will be independent conditional on $Y$.\n",
    "\n",
    "The third case, known as a collider, is slightly different. The last vertex will be unblocked if and only if we condition on $Y$.\n",
    "\n",
    "To illustrate the concept of colliders, consider the example of college admissions. Without knowledge of whether a student was admitted, learning her SAT scores tells us nothing about her admissions essays. However, if we know that the student was admitted, and we observe that her SAT scores were low, we can infer that her essays must have been good.\n",
    "\n",
    "A path is considered blocked if any vertex along it is blocked. If, after conditioning on a set of variables $\\textbf{Z}$, there are no unblocked paths connecting two variables $v_i$ and $v_j$, then the model predicts that $v_i$ and $v_j$ are independent conditional on $\\textbf{Z}$. In this case, we say that $v_i$ and $v_j$ are d-separated by $\\textbf{Z}$. This concept of d-separation provides a means to connect the ideas of statistical association in the joint distribution with properties of the graph, and allows us to use graphical models of causal relationships to make testable predictions about datasets."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Figure 2. Examples of D-Separation**\n",
    "\n",
    "![](2023-01-14-13-52-24.png)\n",
    "\n",
    "*The figure shows an example of a causal graphical model. Nodes represent random variables, and edges represent direct causal influence.*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, in figure 2 we can make the following predictions about distribution $P(\\textbf{V})$ based on the causal diagram:\n",
    "\n",
    "- $A \\perp\\!\\!\\!\\!\\perp C$ but not $A \\perp\\!\\!\\!\\!\\perp C | D$\n",
    "- $A \\perp\\!\\!\\!\\!\\perp B | C$ but not $A \\perp\\!\\!\\!\\!\\perp B | C, D$\n",
    "- $B \\perp\\!\\!\\!\\!\\perp D | C$ but not $B \\perp\\!\\!\\!\\!\\perp D$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph Surgery and Causal Effects\n",
    "\n",
    "In causal inference, a fundamental task is to measure the causal effect of one set of variables, $X$, on another, $Y$. To operationalize this task within the Structural Causal Model (SCM) framework, we utilize the concept of interventions. Specifically, in the SCM, the values of $X$ are determined by its parents, $pa(X)$. However, we are interested in understanding the effect of altering the value of $X$ through intervention, rather than allowing it to be set by its natural causes. To model this intervention process, we perform \"graph surgery\" by cutting all incoming edges into $X$, and examining the resulting interventional distribution. This allows us to isolate any remaining conditional effect of $X$ on $Y$, which can then be interpreted as a causal effect.\n",
    "\n",
    "To gain further insight into this process, we can consider two types of paths that may connect $X$ and $Y$: backdoor paths and frontdoor paths. Backdoor paths are those that connect to $X$ through its parents, while frontdoor paths connect through its children. These paths represent different mechanisms through which $X$ may affect $Y$; frontdoor paths indicate direct causal effects, while backdoor paths indicate indirect effects through other variables (i.e. confounding). By performing graph surgery and cutting all backdoor paths, we effectively isolate any causal effects flowing through frontdoor paths.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Do-Calculus\n",
    "\n",
    "In the Structural Causal Model (SCM) framework, causal queries are represented by the use of the \"do-operator.\" The do-operator is indicated by its placement behind the conditioning bar in a probability expression, and it represents a modification of the underlying generating process. To illustrate, for sets of variables $X$, $Y$, and $Z$, the expression $P(Y | do(X), Z)$ represents the conditional probability $P(Y | X, Z)$ in the model that results from performing graph surgery on $X$. This represents a hypothetical scenario in which $X$ is fixed through intervention, rather than being determined by \"nature.\" A \"do-expression\" is any probability expression containing the do-operator.\n",
    "\n",
    "Both the average treatment effect (ATE) and the conditional average treatment effect (CATE) can be expressed in terms of do-expressions. The ATE is given by:\n",
    "\n",
    "$ATE = E(P(y | do(x = 1))) - E(P(y | do(x = 0)))$\n",
    "\n",
    "while the CATE is given by:\n",
    "\n",
    "$CATE = E(P(y | z, do(x = 1))) - E(P(y | z, do(x = 0)))$\n",
    "\n",
    "The manipulation of do-expressions is facilitated by Pearl's \"do-calculus\", which references properties of the model in which the do-expression is evaluated. The do-calculus provides conditions under which do-operators can be removed from an expression or replaced with conditioning. This is advantageous because it allows us to transform do-expressions, which cannot be estimated from the data, into traditional statistical estimands (e.g., $P(Y | X, Z)$), which can be estimated using parametric assumptions.\n",
    "\n",
    "$\n",
    "\\textbf{Rule 1 } \\text{Insertion/deletion of observations:}\\\\\n",
    "P(Y | do(X), Z, W) = P(Y | do(X), W) \\\\\n",
    "\\text{if } (Y \\perp\\!\\!\\!\\!\\perp Z | X, W)_{G_{\\overline{X}}}\n",
    "$\n",
    "\n",
    "$\n",
    "\\textbf{Rule 2 } \\text{Action/observation interchange:}\\\\\n",
    "P(Y | do(X), do(Z), W) = P(Y | do(X), Z, W) \\\\\n",
    "\\text{if } (Y \\perp\\!\\!\\!\\!\\perp Z | X, W)_{G_{\\overline{X} \\underline{Z}}}\n",
    "$\n",
    "\n",
    "$\n",
    "\\textbf{Rule 3 } \\text{Insertion/deletion of actions:}\\\\\n",
    "P(Y | do(X), do(Z), W) = P(Y | do(X), W) \\\\\n",
    "\\text{if } (Y \\perp\\!\\!\\!\\!\\perp Z | X, W)_{G_{\\overline{X} \\overline{Z(W)}}}\n",
    "$\n",
    "\n",
    "The task of removing the do-operators from a do-expression and turning it into a statistical estimand is called \"identification.\" It is a crucial step in the process of causal inference in the SCM framework. General procedures for identification allow us to express causal queries in the rich language of do-expressions and then algorithmically translate these queries into statistical estimands that can be directly estimated from the data. Additionally, because identification does not make any parametric assumptions about the data, it allows us to decouple our causal assumptions from our parametric assumptions during modeling."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Four Stages of Causal Inference\n",
    "\n",
    "Structured causal effect estimation is a four-step process consisting of modeling, identification, estimation, and robustness checks.\n",
    "\n",
    "1. Modeling: This step involves identifying plausible causal relationships in the form of a directed acyclic graph (DAG). The DAG serves as a representation of the causal structure of the system being studied.\n",
    "\n",
    "2. Identification: Once the causal structure is represented in the form of a DAG, the next step is to translate a causal query into an abstract estimator in the context of these assumptions. This process is known as identification, and it is a crucial step in the process of causal inference.\n",
    "\n",
    "3. Estimation: After the abstract estimator has been derived, the next step is to add parametric assumptions and pick a specific model to represent the abstract estimator. This model is then fitted to the data, and an estimate of the causal effect is extracted.\n",
    "\n",
    "4. Robustness checks: The final step is to assess the robustness of the analysis to the specifics of the assumptions made in the modeling process. This is done by perturbing the assumptions of the modeling process and determining the sensitivity of the analysis to these perturbations. These robustness checks are important for ensuring the validity and generalizability of the causal estimates.\n",
    "\n",
    "It's important to note that the modeling, identification, estimation and robustness checks are interrelated, and that making progress in one step may require revisiting the others."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Problem of Identification\n",
    "\n",
    "### Overview\n",
    "\n",
    "It is important to note that not every causal estimand can be unambiguously estimated in every model. Identification, or the process of determining the causal estimand from the joint distribution, may fail when it is impossible to unambiguously determine $P(Y | do(X))$ from $P$. Identification is always possible in a graph with no confounding, but in some cases it is not possible because it is not possible to disentangle the effect from possible confounding. For example, in a model with a bidirected edge between variables, it may be impossible to identify $P(Y | do(X))$ because any observed effect could be explained by confounding along the bidirected edge, and there is no way to control for this."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Figure 4. The Bow Graph**\n",
    "\n",
    "![](2023-01-14-14-22-06.png)\n",
    "\n",
    "*The bow graph is the simplest example of a graph with a non-identifiable interventional distribution.*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rules of the do-calculus provide complete conditions for identification of causal estimands; if it is possible to convert the causal estimand to a statistical estimand, then it is possible using the do-calculus. However, manually applying the rules of the do-calculus to derive an abstract estimator is time-consuming and requires the researcher to make reference to complex properties of the causal graph, which is a task humans are ill-suited to, especially as the complexity of the graph grows. In the general case, it is too complex a task to be performed by hand.\n",
    "\n",
    "Thus, it is necessary to find algorithms by which identification can be performed automatically. This is a nontrivial problem; naive approaches often have exponential time complexity in the size of the graph, and the best algorithms, while polynomial time, rest on complex graph theory.\n",
    "\n",
    "Some researchers have simplified this problem by sidestepping direct application of the do-calculus and instead using the concept of adjustment sets. These methods rely on finding a set of variables which, when controlled for, block all backdoor-paths from the intervention set to the outcome set. However, these approaches face two distinct challenges. First, naive approaches to adjustment set search, such as those implemented in Knupple (2010), Breitling (2010), and Sharma (2020) rely on enumerating the set of all possible adjustment sets and then checking whether each successfully blocks all backdoor paths. This is an issue because the number of possible adjustment sets grows exponentially in the number of nodes in the graph. This makes these approaches infeasible for even fairly small graphs.\n",
    "\n",
    "More efficient algorithms exist for adjustment set search, such as the one proposed in Textor and Liskiewicz (2011), which works in polynomial time. However, the drawback of these algorithms is that although every valid adjustment set corresponds to a valid statistical estimator for the query, not every valid statistical estimator can be represented as an adjustment set. Because these algorithms are only searching among adjustment sets, they fail in cases where other classes of estimator are needed.\n",
    "\n",
    "To illustrate, in the famous front-door model, the interventional distribution $P(Y | do(X))$ is identified by the simple statistical estimator $P(Y | do(X)) = \\sum_z P(Z | X) \\sum_x P(Y | Z, X) P(X)$. This estimator works by breaking the problem into two subproblems: first identifying the interventional distributions $P(M | do(X))$ and $P(Y | do(M))$ and then combining these to identify $P(Y | do(X))$. Each subproblem can be solved using an adjustment set operator, but there is no adjustment set estimator which identifies $P(Y | do(X))$."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C-components\n",
    "\n",
    "Front-door estimation is an interesting technique, but it also illustrates a larger concept in causal inference known as c-component factorization. C-components, or connected components, are subsets of the graph that are connected via bidirectional (confounding) edges. Two nodes, $A$ and $B$, in a causal graph are in the same c-component if and only if there is a path from $A$ to $B$ that only follows bidirectional edges. It has been shown that any causal graph can be uniquely partitioned into a minimal set of c-components (Tian, 2002).\n",
    "\n",
    "More importantly, Tian (2002) showed that for any c-component $C$ in a graph $G$, the interventional distribution $P(C | do(V \\backslash C))$ is identifiable, where $V$ denotes the set of nodes in $G$ and $\\backslash$ represents set difference. This means that the problem of identifying $P(Y | do(X))$ can be broken down into a set of subproblems, one for each c-component in the graph $G \\backslash X$. This is the first critical insight that enables efficient identification and is known as c-component factorization.\n",
    "\n",
    "C-components also allow for the introduction of more complex graphical structures, such as the c-tree. A $Y$-rooted c-tree is a graph $G$ that contains both directed and bidirected edges, where the entire graph is a single c-component and every node has at most one child. Additionally, there is a single node $Y$ that has no children. If there are multiple nodes with no children, these nodes are referred to as the root-set of $G$, and the graph is called a c-forest."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Figure 4. A C-Tree and  C-Forest**\n",
    "\n",
    "![](2023-01-14-15-01-52.png)\n",
    "\n",
    "*This figure shows a c-tree (left) and a c-forest (right). Note that both are c-components because they are completely connected by bidirectional edges. In addition, in both, no node has more than one child. However, in the c-tree, C is the only node without children. This makes this a $C$-rooted c-tree. On the other hand, the graph on the right has two nodes without children: $C$ and $G$. This makes it a $\\{C, G\\}$-rooted c-forest.*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By utilizing c-forests, the concept of a hedge can be defined. Hedges are graphical structures that prevent the identification of interventional distributions. In a causal graphical model with graph $G$, if an interventional distribution $P(Y | do(X))$ is sought for two sets of random variables $X$ and $Y$, and if there exist two subgraphs $F$ and $F'$ such that the intersection of $F$ and $X$ is non-empty, but the intersection of $F'$ and $X$ is empty, and if $F'$ is a subgraph of $F$, and both form $Z$-rooted c-forests, where $Z$ is a subset of $Y$, the interventional distribution $P(Y | do(X))$ will be identifiable if and only if such $F$, $F'$, and $Z$ do not exist.\n",
    "\n",
    "In other words, if two nested c-forests are found, where at least some elements from $Y$ are in their root set, and the smaller one does not contain any elements from $X$ but the bigger one does, the interventional distribution is not identifiable."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shpitser's Algorithm\n",
    "\n",
    "Shpitser’s ID algorithm exploits the properties of c-components to identify interventional distributions. It is polynomial time and can always derive an estimator if one exists. The algorithm works as follows (Shpitser, 2008):\n",
    "\n",
    "$\n",
    "\\text{function }\\textbf{ID}(y, x, P, G)\\\\\n",
    "\\text{INPUT: x, y value assignments, P a probability distribution, G a causal diagram}\\\\\n",
    "\\text{OUTPUT: Expression for } P_x(y) \\text{in terms of } P \\text{ or } \\textbf{FAIL}\n",
    "$\n",
    "\n",
    "$\n",
    "\\text{1. if } x = \\emptyset \\text{ return } \\sum_{v \\setminus y} P(v)\\\\ \\\\\n",
    "$\n",
    "\n",
    "$\n",
    "\\text{2. if } V \\setminus An(Y)_G \\ne \\emptyset \\\\ \\text{ return } \\textbf{ID}(y, x \\cap An(Y)_G, \\sum_{v \\setminus An(Y)_G} P, G_{An(Y)})\n",
    "$\n",
    "\n",
    "$\n",
    "\\text{3. let } W = (V \\setminus X) \\setminus An(Y)_{G_{\\overline{x}}} \\\\\n",
    "\\text{if } W \\ne \\emptyset \\text{, return } \\textbf{ID}(y, x\\cup w, P, G)\n",
    "$\n",
    "\n",
    "$\n",
    "\\text{4. if } C(G \\setminus X) = {S_1...S_k}\\\\\n",
    "\\text{return } \\sum_{v \\setminus (y \\cup x)} \\prod_{i} \\textbf{ID}(s_i, v \\setminus s_i, P, G)\n",
    "$\n",
    "\n",
    "If line 4 does not return, then $C(G \\setminus X) = {S}$\n",
    "\n",
    "$\n",
    "\\text{5. if } C(G) = {G} \\text{, throw } \\textbf{FAIL}\n",
    "$\n",
    "\n",
    "$\n",
    "\\text{6. } S \\isin C(G) \\text{ return } \\sum_{s \\setminus y}\\prod_{ \\{i | V_i \\subset S \\} } P(v_i | v_\\pi^{(i - 1)})\n",
    "$\n",
    "\n",
    "$\n",
    "\\text{7. if } (\\exists S') S \\subset S' \\in C(G) \\\\\n",
    "\\text{ return } \\textbf{ID}(y, x \\cap S', \\prod_{ \\{i | V_i \\subset S' \\} }P(V_i | V_\\pi^{(i - 1)} \\cap S', v_\\pi^{(i - 1)} \\setminus S'), G_{S'})\n",
    "$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first three lines set up the algorithm. Line one is a base-case for identifiability. Lines two and three perform simplification.\n",
    "\n",
    "Line four works by breaking up the identification problem into subproblems. Considering the subgraph $G’ = G \\setminus X$, we find the c-components $\\{s_i\\}$ of $G’$. If there is more than one, then we can identify $P(Y | do(X))$ by finding the interventional distribution $P(s_i | do(G \\ s_i))$ for each $s_i$. Because of c-component factorization, we know that all such terms will be identifiable if and only if $P(Y | do(X))$ is identifiable. We can then take the product of all such terms to get a joint interventional distribution over the nodes in $G’$. By marginalizing all variables other than those in $X$ and $Y$, we can identify the interventional distribution.\n",
    " \n",
    "After repeated application of the above step, we will be in a position where $G’$ consists of a single c-component. There are three possible ways in which $X$ could relate to $G’$. $X$ and $G’$ could together form a single c-component. In this case, we have discovered a hedge, proving the interventional distribution is not identifiable (line 5). There could be no bidirectional edges connecting elements of $G’$ to elements of $X$. In this case, there are no backdoor paths from $X$ to $G’$ and we can identify the interventional distribution by conditioning on $X$ (line 6). It could be that some elements $Z \\subset X$ are connected via bidirectional edges to elements in $G’$, while others $W \\subset X$ are not. In this case, we can condition on $W$ and make a recursive call to the algorithm, attempting to identify the interventional distribution $P(G’ | do(Z))$ (line 7).\n",
    " \n",
    "The algorithm as described so far can only deal with queries of the form $P(Y | do(X))$, but often we will wish to calculate conditional interventional effects of the form $P(Y | do(X), Z)$. Thankfully, queries of this form can be mapped to queries without a conditional term with only a minimal transformation. This modification of the algorithm is known as IDC, or ID with conditioning, and it eliminates conditional variables in two ways. The first way is using Rule 22 of the do-calculus: if a conditional variable $z \\in Z$ has no back door paths to $Y$ when conditioning on $X$ and $Z \\ z$, then conditioning on z is equivalent to intervening on it, and it can be put inside the do operator. The second way is to treat $z$ as an outcome, run the algorithm, and then condition on $z$. Together, these two techniques can be used to eliminate all conditional variables from the query."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-existing Implementations\n",
    "\n",
    "A number of open source implementations of the ID algorithm existed prior to my work. Dowhy is a popular python library developed by Microsoft Research, but its implementation is too slow. Researchers working on the dowhy project explicitly asked me to create a faster implementation and integrate it with their library. There is also an implementation in Clojure called Whittemore which is quite fast, but because Clojure is a JVM language it is not possible to integrate this implementation with Python, R, or Javascript code. I based my implementation on Whittemore. Ananke is a causal inference library developed by Shpitser’s team, and it has an implementation of a related algorithm, but Ananke has not seen widespread adoption, and it is unmaintained. FInally, the Javascript/R tool Daggity has an implementation of adjustment set operators, which suffer from the drawbacks discussed above."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation\n",
    "\n",
    "## Technical Challenges\n",
    "\n",
    "### Graph Representation and Subroutines\n",
    "As a prerequisite to the rest of the work I did for this project, I implemented a set of graph routines to capture key operations that need to be performed during the algorithm. The key operations here are c-component factorization and ancestor search. C-component factorization is breaking partitioning the graph $G$ into subgraphs $S_i$ that obey the following constraints. Any two nodes ${a, b} \\subset S_i$ there exists a path from $a$ to $b$ along bidirectional edges, and for any two nodes $c \\in S_i$ and $d \\in S_j$ if $i \\ne j$ then there does not exist such a path. Ancestor search is the problem of finding the set $An(y)$ for a nodes $y$ such that a node $w$ is a member of $An(y)$ if and only if there is a directed path from $w$ to $y$.\n",
    "\n",
    "Because of of these operations only requires access to one kind of edge (directed or bidirected), I model a causal graphical model as consisting of two graphs: one directional and one bidirectional. The directional graph data structure handles ancestor queries, and the bidirectional graph data structure handles c-component factorization. Each of these problems is trivially solvable in $O(E)$ (order of number of edges in the graph) using breadth-first search. The subtlety here is because of the way the algorithm recursively parititons the graph into subproblems, we will be repeatedly rerunning ancestor and c-components queries on slightly modified versions of the graph. The causal graph data structure needs to efficiently handle arbitrary series of the following four operations:\n",
    "\n",
    "- c-component queries\n",
    "- ancestor queries\n",
    "- graph surgery (maintaining a copy of the original graph)\n",
    "- node deleletion (maintaining a copy of the original graph)\n",
    "\n",
    "Specifically, lines 2 and 3 of the algorithm require ancestor queries, and in the case of line 3, this query is performed after surgey. Lines 4 and 5 require c-component queries, and line 4 requires first removing $x$ from $G$.\n",
    "\n",
    "Since a structure representing the original graph must be maintained through deletions, we cannot just apply these as mutable changes to the data structure. So, a naive approach would be to make a copy of the graph at each modification and run the queries on this copied graph. This is quite wasteful from a resource standpoint though because it requires a linear-time $O(N + E)$ copy operation (order of number of nodes plus number of edges) at each modification. Since the algorithm has a worst case recursion-depth of $O(N)$, this amounts to an an additional quadratic order $O(N^2 + NE)$ runtime cost. The more concerning term here is the $NE$, because number of edges can grow with $O(N^2)$, so this term could be cubic. Although this is unlikely to be an issue in manually-specified models, it could become a real problem is models derived via automated causal discovery (e.g. in geothermal or econometric datasets) or in bioinfomatics applications, where causal networks are used to study genetic data, and models can get quite complicated.\n",
    "\n",
    "To address this problem, I implemented a set of routines that allows small modifications to be performed to the original graphs in such a way that a new data structure is created which is logically distinct inside the program but which uses most of the same memory. This reduces the memory footprint of the algorithm as well as reducing time spent copying data.\n",
    "\n",
    "Instead of copying the causal graph when subgraphing, the data structure maintains a reference to the original graph, and each subgraph tracks the nodes which it currently contains and the nodes which have been the subject of surgery. It is still possible to perform c-component and ancestors queries with the same time complexity. This requires a $O(N)$ operation, but it avoids the especially costly $O(NE)$ term in the final time complexity."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simplification\n",
    "Simplification is an important step in computational identification because the ID algorithm tends to return symbolic expressions that are quite complex and require simplification. The complexity of these outputs is not indicative of the complexity of the \"answer\", but they tend to contain many elements which are algebraically redundant. E.g., frequently identical terms will appear in the numerator and denominator of a quotient. A few lines of mathematical manipulation can reduce the complexity of these expressions significantly, but it is a nontrivial problem to write a program that can do this.\n",
    "\n",
    "It is important to simplify the results for a couple of reasons. Simpler expressions are easier for humans to understand. They make it easier to test the program because they reduce the number of “correct” answers to an identification problem. And, maybe most importantly, simpler expressions are easier to evaluate numerically. It is both computationally cheaper and more accurate to simplify an expression before applying numerical estimation techniques.\n",
    "\n",
    "Whittemore, which I have borrowed from extensively, uses a heuristic-based simplification algorithm with just a couple of rules. My original plan was to just use this, but their algorithm contains idiosyncracies that I think may indicate a mathematical error. I plan to present an example failure case in the next iteration of this report.\n",
    "\n",
    "Tikka and Karvanen (2017) describe a simplification routine that uses properties of the graphical model to find ways to reduce conditional terms. I was originally optimistic about this approach as it has nice guarantees on the degree of simplification. However, this approach has a time complexity that gorws significantly faster than exponential in the number of variables, and so would not prove practical for real problems.\n",
    "\n",
    "Instead of relying on these solutions, I developed my own heuritsitc simplification algorithm. This algorithm relis on an observation that most of the redundancy in the estimands generated by the algorithm can be remedied by fairly simple algebra. I implemented a simple recursive algorithm that applies a series of transformations on elements in the symbolic expression. It traverses the expression tree, replacing each node with a simplified version.\n",
    "\n",
    "For each possible type of subexpression, the following transformations are applied:\n",
    "\n",
    "expression type | transformations | example | example (simplified)\n",
    "---|---|---|---\n",
    "Quotient | Merge nested quotients and products. Cancel identical terms. | ${P(a)(P(b)P(c)) \\over {P(b) \\over P(d))}}$ | $P(a)P(c)P(d)$\n",
    "Product | Merge nested products and quotients. | ${P(a) \\over P(b)} P(c)$ | $P(a)P(c) \\over P(b)$\n",
    "Marginal | Convert sum over joint distribution to marginal distribution. | $\\sum_{a} P(a,b)$ | $P(b)$\n",
    "Conditional Probability | Convert to quotient. | $P(a \\| b)$ | ${P(a, b) \\over P(b)}$\n",
    "\n",
    "This scheme has the disadvantage that no conditional probability expressions are left in the final result, which can make the formulas less readable. But, this is worth it because in quotient form it is much easier to identify redundant terms and cancel them. So, the formulas end up simpler on balance."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To demonstrate the effectiveness of this technique, I apply this algorithm to the front door estimator. This expression is unsimplified expression, and it represents the form of the expression that is derived using ID. \n",
    "\n",
    "$$\n",
    "P(y | do(x)) = \\sum_{Z} \\big(\\sum_{} \\big(\\sum_{X} \\big({\\sum_{} \\big(P(X, Z, Y)\\big) \\over \\sum_{Y} \\big(P(X, Z, Y)\\big)} {\\sum_{Z, Y} \\big(P(X, Z, Y)\\big) \\over \\sum_{Z, Y, X} \\big(P(X, Z, Y)\\big)}\\big)\\big) \\sum_{} \\big({\\sum_{} \\big(\\sum_{Y} \\big(P(X, Z, Y)\\big)\\big) \\over \\sum_{Z} \\big(\\sum_{Y} \\big(P(X, Z, Y)\\big)\\big)}\\big)\\big)\n",
    "$$\n",
    "\n",
    "After simplification, the expression is reduced to the following form. This example highlights the need for a simplification algorithm, and it shows that the heuristic simplification algorithm is surprisingly effective for outputs of this size.\n",
    "\n",
    "$$\n",
    "P(y | do(x)) = \\sum_{Z} \\big({\\sum_{X} \\big({P(X) P(X, Z, Y) \\over P(X, Z)}\\big) P(X, Z) \\over P(X)}\\big)\n",
    "$$\n",
    "\n",
    "Both of the above expressions were generated by `pqp`."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimation\n",
    "\n",
    "In order for the estimator to be useful, we need to be able to use it to actually estimate a treatment effect in the precense of real data and a set of parametric assumptions. I have implemented a limited feature that allows for parametric modeling and causal estimation on statistical quantities. This feature is still quite experimental, and so I haven't added it to the library yet, but it is close to finished.\n",
    "\n",
    "In general, estimation of useful quantities from identified estimands can be quite hard because they involve a large number of nested sums (or integrals, in the continuous case). The computational complexity of evaluating nested sums grows exponentially in the number of these sums, and there is no way to reduce this cost in the general case while still computing an exact value.\n",
    "\n",
    "There are many approaches to this problem. A number of numerical approximation tools have been developed in the field of Bayesian statistics, but these a often quite finicky and most are heavy weight solutions. Shpitser (2012) shows how the conditional independence properties of causal graphs can be exploited to reduce the practical difficulty, but their algorithm is still exponential time. Bhattacharya et. al. (2021) used a variety of sampling techniques, but this is a heavyweight solution, and although the estimators they propose are doubly-robust, they still require fitting a number of intermediate linear models which carry undesirable parametric assumptions.\n",
    "\n",
    "Due to the complex tradeoffs between algorithms and difficulty of implementation, I have chosen to extend Brule (2018) and implement a brute-force solution. Brule's estimator relies on directly calculating the sums, and as such remains completely non parametric and is tractable for small number of variables. Brule assumes that all variables in the model are discrete, which is needed for the brute-force approach, so to extend to the continuous case I plan to use quantization.\n",
    "\n",
    "In addition to the computational difficulties, a further, slightly more subtle, difficulty has to do with the *positivity*. All useful estimators identified by ID will have conditional probability terms, and these remained defined only when the conditioning variable can be guaranteed to have positive probability in the model. Brule (2018) uses a maximum likelihood multinomial estimator, which does not guarantee positivity. To get around this issue, I use a Bayesian multinomial estimator with a Dirichlet prior, which does guarantee positivity.\n",
    "\n",
    "This estimator has been implemented, but during simulation testing I discovered a error that I have yet to debug. The code is available in the appendix, and I will have a demo in the next iteration of this report."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "\n",
    "The primary goals for this implementation were correctness, performance, and ease of use. In this section, I examine the library in light of each of these goals in turn."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correctness\n",
    "\n",
    "One of the main impetus for this project was to improve on the many correctness issues with existing implementations of the algorithm. To this end, I implemented a large number of tests. I used hand derived answers to test the algorithm on a number of famous examples (backdoor, frontdoor, IV, bowgraph). Then, I copied all of the other examples of identification from Shpitser's dissertation (Shpitser, 2008). He gives 15 examples of identifiable and nonidentifiable graphs, and I test the algorithm the on each of these examples."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Figure 5. Examples of identifiable graphs**\n",
    "\n",
    "![](2023-02-25-09-07-36.png)\n",
    "\n",
    "*This figure, taken from Shpitser (2008) shows several examples of identifiable graphs. My implementation recovers the correct estimator for each.*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To demonstrate typical output from the algorithm, I apply the algorithm to find estimators for each of these graphs. These estimators are shown below. The algorithm successfully recovers the estimator in each case. The only issue highlighted by this example is that the simplification routine still stuggles to achieve an acceptable outcome as graphs get larger. This is an area of active work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\textbf{Model a: } P(y | do(x)) = {P(x, y) \\over P(x)}$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\textbf{Model b: } P(y | do(x)) = \\sum_{z} \\big({P(z, y, x) \\over P(x)}\\big)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\textbf{Model c: } P(y | do(x)) = \\sum_{z} \\big({P(x, y, z) P(z) \\over P(x, z)}\\big)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\textbf{Model d: } P(y | do(x)) = \\sum_{z} \\big({P(z) P(z, y, x) \\over P(z, x)}\\big)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\textbf{Model e: } P(y | do(x)) = \\sum_{z} \\big({\\sum_{x} \\big({P(z, y, x) P(x) \\over P(z, x)}\\big) P(z, x) \\over P(x)}\\big)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\textbf{Model f: } P(y | do(x)) = \\sum_{z2, z1} \\big({\\sum_{x} \\big({P(z1, z2, x) P(x) \\over P(z1, x)}\\big) P(z1, z2, x, y) P(z1, x) \\over P(z1, z2, x) P(x)}\\big)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\textbf{Model g: } P(y | do(x)) = \\sum_{z3, z2, z1} \\big({\\sum_{z1, x} \\big({P(z3, y, z1, z2, x) P(z3, z2, x) \\over P(z3, z1, z2, x)}\\big) \\sum_{z1, z3, x, y} \\big({P(z3, y, z1, z2, x) P(z3, z2, x) \\over P(z3, z1, z2, x)}\\big) P(z3, z2) P(z1, z2, x) \\over \\sum_{z1, y, x} \\big({P(z3, y, z1, z2, x) P(z3, z2, x) \\over P(z3, z1, z2, x)}\\big) \\sum_{z3, z2, x, z1, y} \\big({P(z3, y, z1, z2, x) P(z3, z2, x) \\over P(z3, z1, z2, x)}\\big) P(z2) P(z2, x)}\\big)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Math\n",
    "from string import ascii_lowercase\n",
    "from supplement import g1, g2, g3, g4, g5, g6, g7, x, y\n",
    "\n",
    "for i, g in enumerate([g1, g2, g3, g4, g5, g6, g7]):\n",
    "    estimand = g.idc([y], [x])\n",
    "    display(Math(\"\\\\textbf{Model \" + ascii_lowercase[i] + \": } P(y | do(x)) = \" + estimand.to_latex()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, Shpitser (2008) supplies of a number of examples of nonidentifiable graphs. The algorithm correctly identifies these as nonidentifiable. The examples from Shpitser (2008), along with estimators derived by the algorithm, are shown below.\n",
    "\n",
    "**Figure 6. Examples of nonidentifiable graphs**\n",
    "\n",
    "![](2023-02-25-09-22-50.png)\n",
    "\n",
    "*This figure, taken from Shpitser (2008) shows several examples of nonidentifiable graphs. My implementation correctly identifies these as nonidentifiable.*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When run on each of these graphs, the algorithm successfully recovers a hedge, demonstrating non identifiability of each graph."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance\n",
    "\n",
    "To test to performance of the implementation, I am designing a set of benchmarks to compare it to other existing implementations. For these benchmanrks, I will randomly generated a large number of graphs with different properties. Then, I will time my algorithm at identifying these graphs."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ease of Use\n",
    "The Rust code underlying the library is extremely fast, but Rust is a language used by few in the causal inference community. To make the library more accessible, I created a Python library that wraps the Rust code. Although Python is definitely second to R in terms of adoption in the community, it is much more common among industrial practicioners.\n",
    "\n",
    "While the focus of the Rust implementation is correctness and performance, the focus of the Python bindings is on elegance and usability. I used Python's magic methods to create an API for specifying and querying causal models that is extremely simple and readable. I created a website with documentation for the python library, and I have published the library on PyPI.\n",
    "\n",
    "By utilizing Python's infix operators, I was able to create an API in which graphs can be created via an intuitive embedded syntax. It is possible to create a new causal model using the library in just a few lines. The `<=` operator creates a directed edge in the graph, while the `&` operator creates a bidirected edge. See the following example, which implements the front-door model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pqp.variable import make_vars\n",
    "from pqp.graph import Graph\n",
    "\n",
    "x, y, z = make_vars(\"xyz\")\n",
    "g = Graph([\n",
    "    z <= x,\n",
    "    y <= z,\n",
    "    x & y\n",
    "])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identification is accessed through a method, and several output formats are available. As demonstrated below, Latex is available inside Jupyter notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\sum_{z} \\big({\\sum_{x} \\big({P(x) P(x, z, y) \\over P(x, z)}\\big) P(x, z) \\over P(x)}\\big)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "estimand = g.idc([y], [x])\n",
    "estimand.display()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The library also supports visualization using the `networkx` library as an optional dependency. Although this feature is not entirely polished yet, it is useful to quickly visualize the model. Bidirected edges are indicated using a dashed line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "g.draw()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examples"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, I show how my code can be used to identify interventional distributions in two toy examples."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next Steps\n",
    "- prove Whittemore broken (simplification, nonpositivity)\n",
    "- randomly generated tests for correctness and benchmarking\n",
    "- educational materials\n",
    "- estimation code debug + quantization\n",
    "- more compelling motivation\n",
    "- end-to-end demo"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "Bhattacharya, R., Nabi, R., & Shpitser, I. (2021). Semiparametric Inference For Causal Effects In Graphical Models With Hidden Variables (arXiv:2003.12659). arXiv. http://arxiv.org/abs/2003.12659\n",
    "\n",
    "\n",
    "Breitling, L. P. (2010). dagR: A suite of R functions for directed acyclic graphs. Epidemiology (Cambridge, Mass.), 21(4), 586–587. https://doi.org/10.1097/EDE.0b013e3181e09112\n",
    "\n",
    "\n",
    "Brulé, J. (2018). Whittemore: An embedded domain specific language for causal programming (arXiv:1812.11918). arXiv. https://doi.org/10.48550/arXiv.1812.11918\n",
    "\n",
    "\n",
    "Efficiently Finding Conditional Instruments for Causal Inference. (n.d.). 7.\n",
    "Identification With Surrogates—Ananke-causal documentation. (n.d.). Retrieved October 3, 2022, from https://ananke.readthedocs.io/en/latest/notebooks/identification_surrogates.html\n",
    "\n",
    "\n",
    "Knüppel, S., & Stang, A. (2010). DAG program: Identifying minimal sufficient adjustment sets. Epidemiology (Cambridge, Mass.), 21(1), 159. https://doi.org/10.1097/EDE.0b013e3181c307ce\n",
    "\n",
    "\n",
    "Leslie Myint (Director). (2020, September 13). Estimating Causal Effects: Inverse Probability Weighting. https://www.youtube.com/watch?v=PfLYPt9ur4g\n",
    "\n",
    "\n",
    "Rice U ECE (Director). (2021, October 26). Prof. Ilya Shpitser | The Proximal ID Algorithm. https://www.youtube.com/watch?v=6nZslQafmYQ\n",
    "\n",
    "\n",
    "Sharma, A., & Kiciman, E. (2020). DoWhy: An End-to-End Library for Causal Inference (arXiv:2011.04216). arXiv. https://doi.org/10.48550/arXiv.2011.04216\n",
    "\n",
    "\n",
    "Shpitser, I. (2006). Identification of Joint Interventional Distributions in Recursive Semi-Markovian Causal Models. 8.\n",
    "\n",
    "\n",
    "Shpitser, I. (2008). Complete Identi cation Methods for Causal Inference. 114.\n",
    "\n",
    "\n",
    "Shpitser, I., & Pearl, J. (n.d.). Identiﬁcation of Conditional Interventional Distributions. 8.\n",
    "\n",
    "\n",
    "Shpitser, I., Richardson, T. S., & Robins, J. M. (2012). An Efficient Algorithm for Computing Interventional Distributions in Latent Variable Causal Models (arXiv:1202.3763). arXiv. https://doi.org/10.48550/arXiv.1202.3763\n",
    "\n",
    "\n",
    "Shpitser, I., & Sherman, E. (2018). Identification of Personalized Effects Associated With Causal Pathways. Uncertainty in Artificial Intelligence: Proceedings of the ... Conference. Conference on Uncertainty in Artificial Intelligence, 2018, 198.\n",
    "\n",
    "\n",
    "Shpitser, I., VanderWeele, T., & Robins, J. M. (2012). On the Validity of Covariate Adjustment for Estimating Causal Effects (arXiv:1203.3515). arXiv. https://doi.org/10.48550/arXiv.1203.3515\n",
    "\n",
    "\n",
    "Shpitser, I., Wood-Doughty, Z., & Tchetgen, E. J. T. (2021). The Proximal ID Algorithm (arXiv:2108.06818). arXiv. https://doi.org/10.48550/arXiv.2108.06818\n",
    "\n",
    "\n",
    "Textor, J., & Liskiewicz, M. (n.d.). Adjustment Criteria in Causal Diagrams: An Algorithmic Perspective. 8.\n",
    "\n",
    "\n",
    "Textor, J., van der Zander, B., Gilthorpe, M. S., Liśkiewicz, M., & Ellison, G. T. H. (2017). Robust causal inference using directed acyclic graphs: The R package ‘dagitty.’ International Journal of Epidemiology, dyw341. https://doi.org/10.1093/ije/dyw341\n",
    "\n",
    "\n",
    "Tian, J., & Pearl, J. (n.d.). A General Identiﬁcation Condition for Causal Effects. 7.\n",
    "\n",
    "\n",
    "Tikka, S., & Karvanen, J. (n.d.). Simplifying Probabilistic Expressions in Causal Inference. 30.\n",
    "Van der Zander, B., & Liskiewicz, M. (2016). Separators and Adjustment Sets in Markov Equivalent DAGs. Proceedings of the AAAI Conference on Artificial Intelligence, 30(1). https://doi.org/10.1609/aaai.v30i1.10424\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendices"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix 1: HC and LO Applications"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HC Applications"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#induction\n",
    "\n",
    "Structural causal modeling is all about principled approaches to induction. I carefully explain how inference is conceptualized within this framework, and I draw connections between the framework and predictions that result on actual datasets. I show a deep understanding of the nuances of inductive reasoning.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#algorithms\n",
    "\n",
    "\n",
    "I explain the tradeoffs between a number of approaches to identification. I carefully explain how each alternative works, and I provide a high-level overview of Shpitser’s identification algorithm. I use asymptotic complexity to characterize tradeoffs. I implement Shpitser’s identification algorithm.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#variables\n",
    "\n",
    "I carefully handle distinctions between treatment, outcome, and control variables. I provide a subtle discussion of the relationships between treatment and outcome variables in the structural causal modeling framework. I explain how treatment variables in a causal estimand may be converted to control variables or excluded via identification.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#probability\n",
    "\n",
    "I show a deep understanding of probabilistic expressions and how they can be manipulated via the two rules of probability. I show how an extension to the basic logic of probability (do-expressions) can be incorporated into probabilistic reasoning."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#deduction\n",
    "\n",
    "The do-calculus is a framework for using formal mathematics to reason about the very hairy and complex inductive problem of causal inference. I present the key intuitions behind the do-calculus, and then leverage an algorithm based on the do-calculus to perform identification. In addition, I make use of mathematical reasoning to prove a number of small supporting points."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#organization\n",
    "\n",
    "\n",
    "Structural causal modeling is a complex framework for reasoning about inductive reasoning. I break down this highly complex and interconnected topic into a series of short digestible insights, each of which I present in a subsection. I present the idea in an order which allows the reader to build an intuition for the field.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#professionalism\n",
    "\n",
    "\n",
    "For the final project, I will reformat this report using Latex.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#composition\n",
    "\n",
    "I explain a complex, technically rigorous topic in a way that is accessible to someone educated in mathematics or computer science. I carefully handle jargon—using it only when necessary and being careful to define my terms. I condense most of the information I have learned over the course of a year-long literature review into 8 pages of background information. I balance concision with clarity in a highly difficult explanation."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#regression\n",
    "\n",
    "\n",
    "I explain how regression modeling (under the name estimation) fits into the framework of structural causal modeling. I show a deep understanding of the role of regression in larger causal inference through my explanation of the role of abstract statistical estimators. For the final capstone, I will implement a regressions model to estimate causal effects, using abstract estimators derived from my implementation of identification.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#correlation\n",
    "\n",
    "\n",
    "Rather than referring to correlation directly, I discuss the more general notion of statistical estimation. I explain how association in the joint distribution of a dataset relates to d-separation and live paths in the causal model. I explain how statistical association can change as a result of conditioning, and I present a complete account (based on Pearl’s work) of when this occurs.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#sampling\n",
    "\n",
    "\n",
    "All of the difficulties of observational research fundamentally result from biased samples. In the final deliverable, I will explain how sampling bias in a real dataset can be controlled for using structural causal models."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#observationalstudy\n",
    "\n",
    "\n",
    "I implement a complex software library aimed to help researchers working with observational data. I show a deep understanding of the pitfalls of observational research through my explanation of confounding and collider bias. I explain how identification can be used to remove biases from estimation of causal effects.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#modeling\n",
    "\n",
    "\n",
    "I show a deeply researched and incredibly rigorous understanding of the structural causal modeling approach to causal inference. I explain how the “moving parts” of the model relate to changes in its predictions for the data. I implement a tool to aid in using structural causal modeling on real data.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#comparisongroups\n",
    "\n",
    "\n",
    "In observational research, proper control groups are rarely available. The marginalization and control operations called for in the abstract estimator returned from identification can be interpreted as reweighting and excluding existing data in a way that synthetically generates a proper control group from available data. I will develop this analogy further in the final deliverable.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LO Applications"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#search\n",
    "\n",
    "\n",
    "Deriving an abstract estimator using the do-calculus is fundamentally a search problem. I explain the workings of two approaches to solving this problem: adjustment set search, which relies on backtracking, and Shpitser’s identification algorithm, which can be interpreted as a dynamic programming solution. I will further develop these connections in the final deliverable.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#datamodel\n",
    "\n",
    "\n",
    "I provide an explanation of structural causal modeling which demonstrates deep understanding. I provide extensive discussion of benefits and pitfalls. I implement a challenging subroutine of the structural causal modeling workflow. For the final deliverable, I will apply structural causal modeling (and my code) to a data analysis.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#quantprofessionalism\n",
    "\n",
    "\n",
    "For the final deliverable, I will format this report using latex, following conventional guidelines for the reporting of figures. I will make my code available as a well-formatted and commented GitHub repository.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#numimplementation\n",
    "\n",
    "\n",
    "For the final project, a stretch goal is to implement estimation. This is a classic numerical algorithm, where issues of convergence, numerical precision, and iterative solving will come into play.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Capstone LO Applications"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- #qualitydeliverables\n",
    "- #curation\n",
    "- #navigation\n",
    "- #outcomeanalysis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix 2: Documentation\n",
    "\n",
    "This appendix contains documentation which can be found on the project website. I present it here as work compelted towards the project"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Landing Page\n",
    "\n",
    "![](2023-02-26-04-04-18.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quickstart Guide\n",
    "\n",
    "![](2023-02-26-04-04-52.png)\n",
    "![](2023-02-26-04-05-15.png)\n",
    "![](2023-02-26-04-05-29.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expression Module Documentation\n",
    "\n",
    "![](2023-02-26-04-06-16.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph Module Documentation\n",
    "\n",
    "![](2023-02-26-04-06-43.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variable Module Documentation\n",
    "\n",
    "![](2023-02-26-04-07-22.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submodule Documentation\n",
    "\n",
    "![](2023-02-26-04-07-57.png)\n",
    "![](2023-02-26-04-08-12.png)\n",
    "![](2023-02-26-04-08-27.png)\n",
    "![](2023-02-26-04-08-47.png)\n",
    "![](2023-02-26-04-09-02.png)\n",
    "![](2023-02-26-04-09-16.png)\n",
    "![](2023-02-26-04-09-29.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix 3: Code"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimation Code (In Progress)\n",
    "\n",
    "This is experimental code that I wrote for use in estimation. It is still somewhat buggy, but it demonstrates the direction of the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\sum_{z} \\big({\\sum_{x} \\big({P(z, y, x) P(x) \\over P(z, x)}\\big) P(z, x) \\over P(x)}\\big)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pqp.variable import make_vars, Variable\n",
    "from pqp.graph import Graph\n",
    "from pqp.expression import Expression, Marginal, P, Product, Quotient\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "x, y, z = make_vars(\"xyz\")\n",
    "g = Graph([\n",
    "    z <= x,\n",
    "    y <= z,\n",
    "    x & y\n",
    "])\n",
    "estimand = g.idc([y], [x])\n",
    "estimand.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "I = object()\n",
    "def p(*args):\n",
    "    acc = vars = []\n",
    "    given = []\n",
    "    for arg in args:\n",
    "        if arg is I:\n",
    "            acc = given\n",
    "        elif not isinstance(arg, Variable):\n",
    "            raise ValueError(\"Expected Variable\")\n",
    "        else:\n",
    "            acc.append(arg)\n",
    "    return P(vars, given)\n",
    "\n",
    "V = Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class attrdict(dict):\n",
    "    def __getattr__(self, key):\n",
    "        return self[key]\n",
    "\n",
    "class CategoricalDistribution:\n",
    "    def __init__(self, data, observed=None, prior=5):\n",
    "        self.data = data\n",
    "        self.n = data.shape[0]\n",
    "        self.vars = attrdict({col: V(col) for col in data.columns})\n",
    "\n",
    "        observed = observed or list(data.columns)\n",
    "        domain = 1\n",
    "        for obs in observed:\n",
    "            domain *= len(np.unique(data[obs]))\n",
    "        prior_observations = domain * prior\n",
    "\n",
    "        self.chance_prior = prior_observations / (self.n + prior_observations)\n",
    "        self.prior = self.chance_prior / domain\n",
    "    \n",
    "    def approx_p(self, expr: P, context):\n",
    "        data = self.data\n",
    "        for cond in expr.given:\n",
    "            data = data[data[cond.name] == context[cond.name]]\n",
    "\n",
    "        mask = np.ones(data.shape[0], dtype=bool)\n",
    "        for var in expr.vars:\n",
    "            if var.name not in context:\n",
    "                raise ValueError(f\"Missing context for {var.__repr__()}\")\n",
    "            mod = data[var.name] == context[var.name]\n",
    "            mask = mask & mod\n",
    "                \n",
    "        return (mask.sum() / data.shape[0])*(1-self.chance_prior) + self.prior\n",
    "    \n",
    "    def approx_marginal(self, expr: Marginal, context):\n",
    "        acc = 0\n",
    "        if expr.sub:\n",
    "            summation_var = expr.sub[0].name\n",
    "            expr = expr.expr if len(expr.sub) == 1 else Marginal(expr.sub[1:], expr.expr)\n",
    "            for val in np.unique(self.data[summation_var]):\n",
    "                acc += self.approx(expr, {summation_var: val, **context})\n",
    "        return acc\n",
    "    \n",
    "    def approx_product(self, expr: Product, context):\n",
    "        acc = 1\n",
    "        for e in expr.expr:\n",
    "            acc *= self.approx(e, context)\n",
    "        return acc\n",
    "    \n",
    "    def approx_quotient(self, expr: Quotient, context):\n",
    "        return self.approx(expr.numer, context) / self.approx(expr.denom, context)\n",
    "\n",
    "    def approx(self, expr, context = None):\n",
    "        context = context or {}\n",
    "        if isinstance(expr, P):\n",
    "            res = self.approx_p(expr, context)\n",
    "        elif isinstance(expr, Marginal):\n",
    "            res = self.approx_marginal(expr, context)\n",
    "        elif isinstance(expr, Product):\n",
    "            res = self.approx_product(expr, context)\n",
    "        elif isinstance(expr, Quotient):\n",
    "            res = self.approx_quotient(expr, context)\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported expression type: {}\".format(type(expr)))\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 1 1 0 1 1 0 1 0]\n",
      "[1 0 0 0 0 0 0 0 0 0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>severity</th>\n",
       "      <th>treatment</th>\n",
       "      <th>pathway</th>\n",
       "      <th>outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   severity  treatment  pathway  outcome\n",
       "0         3          0        0        3\n",
       "1         0          0        0        0\n",
       "2         2          1       -1        1\n",
       "3         2          1       -1        1\n",
       "4         1          0        0        1\n",
       "5         2          1       -1        1\n",
       "6         3          1       -1        2\n",
       "7         0          0        0        0\n",
       "8         2          1       -1        1\n",
       "9         1          0        0        1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(137)\n",
    "n = 10\n",
    "\n",
    "severity = np.random.binomial(3, 0.5, size=n)\n",
    "doctor_noise = np.random.binomial(1, 0.1, size=n)\n",
    "print((severity > 1).astype(int))\n",
    "print(doctor_noise)\n",
    "treatment = ((severity > 1) != doctor_noise).astype(int)\n",
    "\n",
    "# print(treatment)\n",
    "\n",
    "pathway_predisposition = 0# np.random.binomial(2, 0.5, size=n)\n",
    "pathway = pathway_predisposition - treatment\n",
    "\n",
    "outcome_noise = 0#np.random.binomial(2, 0.5, size=n)\n",
    "outcome = pathway + severity + outcome_noise\n",
    "\n",
    "model_vars = {}\n",
    "for name in [\"severity\", \"treatment\", \"pathway\", \"outcome\"]:\n",
    "    model_vars[name] = Variable(name)\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"severity\": severity,\n",
    "    \"treatment\": treatment,\n",
    "    \"pathway\": pathway,\n",
    "    \"outcome\": outcome,\n",
    "})\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "treat outcome: 1.2\n",
      "control outcome: 1.0\n",
      "treatment effect (naive): 0.19999999999999996\n"
     ]
    }
   ],
   "source": [
    "treat_outcome = df.outcome[df.treatment == 1].mean()\n",
    "control_outcome = df.outcome[df.treatment == 0].mean()\n",
    "\n",
    "print(f\"treat outcome: {treat_outcome}\")\n",
    "print(f\"control outcome: {control_outcome}\")\n",
    "print(f\"treatment effect (naive): {treat_outcome - control_outcome}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self, dist, graph):\n",
    "        self.dist = dist\n",
    "        self.graph = graph\n",
    "    \n",
    "    def estimand(self, y, x=None, z=None):\n",
    "        if x == None:\n",
    "            x = []\n",
    "        if z == None:\n",
    "            z = []\n",
    "        return self.graph.idc(y=[V(y)], x=[V(i) for i in x], z=[V(i) for i in z])\n",
    "    \n",
    "    def expectation(self, var, do=None, given=None):\n",
    "        do = do or {}\n",
    "        given = given or {}\n",
    "        estimand = self.estimand(var, do.keys(), given.keys())\n",
    "\n",
    "        acc = 0\n",
    "        prob_acc = 0\n",
    "        for val in np.unique(dist.data[var]):\n",
    "            prob = self.dist.approx(estimand, {var: val, **do, **given})\n",
    "            prob_acc += 1\n",
    "            acc += prob * val\n",
    "            print(prob, val)\n",
    "        \n",
    "        if abs(prob_acc - 1) > 1e-6:\n",
    "            raise Exception(f\"Probabilities do not sum to 1 (eps ~= {abs(prob_acc - 1)})\")\n",
    "\n",
    "        return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.015748031496062992\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\sum_{pathway} \\big({\\sum_{treatment} \\big({P(pathway, outcome, treatment) P(treatment) \\over P(pathway, treatment)}\\big) P(pathway, treatment) \\over P(treatment)}\\big)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.39763779527559057 0\n",
      "0.39763779527559057 1\n",
      "0.003937007874015748 2\n",
      "0.20078740157480315 3\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Probabilities do not sum to 1 (eps ~= 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[39mprint\u001b[39m(dist\u001b[39m.\u001b[39mchance_prior)\n\u001b[1;32m     12\u001b[0m model\u001b[39m.\u001b[39mestimand(\u001b[39m\"\u001b[39m\u001b[39moutcome\u001b[39m\u001b[39m\"\u001b[39m, [\u001b[39m\"\u001b[39m\u001b[39mtreatment\u001b[39m\u001b[39m\"\u001b[39m])\u001b[39m.\u001b[39mdisplay()\n\u001b[0;32m---> 14\u001b[0m outcome_control \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mexpectation(\u001b[39m\"\u001b[39;49m\u001b[39moutcome\u001b[39;49m\u001b[39m\"\u001b[39;49m, do\u001b[39m=\u001b[39;49m{\u001b[39m\"\u001b[39;49m\u001b[39mtreatment\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m0\u001b[39;49m})\n\u001b[1;32m     15\u001b[0m outcome_treat \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mexpectation(\u001b[39m\"\u001b[39m\u001b[39moutcome\u001b[39m\u001b[39m\"\u001b[39m, do\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mtreatment\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m1\u001b[39m})\n\u001b[1;32m     16\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtreat outcome: \u001b[39m\u001b[39m{\u001b[39;00moutcome_treat\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[7], line 27\u001b[0m, in \u001b[0;36mModel.expectation\u001b[0;34m(self, var, do, given)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[39mprint\u001b[39m(prob, val)\n\u001b[1;32m     26\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mabs\u001b[39m(prob_acc \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m) \u001b[39m>\u001b[39m \u001b[39m1e-6\u001b[39m:\n\u001b[0;32m---> 27\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mException\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mProbabilities do not sum to 1 (eps ~= \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mabs\u001b[39m(prob_acc\u001b[39m \u001b[39m\u001b[39m-\u001b[39m\u001b[39m \u001b[39m\u001b[39m1\u001b[39m)\u001b[39m}\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     29\u001b[0m \u001b[39mreturn\u001b[39;00m acc\n",
      "\u001b[0;31mException\u001b[0m: Probabilities do not sum to 1 (eps ~= 3)"
     ]
    }
   ],
   "source": [
    "prior = 0.01\n",
    "\n",
    "dist = CategoricalDistribution(df, observed=[\"treatment\", \"outcome\", \"pathway\"], prior=prior)\n",
    "graph = Graph([\n",
    "    dist.vars.pathway <= dist.vars.treatment,\n",
    "    dist.vars.outcome <= dist.vars.pathway,\n",
    "    dist.vars.outcome & dist.vars.treatment,\n",
    "])\n",
    "model = Model(dist, graph)\n",
    "\n",
    "print(dist.chance_prior)\n",
    "model.estimand(\"outcome\", [\"treatment\"]).display()\n",
    "\n",
    "outcome_control = model.expectation(\"outcome\", do={\"treatment\": 0})\n",
    "outcome_treat = model.expectation(\"outcome\", do={\"treatment\": 1})\n",
    "print(f\"treat outcome: {outcome_treat}\")\n",
    "print(f\"control outcome: {outcome_control}\")\n",
    "print(f\"treatment effect (my model): {outcome_treat - outcome_control}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.015748031496062992\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\sum_{pathway} \\big({\\sum_{treatment} \\big({P(pathway, outcome, treatment) P(treatment) \\over P(pathway, treatment)}\\big) P(pathway, treatment) \\over P(treatment)}\\big)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.39763779527559057 0\n",
      "0.39763779527559057 1\n",
      "0.003937007874015748 2\n",
      "0.20078740157480315 3\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Probabilities do not sum to 1 (eps ~= 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[39mprint\u001b[39m(dist\u001b[39m.\u001b[39mchance_prior)\n\u001b[1;32m     10\u001b[0m model\u001b[39m.\u001b[39mestimand(\u001b[39m\"\u001b[39m\u001b[39moutcome\u001b[39m\u001b[39m\"\u001b[39m, [\u001b[39m\"\u001b[39m\u001b[39mtreatment\u001b[39m\u001b[39m\"\u001b[39m])\u001b[39m.\u001b[39mdisplay()\n\u001b[0;32m---> 12\u001b[0m outcome_control \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mexpectation(\u001b[39m\"\u001b[39;49m\u001b[39moutcome\u001b[39;49m\u001b[39m\"\u001b[39;49m, do\u001b[39m=\u001b[39;49m{\u001b[39m\"\u001b[39;49m\u001b[39mtreatment\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m0\u001b[39;49m})\n\u001b[1;32m     13\u001b[0m outcome_treat \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mexpectation(\u001b[39m\"\u001b[39m\u001b[39moutcome\u001b[39m\u001b[39m\"\u001b[39m, do\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mtreatment\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m1\u001b[39m})\n\u001b[1;32m     14\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtreat outcome: \u001b[39m\u001b[39m{\u001b[39;00moutcome_treat\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[7], line 27\u001b[0m, in \u001b[0;36mModel.expectation\u001b[0;34m(self, var, do, given)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[39mprint\u001b[39m(prob, val)\n\u001b[1;32m     26\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mabs\u001b[39m(prob_acc \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m) \u001b[39m>\u001b[39m \u001b[39m1e-6\u001b[39m:\n\u001b[0;32m---> 27\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mException\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mProbabilities do not sum to 1 (eps ~= \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mabs\u001b[39m(prob_acc\u001b[39m \u001b[39m\u001b[39m-\u001b[39m\u001b[39m \u001b[39m\u001b[39m1\u001b[39m)\u001b[39m}\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     29\u001b[0m \u001b[39mreturn\u001b[39;00m acc\n",
      "\u001b[0;31mException\u001b[0m: Probabilities do not sum to 1 (eps ~= 3)"
     ]
    }
   ],
   "source": [
    "dist = CategoricalDistribution(df, observed=[\"treatment\", \"outcome\", \"pathway\"], prior=prior)\n",
    "graph = Graph([\n",
    "    dist.vars.pathway <= dist.vars.treatment,\n",
    "    dist.vars.outcome <= dist.vars.pathway,\n",
    "    dist.vars.outcome & dist.vars.treatment,\n",
    "])\n",
    "model = Model(dist, graph)\n",
    "\n",
    "print(dist.chance_prior)\n",
    "model.estimand(\"outcome\", [\"treatment\"]).display()\n",
    "\n",
    "outcome_control = model.expectation(\"outcome\", do={\"treatment\": 0})\n",
    "outcome_treat = model.expectation(\"outcome\", do={\"treatment\": 1})\n",
    "print(f\"treat outcome: {outcome_treat}\")\n",
    "print(f\"control outcome: {outcome_control}\")\n",
    "print(f\"treatment effect (my model): {outcome_treat - outcome_control}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.015748031496062992\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\sum_{severity} \\big({P(severity) P(severity, outcome, treatment) \\over P(severity, treatment)}\\big)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5917808824395704 0\n",
      "0.5917808824395704 1\n",
      "0.394930488738783 2\n",
      "0.5915354330708662 3\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Probabilities do not sum to 1 (eps ~= 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[39mprint\u001b[39m(dist\u001b[39m.\u001b[39mchance_prior)\n\u001b[1;32m     12\u001b[0m model\u001b[39m.\u001b[39mestimand(\u001b[39m\"\u001b[39m\u001b[39moutcome\u001b[39m\u001b[39m\"\u001b[39m, [\u001b[39m\"\u001b[39m\u001b[39mtreatment\u001b[39m\u001b[39m\"\u001b[39m])\u001b[39m.\u001b[39mdisplay()\n\u001b[0;32m---> 14\u001b[0m outcome_control \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mexpectation(\u001b[39m\"\u001b[39;49m\u001b[39moutcome\u001b[39;49m\u001b[39m\"\u001b[39;49m, do\u001b[39m=\u001b[39;49m{\u001b[39m\"\u001b[39;49m\u001b[39mtreatment\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m0\u001b[39;49m})\n\u001b[1;32m     15\u001b[0m outcome_treat \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mexpectation(\u001b[39m\"\u001b[39m\u001b[39moutcome\u001b[39m\u001b[39m\"\u001b[39m, do\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mtreatment\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m1\u001b[39m})\n\u001b[1;32m     16\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtreat outcome: \u001b[39m\u001b[39m{\u001b[39;00moutcome_treat\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[7], line 27\u001b[0m, in \u001b[0;36mModel.expectation\u001b[0;34m(self, var, do, given)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[39mprint\u001b[39m(prob, val)\n\u001b[1;32m     26\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mabs\u001b[39m(prob_acc \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m) \u001b[39m>\u001b[39m \u001b[39m1e-6\u001b[39m:\n\u001b[0;32m---> 27\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mException\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mProbabilities do not sum to 1 (eps ~= \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mabs\u001b[39m(prob_acc\u001b[39m \u001b[39m\u001b[39m-\u001b[39m\u001b[39m \u001b[39m\u001b[39m1\u001b[39m)\u001b[39m}\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     29\u001b[0m \u001b[39mreturn\u001b[39;00m acc\n",
      "\u001b[0;31mException\u001b[0m: Probabilities do not sum to 1 (eps ~= 3)"
     ]
    }
   ],
   "source": [
    "dist = CategoricalDistribution(df, prior=prior/4)\n",
    "graph = Graph([\n",
    "    # dist.vars.pathway <= dist.vars.treatment,\n",
    "    # dist.vars.outcome <= dist.vars.pathway,\n",
    "    dist.vars.outcome <= dist.vars.treatment,\n",
    "    dist.vars.treatment <= dist.vars.severity,\n",
    "    dist.vars.outcome <= dist.vars.severity,\n",
    "])\n",
    "model = Model(dist, graph)\n",
    "\n",
    "print(dist.chance_prior)\n",
    "model.estimand(\"outcome\", [\"treatment\"]).display()\n",
    "\n",
    "outcome_control = model.expectation(\"outcome\", do={\"treatment\": 0})\n",
    "outcome_treat = model.expectation(\"outcome\", do={\"treatment\": 1})\n",
    "print(f\"treat outcome: {outcome_treat}\")\n",
    "print(f\"control outcome: {outcome_control}\")\n",
    "print(f\"treatment effect (god): {outcome_treat - outcome_control}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python Library\n",
    "\n",
    "This is the code from the Python library. It has the following structure.\n",
    "\n",
    "- `pqp`\n",
    "    - `__init__.py`\n",
    "    - `expression.py`\n",
    "    - `graph.py`\n",
    "    - `utils.py`\n",
    "    - `variable.py`\n",
    "    - `tests`\n",
    "        - `test_pqp.py`\n",
    "        - `test_variable.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# __init__.py\n",
    "\n",
    "import pqp.graph\n",
    "import pqp.expression\n",
    "import pqp.variable\n",
    "import pqp.utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# expression.py\n",
    "\n",
    "import json\n",
    "\n",
    "def parse_json(exp):\n",
    "    \"\"\"Parses JSON returned from backend.id() into an Expression object.\n",
    "\n",
    "    Args:\n",
    "        exp (str or dict): The JSON string or parsed JSON object.\n",
    "    \n",
    "    Returns:\n",
    "        Expression: The parsed expression.\n",
    "    \"\"\"\n",
    "    from pqp.variable import Variable\n",
    "\n",
    "    if isinstance(exp, str):\n",
    "        return parse_json(json.loads(exp))\n",
    "\n",
    "    if exp[\"type\"] == \"Quotient\":\n",
    "        return Quotient(\n",
    "            parse_json(exp[\"numer\"]),\n",
    "            parse_json(exp[\"denom\"]),\n",
    "        )\n",
    "    elif exp[\"type\"] == \"Product\":\n",
    "        return Product(\n",
    "            [parse_json(e) for e in exp[\"exprs\"]],\n",
    "        )\n",
    "    elif exp[\"type\"] == \"Marginal\":\n",
    "        return Marginal(\n",
    "            [Variable(x) for x in exp[\"sub\"]],\n",
    "            parse_json(exp[\"exp\"]),\n",
    "        )\n",
    "    elif exp[\"type\"] == \"Hedge\":\n",
    "        return Hedge()\n",
    "    elif exp[\"type\"] == \"P\":\n",
    "        return P(\n",
    "            [Variable(e) for e in exp[\"vars\"]],\n",
    "            [Variable(e) for e in exp[\"given\"]],\n",
    "        )\n",
    "    else:\n",
    "        raise Exception(\"Unknown expression type: \" + exp[\"type\"])\n",
    "\n",
    "class Expression:\n",
    "    \"\"\"Base class for all expressions.\n",
    "    \n",
    "    The primary use of Expression is to represent the results of identification. However,\n",
    "    Expressions can be constructed from Variables and other Expressions. Using the\n",
    "    infix `/` and `*` operators.\n",
    "\n",
    "    Examples:\n",
    "        >>> from pqp.variable import make_vars\n",
    "        >>> x, y = make_vars(\"xy\")\n",
    "        >>> x / y\n",
    "        Quotient(Variable(x), Variable(y))\n",
    "        >>> x * y\n",
    "        Product([Variable(x), Variable(y)])\n",
    "    \n",
    "    Expressions can be represented in a number of different ways.\n",
    "        - `__repr__` returns an unambiguous representation of the expression\n",
    "        - `__str__` returns a human-readable (ascii, symbolic) representation\n",
    "        - `to_latex` returns a Latex representation of the expression\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    def display(self):\n",
    "        \"\"\"Renders an expression as Latex using IPython.display\"\"\"\n",
    "        from IPython.display import display, Math\n",
    "        return display(Math(self.to_latex()))\n",
    "    \n",
    "    def syntactic_eq(self, other):\n",
    "        \"\"\"Test whether two Expressions are syntactically identical (structural compare without sorting first)\"\"\"\n",
    "        raise NotImplementedError()\n",
    "    \n",
    "    def sorted(self):\n",
    "        \"\"\"Returns a sorted copy of an expression for structural comparison.\"\"\"\n",
    "        raise NotImplementedError()\n",
    "    \n",
    "    def __eq__(self, other):\n",
    "        \"\"\"Returns True if two expressions are structurally equivalent.\"\"\"\n",
    "        if not isinstance(other, Expression):\n",
    "            return False\n",
    "        return self.sorted().syntactic_eq(other.sorted())\n",
    "    \n",
    "    def to_latex(self):\n",
    "        \"\"\"Returns the Latex representation of an expression.\"\"\"\n",
    "        raise NotImplementedError()\n",
    "    \n",
    "    def __truediv__(self, other):\n",
    "        \"\"\"Returns a Quotient of the expressions.\"\"\"\n",
    "        if isinstance(other, Expression):\n",
    "            return Quotient(self, other)\n",
    "        else:\n",
    "            raise TypeError(\"Cannot divide by non-expression\")\n",
    "    \n",
    "    def __mul__(self, other):\n",
    "        \"\"\"Returns a Product of the expressions.\"\"\"\n",
    "        if isinstance(other, Expression):\n",
    "            return Product([self, other])\n",
    "        else:\n",
    "            raise TypeError(\"Cannot multiply by non-expression\")\n",
    "\n",
    "class Quotient(Expression):\n",
    "    \"\"\"Represents a quotient of expressions\n",
    "\n",
    "    Args:\n",
    "        numer (Expression): The numerator\n",
    "        denom (Expression): The denominator\n",
    "    \"\"\"\n",
    "    def __init__(self, numer, denom):\n",
    "        if not isinstance(numer, Expression):\n",
    "            raise TypeError(\"numerator must be an Expression\")\n",
    "        if not isinstance(denom, Expression):\n",
    "            raise TypeError(\"denominator must be an Expression\")\n",
    "        \n",
    "        self.numer = numer\n",
    "        self.denom = denom\n",
    "    \n",
    "    def syntactic_eq(self, other):\n",
    "        return (\n",
    "            isinstance(other, Quotient) and\n",
    "            self.numer == other.numer and\n",
    "            self.denom == other.denom\n",
    "        )\n",
    "    \n",
    "    def sorted(self):\n",
    "        return Quotient(self.numer.sorted(), self.denom.sorted())\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"Quotient({repr(self.numer)}, {repr(self.denom)})\"\n",
    "    \n",
    "    def __str__(self):\n",
    "        return \"[%s / %s]\" % (str(self.numer), str(self.denom))\n",
    "    \n",
    "    def to_latex(self):\n",
    "        return \"{\" + self.numer.to_latex() + \" \\\\over \" + self.denom.to_latex() + \"}\"\n",
    "\n",
    "class Product(Expression):\n",
    "    \"\"\"Represents a product of expressions\n",
    "\n",
    "    Args:\n",
    "        expr (list of Expression): The expressions to multiply\n",
    "    \"\"\"\n",
    "    def __init__(self, expr):\n",
    "        if not isinstance(expr, list):\n",
    "            expr = list(expr)\n",
    "        for e in expr:\n",
    "            if not isinstance(e, Expression):\n",
    "                raise TypeError(\"Product must be a list of Expressions\")\n",
    "        \n",
    "        self.expr = expr\n",
    "    \n",
    "    def syntactic_eq(self, other):\n",
    "        return (\n",
    "            isinstance(other, Product) and\n",
    "            self.expr == other.expr\n",
    "        )\n",
    "    \n",
    "    def sorted(self):\n",
    "        return Product(sorted([e.sorted() for e in self.expr], key=str))\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"Product({[repr(e) for e in self.expr]})\"\n",
    "    \n",
    "    def __str__(self):\n",
    "        return \" * \".join([str(e) for e in self.expr])\n",
    "    \n",
    "    def to_latex(self):\n",
    "        return \" \".join([e.to_latex() for e in self.expr])\n",
    "\n",
    "class Marginal(Expression):\n",
    "    \"\"\"Represents a sum\n",
    "\n",
    "    Args:\n",
    "        sub (list of Variable): The variables to sum over\n",
    "        expr (Expression): The expression to sum\n",
    "    \"\"\"\n",
    "    def __init__(self, sub, expr):\n",
    "        from pqp.variable import Variable\n",
    "\n",
    "        if not isinstance(expr, Expression):\n",
    "            raise TypeError(\"Marginal must be a list of Expressions\")\n",
    "        if isinstance(sub, Variable):\n",
    "            sub = [sub]\n",
    "        elif not isinstance(sub, list):\n",
    "            sub = list(sub)\n",
    "        for s in sub:\n",
    "            if not isinstance(s, Variable):\n",
    "                raise TypeError(\"Marginal must be a list of Variables\")\n",
    "\n",
    "        self.sub = sub\n",
    "        self.expr = expr\n",
    "    \n",
    "    def sorted(self):\n",
    "        return Marginal(sorted(self.sub), self.expr.sorted())\n",
    "    \n",
    "    def syntactic_eq(self, other):\n",
    "        return (\n",
    "            isinstance(other, Marginal) and\n",
    "            self.sub == other.sub and\n",
    "            self.expr == other.expr\n",
    "        )\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"Marginal({self.sub}, {repr(self.expr)})\"\n",
    "    \n",
    "    def __str__(self):\n",
    "        return \"Σ_(%s) [ %s ]\" % (\", \".join(str(c) for c in self.sub), str(self.expr))\n",
    "    \n",
    "    def to_latex(self):\n",
    "        return (\n",
    "            \"\\\\sum_{\" + \", \".join(c.to_latex() for c in self.sub) + \"} \\\\big(\" +\n",
    "            self.expr.to_latex()\n",
    "            + \"\\\\big)\")\n",
    "\n",
    "class P(Expression):\n",
    "    \"\"\"Expression representing a probability or conditional probability\n",
    "\n",
    "    Args:\n",
    "        vars (list of Variable): probability variables\n",
    "        given (list of Variable): conditioned variables\n",
    "    \"\"\"\n",
    "    def __init__(self, vars, given=None):\n",
    "        from pqp.variable import Variable\n",
    "\n",
    "        if not isinstance(vars, list):\n",
    "            vars = list(vars)\n",
    "        for v in vars:\n",
    "            if not isinstance(v, Variable):\n",
    "                raise TypeError(\"vars must be a list of Variables\")\n",
    "        \n",
    "        if given is not None:\n",
    "            if not isinstance(given, list):\n",
    "                given = list(given)\n",
    "            for g in given:\n",
    "                if not isinstance(g, Variable):\n",
    "                    raise TypeError(\"given must be a list of Variables\")\n",
    "        \n",
    "        self.vars = vars\n",
    "        self.given = given or []\n",
    "    \n",
    "    def sorted(self):\n",
    "        return P(\n",
    "            sorted(self.vars, key=lambda v: v.name),\n",
    "            sorted(self.given, key=lambda v: v.name)\n",
    "            )\n",
    "    \n",
    "    def __str__(self):\n",
    "        v = \", \".join(str(c) for c in self.vars)\n",
    "        g = \", \".join(str(c) for c in self.given)\n",
    "        if not v:\n",
    "            return \"1\"\n",
    "        return \"P(\" + v + (f\"| {g}\" if g else \"\") + \")\"\n",
    "    \n",
    "    def syntactic_eq(self, other):\n",
    "        return (\n",
    "            isinstance(other, P) and\n",
    "            self.vars == other.vars and\n",
    "            self.given == other.given\n",
    "        )\n",
    "    \n",
    "    def __repr__(self):\n",
    "        if self.given:\n",
    "            return f\"P({self.vars} | {self.given})\"\n",
    "        else:\n",
    "            return f\"P({self.vars})\"\n",
    "    \n",
    "    def to_latex(self):\n",
    "        v = \", \".join(c.to_latex() for c in self.vars)\n",
    "        g = \", \".join(c.to_latex() for c in self.given)\n",
    "        if not v:\n",
    "            return \"1\"\n",
    "        return \"P(\" + v + (f\" \\\\mid {g}\" if g else \"\") + \")\"\n",
    "\n",
    "class Hedge(Expression):\n",
    "    \"\"\"Represents a failure to identify the query\"\"\"\n",
    "    def syntactic_eq(self, other):\n",
    "        return isinstance(other, Hedge)\n",
    "    \n",
    "    def sorted(self):\n",
    "        return self\n",
    "    \n",
    "    def __str__(self):\n",
    "        return \"FAIL\"\n",
    "    \n",
    "    def to_latex(self):\n",
    "        return \"\\\\textbf{FAIL}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph.py\n",
    "\n",
    "from pqp.expression import parse_json\n",
    "from pqp.variable import Variable\n",
    "from pqp.pqp import id\n",
    "import json\n",
    "\n",
    "class Graph:\n",
    "    \"\"\"A causal graph\n",
    "    \n",
    "    Example:\n",
    "        >>> x = Variable(\"X\")\n",
    "        >>> y = Variable(\"Y\")\n",
    "        >>> g = Graph([\n",
    "        ...     y <= x,\n",
    "        ... ])\n",
    "        >>> g.idc([y], [x])\n",
    "        P(y | x)\n",
    "    \n",
    "    Args:\n",
    "        edges (list of DirectedEdge or BidirectedEdge): the edges in the graph\n",
    "    \"\"\"\n",
    "    def __init__(self, edges=[]):\n",
    "        self.bi_edges = []\n",
    "        self.directed_edges = []\n",
    "        self.add_edges(edges)\n",
    "    \n",
    "    def add_edges(self, edges):\n",
    "        while edges:\n",
    "            edge = edges.pop()\n",
    "            if isinstance(edge, BidirectedEdge) or isinstance(edge, DirectedEdge):\n",
    "                self.add_edge(edge)\n",
    "            elif isinstance(edge, list):\n",
    "                edges.extend(edge)\n",
    "            else:\n",
    "                raise TypeError(f\"Cannot add edge of type {type(edge)}\")\n",
    "    \n",
    "    def add_edge(self, edge):\n",
    "        \"\"\"Adds an edge to the graph\n",
    "        \n",
    "        Args:\n",
    "            edge (DirectedEdge or BidirectedEdge): the edge to add\n",
    "        \"\"\"\n",
    "        if isinstance(edge, BidirectedEdge):\n",
    "            self.bi_edges.append(edge)\n",
    "        elif isinstance(edge, DirectedEdge):\n",
    "            self.directed_edges.append(edge)\n",
    "        else:\n",
    "            raise TypeError(f\"Cannot add edge of type {type(edge)}\")\n",
    "    \n",
    "    def bi_edge_tuples(self):\n",
    "        return [(str(edge.a), str(edge.b)) for edge in self.bi_edges]\n",
    "    \n",
    "    def di_edge_tuples(self):\n",
    "        return [(str(edge.start), str(edge.end)) for edge in self.directed_edges]\n",
    "    \n",
    "    def idc(self, y, x, z=[]):\n",
    "        \"\"\"Identification of conditional interventional distribution.\n",
    "\n",
    "        Args:\n",
    "            x (list of Variable): intervention variables\n",
    "            y (list of Variable): outcome variables\n",
    "            z (list of Variable): conditioning variables (optional)\n",
    "        \n",
    "        Returns:\n",
    "            Expression: the expression for the interventional distribution\n",
    "        \"\"\"\n",
    "        # from pqp.pqp import id\n",
    "        res = id(\n",
    "            self.di_edge_tuples(),\n",
    "            self.bi_edge_tuples(),\n",
    "            [str(v) for v in x],\n",
    "            [str(v) for v in y],\n",
    "            [str(v) for v in z],\n",
    "        )\n",
    "        return parse_json(json.loads(res))\n",
    "    \n",
    "    def draw(self):\n",
    "        \"\"\"Draws the causal diagram using networkx\"\"\"\n",
    "        import networkx as nx\n",
    "\n",
    "        layout_graph = nx.Graph()\n",
    "        layout_graph.add_edges_from(self.bi_edge_tuples() + self.di_edge_tuples())\n",
    "        layout = nx.spring_layout(layout_graph, scale=1, k=1/len(layout_graph.nodes)**0.5)\n",
    "        nx.draw_networkx_nodes(layout_graph, layout, node_size=500)\n",
    "\n",
    "        digraph = nx.DiGraph()\n",
    "        digraph.add_edges_from(self.di_edge_tuples())\n",
    "        nx.draw_networkx_edges(digraph, layout)\n",
    "\n",
    "        bigraph = nx.Graph()\n",
    "        bigraph.add_edges_from(self.bi_edge_tuples())\n",
    "        nx.draw_networkx_edges(bigraph, layout, style=\"dashed\")\n",
    "\n",
    "        nx.draw_networkx_labels(layout_graph, layout)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"Graph({self.bi_edges + self.directed_edges})\"\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f\"<Graph n_edges={len(self.bi_edges + self.directed_edges)}>\"\n",
    "\n",
    "class DirectedEdge:\n",
    "    \"\"\"A directed edge between two variables, represents a causal relationship\n",
    "    \n",
    "    Args:\n",
    "        start (Variable): the start of the edge\n",
    "        end (Variable): the end of the edge\n",
    "    \"\"\"\n",
    "    def __init__(self, start, end):\n",
    "        self.start = start\n",
    "        self.end = end\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"DirectedEdge(start={self.start}, end={self.end})\"\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f\"{self.end} <= {self.start}\"\n",
    "    \n",
    "    def __eq__(self, other):\n",
    "        return (isinstance(other, DirectedEdge) and\n",
    "                self.start == other.start and\n",
    "                self.end == other.end)\n",
    "    \n",
    "    def __le__(self, other):\n",
    "        if isinstance(other, Variable):\n",
    "            return [self, self.start <= other]\n",
    "        elif isinstance(other, DirectedEdge):\n",
    "            return [self, self.start <= other.end, other]\n",
    "        elif isinstance(other, BidirectedEdge):\n",
    "            return [self, self.start <= other.a, other]\n",
    "        elif isinstance(other, list):\n",
    "            return [self] + [self <= o for o in other]\n",
    "        else:\n",
    "            raise TypeError(f\"Cannot add edge of type {type(other)}\")\n",
    "\n",
    "class BidirectedEdge:\n",
    "    \"\"\"A bidirected edge between two variables, represents confounding in the causal model\n",
    "    \n",
    "    Args:\n",
    "        a (Variable): one of the variables\n",
    "        b (Variable): the other variable\n",
    "    \"\"\"\n",
    "    def __init__(self, a, b):\n",
    "        self.a = a\n",
    "        self.b = b\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"BidirectedEdge({self.a}, {self.b})\"\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f\"{self.a} & {self.b}\"\n",
    "    \n",
    "    def __eq__(self, other):\n",
    "        return isinstance(other, BidirectedEdge) and (\n",
    "            (self.a == other.a and self.b == other.b) or\n",
    "            (self.a == other.b and self.b == other.a)\n",
    "        )\n",
    "\n",
    "    def __le__(self, other):\n",
    "        if isinstance(other, Variable):\n",
    "            return [self, self.b & other]\n",
    "        elif isinstance(other, DirectedEdge):\n",
    "            return [self, self.b & other.end, other]\n",
    "        elif isinstance(other, BidirectedEdge):\n",
    "            return [self, self.b & other.a, other]\n",
    "        elif isinstance(other, list):\n",
    "            return [self] + [self & o for o in other]\n",
    "        else:\n",
    "            raise TypeError(f\"Cannot add edge of type {type(other)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utils.py\n",
    "\n",
    "def recursive_sort(d):\n",
    "    if isinstance(d, dict):\n",
    "        return {k: recursive_sort(v) for k, v in sorted(d.items())}\n",
    "    elif isinstance(d, list):\n",
    "        return list(sorted(recursive_sort(v) for v in d))\n",
    "    elif isinstance(d, tuple):\n",
    "        return tuple(sorted(recursive_sort(v) for v in d))\n",
    "    else:\n",
    "        return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variable.py\n",
    "\n",
    "from pqp.expression import Expression\n",
    "\n",
    "class Variable(Expression):\n",
    "    \"\"\"A variable in the causal model\n",
    "    \n",
    "    Dunder methods allow for convenient syntax for creating causal graphs.\n",
    "\n",
    "    Example:\n",
    "        >>> x = Variable(\"x\")\n",
    "        >>> y = Variable(\"y\")\n",
    "        >>> x <= y\n",
    "        DirectedEdge(Variable(\"x\"), Variable(\"y\"))\n",
    "        >>> x & y\n",
    "        BidirectedEdge(Variable(\"x\"), Variable(\"y\"))\n",
    "    \n",
    "    Args:\n",
    "        name (str): the name of the variable\n",
    "    \"\"\"\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"Variable({self.name})\"\n",
    "    \n",
    "    def __eq__(self, other):\n",
    "        return isinstance(other, Variable) and self.name == other.name\n",
    "    \n",
    "    def __str__(self):\n",
    "        return self.name\n",
    "    \n",
    "    def __le__(self, other):\n",
    "        from pqp.graph import DirectedEdge, BidirectedEdge\n",
    "        if isinstance(other, Variable):\n",
    "            return DirectedEdge(other, self)\n",
    "        elif isinstance(other, DirectedEdge):\n",
    "            return self <= other.end\n",
    "        elif isinstance(other, BidirectedEdge):\n",
    "            return self <= other.a\n",
    "        elif isinstance(other, list):\n",
    "            return [self <= v for v in other]\n",
    "        else:\n",
    "            raise TypeError(f\"Cannot compare {type(self)} with {type(other)}\")\n",
    "    \n",
    "    def __and__(self, other):\n",
    "        from pqp.graph import BidirectedEdge, DirectedEdge\n",
    "        if isinstance(other, Variable):\n",
    "            return BidirectedEdge(self, other)\n",
    "        elif isinstance(other, BidirectedEdge):\n",
    "            return self & other.a\n",
    "        elif isinstance(other, DirectedEdge):\n",
    "            return self & other.end\n",
    "        elif isinstance(other, list):\n",
    "            return [self & v for v in other]\n",
    "        else:\n",
    "            raise TypeError(f\"Cannot compare {type(self)} with {type(other)}\")\n",
    "    \n",
    "    def to_latex(self):\n",
    "        return self.name\n",
    "\n",
    "def make_vars(names):\n",
    "    \"\"\"Creates a list of variables from a list of names\n",
    "    \n",
    "    Example:\n",
    "        >>> make_vars([\"x\", \"y\", \"z\"])\n",
    "        [Variable(\"x\"), Variable(\"y\"), Variable(\"z\")]\n",
    "        >>> x, y, z = make_vars(\"xyz\")\n",
    "        [Variable(\"x\"), Variable(\"y\"), Variable(\"z\")]\n",
    "    \n",
    "    \"\"\"\n",
    "    return [Variable(name) for name in names]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rust Library\n",
    "\n",
    "This is the underlying Rust library code. The Rust library is significantly larger than the Python library as it implements the main functionality. It has the following layout:\n",
    "\n",
    "- `src`\n",
    "    - `api`\n",
    "        - `mod.rs`\n",
    "        - `functions.rs`\n",
    "        - `python.rs`\n",
    "        - `wrapper.rs`\n",
    "        - `test.rs`\n",
    "    - `form`\n",
    "        - `mod.rs`\n",
    "        - `form.rs`\n",
    "        - `simplify.rs`\n",
    "        - `tikka.rs`\n",
    "        - `test_form.rs`\n",
    "        - `test_simplify.rs`\n",
    "    - `graph`\n",
    "        - `mod.rs`\n",
    "        - `graph.rs`\n",
    "        - `bigraph.rs`\n",
    "        - `digraph.rs`\n",
    "        - `graph_builder.`rs\n",
    "        - `node.rs`\n",
    "        - `tests.rs`\n",
    "    - `identification`\n",
    "        - `mod.rs`\n",
    "        - `shpitser.rs`\n",
    "        - `tests.rs`\n",
    "    - `model`\n",
    "        - `mod.rs`\n",
    "        - `examples.rs`\n",
    "        - `model.rs`\n",
    "        - `order.rs`\n",
    "        - `tests.rs`\n",
    "    - `utils`\n",
    "        - `mod.rs`\n",
    "        - `defaults.rs`\n",
    "        - `set_utils.rs`\n",
    "        - `utils.rs`\n",
    "        - `tests.rs`\n",
    "    - `lib.rs`\n",
    "    - `test.rs`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```rust\n",
    "// mod.rs\n",
    "\n",
    "pub mod wrapper;\n",
    "mod functions;\n",
    "mod test;\n",
    "\n",
    "pub mod python;\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```rust\n",
    "// functions.rs\n",
    "\n",
    "from pqp.expression import Expression\n",
    "\n",
    "class Variable(Expression):\n",
    "    \"\"\"A variable in the causal model\n",
    "    \n",
    "    Dunder methods allow for convenient syntax for creating causal graphs.\n",
    "\n",
    "    Example:\n",
    "        >>> x = Variable(\"x\")\n",
    "        >>> y = Variable(\"y\")\n",
    "        >>> x <= y\n",
    "        DirectedEdge(Variable(\"x\"), Variable(\"y\"))\n",
    "        >>> x & y\n",
    "        BidirectedEdge(Variable(\"x\"), Variable(\"y\"))\n",
    "    \n",
    "    Args:\n",
    "        name (str): the name of the variable\n",
    "    \"\"\"\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"Variable({self.name})\"\n",
    "    \n",
    "    def __eq__(self, other):\n",
    "        return isinstance(other, Variable) and self.name == other.name\n",
    "    \n",
    "    def __str__(self):\n",
    "        return self.name\n",
    "    \n",
    "    def __le__(self, other):\n",
    "        from pqp.graph import DirectedEdge, BidirectedEdge\n",
    "        if isinstance(other, Variable):\n",
    "            return DirectedEdge(other, self)\n",
    "        elif isinstance(other, DirectedEdge):\n",
    "            return self <= other.end\n",
    "        elif isinstance(other, BidirectedEdge):\n",
    "            return self <= other.a\n",
    "        elif isinstance(other, list):\n",
    "            return [self <= v for v in other]\n",
    "        else:\n",
    "            raise TypeError(f\"Cannot compare {type(self)} with {type(other)}\")\n",
    "    \n",
    "    def __and__(self, other):\n",
    "        from pqp.graph import BidirectedEdge, DirectedEdge\n",
    "        if isinstance(other, Variable):\n",
    "            return BidirectedEdge(self, other)\n",
    "        elif isinstance(other, BidirectedEdge):\n",
    "            return self & other.a\n",
    "        elif isinstance(other, DirectedEdge):\n",
    "            return self & other.end\n",
    "        elif isinstance(other, list):\n",
    "            return [self & v for v in other]\n",
    "        else:\n",
    "            raise TypeError(f\"Cannot compare {type(self)} with {type(other)}\")\n",
    "    \n",
    "    def to_latex(self):\n",
    "        return self.name\n",
    "\n",
    "def make_vars(names):\n",
    "    \"\"\"Creates a list of variables from a list of names\n",
    "    \n",
    "    Example:\n",
    "        >>> make_vars([\"x\", \"y\", \"z\"])\n",
    "        [Variable(\"x\"), Variable(\"y\"), Variable(\"z\")]\n",
    "        >>> x, y, z = make_vars(\"xyz\")\n",
    "        [Variable(\"x\"), Variable(\"y\"), Variable(\"z\")]\n",
    "    \n",
    "    \"\"\"\n",
    "    return [Variable(name) for name in names]\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```rust\n",
    "// python.rs\n",
    "use pyo3::prelude::*;\n",
    "use rand::Rng;\n",
    "use std::cmp::Ordering;\n",
    "use std::io;\n",
    "\n",
    "use super::functions;\n",
    "use super::wrapper::IDResult;\n",
    "\n",
    "#[pyfunction]\n",
    "fn hello_world () {\n",
    "    println! ( \"Hello, world!\" );\n",
    "}\n",
    "\n",
    "#[pyfunction]\n",
    "fn id (d_edges: Vec<(String, String)>, b_edges: Vec<(String, String)>, y: Vec<String>, x: Vec<String>, z: Vec<String>) -> PyResult<String> {\n",
    "    \n",
    "    let result = functions::id(d_edges, b_edges, x, y, z).estimand_json.replace(\"\\\\\", \"\");\n",
    "    Ok(result)\n",
    "}\n",
    "\n",
    "#[pymodule]\n",
    "pub fn pqp(_py: Python, m: &PyModule) -> PyResult<()> {\n",
    "    m.add_function(wrap_pyfunction!(hello_world, m)?)?;\n",
    "    m.add_function(wrap_pyfunction!(id, m)?)?;\n",
    "    Ok(())\n",
    "}\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```rust\n",
    "// test.rs\n",
    "\n",
    "#![cfg(test)]\n",
    "\n",
    "use super::{\n",
    "    wrapper::{FormWrapper, ModelWrapper},\n",
    "    functions::id,\n",
    "};\n",
    "use crate::{\n",
    "    utils::defaults::{set, Set},\n",
    "};\n",
    "\n",
    "#[test]\n",
    "fn test_wrapper_bowgraph() {\n",
    "    let mut m = ModelWrapper::new();\n",
    "    m.add_effect(\"x\", \"y\");\n",
    "    m.add_confounding(\"x\", \"y\");\n",
    "    let res = m.id(set![\"y\".to_string()], set![\"x\".to_string()], set![]);\n",
    "    assert_eq!(res.estimand_json, FormWrapper::Hedge.to_json());\n",
    "}\n",
    "\n",
    "#[test]\n",
    "fn test_wrapper_fd() {\n",
    "    let mut m = ModelWrapper::new();\n",
    "    m.add_effect(\"x\", \"z\");\n",
    "    m.add_effect(\"z\", \"y\");\n",
    "    m.add_confounding(\"x\", \"y\");\n",
    "    let res = m.id(set![\"y\".to_string()], set![\"x\".to_string()], set![]);\n",
    "    assert_ne!(res.estimand_json, FormWrapper::Hedge.to_json());\n",
    "}\n",
    "\n",
    "#[test]\n",
    "fn test_wrapped_bd () {\n",
    "    let mut m = ModelWrapper::new();\n",
    "    m.add_effect(\"x\", \"y\");\n",
    "    m.add_effect(\"z\", \"y\");\n",
    "    m.add_effect(\"z\", \"x\");\n",
    "\n",
    "    let res = m.id(set![\"y\".to_string()], set![\"x\".to_string()], set![\"z\".to_string()]);\n",
    "    assert_ne!(res.estimand_json, FormWrapper::Hedge.to_json());\n",
    "}\n",
    "\n",
    "#[test]\n",
    "fn test_fn_id_fd () {\n",
    "    let res = id(\n",
    "        vec![(\"x\".to_string(), \"z\".to_string()), (\"z\".to_string(), \"y\".to_string())],\n",
    "        vec![(\"x\".to_string(), \"y\".to_string())],\n",
    "        vec![\"y\".to_string()],\n",
    "        vec![\"x\".to_string()],\n",
    "        vec![],\n",
    "    );\n",
    "    assert_ne!(res.estimand_json, FormWrapper::Hedge.to_json());\n",
    "}\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```rust\n",
    "// wrapper.rs\n",
    "\n",
    "use itertools::Itertools;\n",
    "\n",
    "use crate::{\n",
    "    model::{Model, ModelBuilder},\n",
    "    utils::defaults::{set, Set, Map},\n",
    "    graph::Node,\n",
    "    form::{Form, form::AbstractForm},\n",
    "};\n",
    "\n",
    "pub struct ModelWrapper {\n",
    "    model_builder: ModelBuilder,\n",
    "    vars: Map<String, Node>,\n",
    "}\n",
    "\n",
    "pub type FormWrapper = AbstractForm<String>;\n",
    "\n",
    "impl FormWrapper {\n",
    "    pub fn to_json(&self) -> String {\n",
    "        match self {\n",
    "            FormWrapper::Marginal(sub, exp) => {\n",
    "                format!(\n",
    "                    \"{{\\\"type\\\": \\\"Marginal\\\", \\\"sub\\\": [{:?}], \\\"exp\\\": {}}}\",\n",
    "                    sub.iter().format_default(\", \").to_string(),\n",
    "                    exp.to_json()\n",
    "                )\n",
    "            },\n",
    "            FormWrapper::Quotient(numer, denom) => {\n",
    "                format!(\n",
    "                    \"{{\\\"type\\\": \\\"Quotient\\\", \\\"numer\\\": {}, \\\"denom\\\": {}}}\",\n",
    "                    numer.to_json(),\n",
    "                    denom.to_json()\n",
    "                )\n",
    "            },\n",
    "            FormWrapper::P(vars, given) => {\n",
    "                format!(\n",
    "                    \"{{\\\"type\\\": \\\"P\\\", \\\"vars\\\": [{:?}], \\\"given\\\": [{:?}]}}\",\n",
    "                    vars.iter().format_default(\", \"),\n",
    "                    given.iter().format_default(\", \")\n",
    "                )\n",
    "            },\n",
    "            FormWrapper::Product(exprs) => {\n",
    "                format!(\n",
    "                    \"{{\\\"type\\\": \\\"Product\\\", \\\"exprs\\\": [{}]}}\",\n",
    "                    exprs.iter().map(|e| {e.to_json()}).format_default(\", \")\n",
    "                )\n",
    "            },\n",
    "            FormWrapper::Hedge => \"{\\\"type\\\": \\\"Hedge\\\"}\".to_string(),\n",
    "        }.replace(\"\\\\\", \"\")\n",
    "    }\n",
    "}\n",
    "\n",
    "impl ModelWrapper {\n",
    "    pub fn new() -> ModelWrapper {\n",
    "        ModelWrapper {\n",
    "            model_builder: ModelBuilder::new(),\n",
    "            vars: Map::new(),\n",
    "        }\n",
    "    }\n",
    "\n",
    "    fn get_or_add_var(&mut self, name: &str) -> Node {\n",
    "        if self.vars.contains_key(name) {\n",
    "            return self.vars[name];\n",
    "        } else {\n",
    "            let var = self.vars.len() as i32;\n",
    "            self.vars.insert(name.to_string(), var);\n",
    "            self.model_builder.add_node(var);\n",
    "            return var;\n",
    "        }\n",
    "    }\n",
    "\n",
    "    pub fn form_sub(&self, form: Form) -> FormWrapper {\n",
    "        let reversed: Map<i32, String> = self.vars.iter()\n",
    "            .map(|(k, v)| (*v, k.clone()))\n",
    "            .collect();\n",
    "\n",
    "        fn substitute(f: &Form, reversed: &Map<i32, String>) -> FormWrapper {\n",
    "            match f {\n",
    "                Form::Marginal(sub, exp) => {\n",
    "                    let sub: Set<String> = sub.iter().map(|s| reversed[s].to_owned()).collect();\n",
    "                    let exp = substitute(exp, reversed);\n",
    "                    FormWrapper::Marginal(sub, Box::new(exp))\n",
    "                },\n",
    "                Form::Quotient(numer, denom) => {\n",
    "                    let numer = substitute(numer, reversed);\n",
    "                    let denom = substitute(denom, reversed);\n",
    "                    FormWrapper::Quotient(Box::new(numer), Box::new(denom))\n",
    "                },\n",
    "                Form::P(vars, given) => {\n",
    "                    let vars = vars.iter().map(|s| reversed[s].to_owned()).collect();\n",
    "                    let given = given.iter().map(|s| reversed[s].to_owned()).collect();\n",
    "                    FormWrapper::P(vars, given)\n",
    "                },\n",
    "                Form::Product(exprs) => {\n",
    "                    let exprs = exprs.iter().map(\n",
    "                        |e| substitute(e, reversed)\n",
    "                    ).collect();\n",
    "                    FormWrapper::Product(exprs)\n",
    "                },\n",
    "                Form::Hedge => FormWrapper::Hedge,\n",
    "            }\n",
    "        }\n",
    "\n",
    "        return substitute(&form, &reversed);\n",
    "    }\n",
    "\n",
    "    pub fn add_effect(&mut self, cause: &str, effect: &str) {\n",
    "        let cause_n = self.get_or_add_var(cause);\n",
    "        let effect_n = self.get_or_add_var(effect);\n",
    "        // TODO: this seems backwards (!!??) but it works\n",
    "        self.model_builder.add_directed_edge(effect_n, cause_n);\n",
    "    }\n",
    "\n",
    "    pub fn add_confounding(&mut self, cause: &str, effect: &str) {\n",
    "        let cause_n = self.get_or_add_var(cause);\n",
    "        let effect_n = self.get_or_add_var(effect);\n",
    "        self.model_builder.add_confounded_edge(cause_n, effect_n);\n",
    "    }\n",
    "\n",
    "    pub fn id(&self, y: Set<String>, x: Set<String>, z: Set<String>) -> IDResult {\n",
    "\n",
    "        let retrieve = |s: &String| {\n",
    "            if self.vars.contains_key(s) {\n",
    "                self.vars[s]\n",
    "            } else {\n",
    "                panic!(\"Variable {} not found\", s);\n",
    "            }\n",
    "        };\n",
    "\n",
    "        let y_n: Set<Node> = y.iter().map(retrieve).collect();\n",
    "        let x_n: Set<Node> = x.iter().map(retrieve).collect();\n",
    "        let z_n: Set<Node> = z.iter().map(retrieve).collect();\n",
    "\n",
    "        let model = ModelBuilder::to_model(Box::new(self.model_builder.to_owned())).cond(&z_n);\n",
    "        let p = model.id(&y_n, &x_n);\n",
    "\n",
    "        // string formatting of query\n",
    "        let mut query = \"P(\".to_string();\n",
    "        if !y.is_empty() {\n",
    "            for each in y { query += &format!(\"{}, \", each); }\n",
    "            query += \"| \";\n",
    "            for each in x { query += &format!(\"{}, \", each); }\n",
    "            for each in z { query += &format!(\"do({}), \", each); }\n",
    "            query.pop();\n",
    "            query.pop();\n",
    "            query += \")\"\n",
    "        }\n",
    "\n",
    "        return IDResult {\n",
    "            estimand_json: self.form_sub(p).to_json(),\n",
    "            query_string: query,\n",
    "        };\n",
    "    }\n",
    "}\n",
    "\n",
    "#[derive(Debug)]\n",
    "pub struct IDResult {\n",
    "    pub estimand_json: String,\n",
    "    pub query_string: String,\n",
    "}\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```rust\n",
    "// form.rs\n",
    "use core::num;\n",
    "use cute::c;\n",
    "\n",
    "use crate::{\n",
    "    utils::{\n",
    "        set_utils::{difference, union, make_set},\n",
    "        defaults::Set,\n",
    "    },\n",
    "    graph::Node\n",
    "};\n",
    "\n",
    "use super::simplify;\n",
    "\n",
    "pub static HEDGE: Form = Form::Hedge;\n",
    "\n",
    "#[derive(Debug, Clone, PartialEq, Eq)]\n",
    "pub enum AbstractForm<T: Eq + std::hash::Hash> {\n",
    "    Marginal(Set<T>, Box<AbstractForm<T>>),\n",
    "    Product(Vec<AbstractForm<T>>),\n",
    "    Quotient(Box<AbstractForm<T>>, Box<AbstractForm<T>>),\n",
    "    P(Vec<T>, Vec<T>),\n",
    "    Hedge\n",
    "}\n",
    "\n",
    "pub type Form = AbstractForm<Node>;\n",
    "\n",
    "impl Form {\n",
    "    pub fn marginal(over: Set<Node>, exp: Form) -> Form {\n",
    "        Form::Marginal(over, Box::new(exp))\n",
    "    }\n",
    "\n",
    "    pub fn product(forms: Vec<Form>) -> Form {\n",
    "        Form::Product(forms)\n",
    "    }\n",
    "\n",
    "    pub fn quotient(num: Form, denom: Form) -> Form {\n",
    "        Form::Quotient(Box::new(num), Box::new(denom))\n",
    "    }\n",
    "\n",
    "    pub fn prob(vars: Vec<Node>) -> Form {\n",
    "        Form::P(vars, vec![])\n",
    "    }\n",
    "\n",
    "    pub fn cond_prob(vars: Vec<Node>, given: Vec<Node>) -> Form {\n",
    "        Form::P(vars, given)\n",
    "    }\n",
    "\n",
    "    pub fn free<'b>(form: &'b Form) -> Set<Node> {\n",
    "        match form {\n",
    "            Form::Marginal(sub, exp) => \n",
    "                difference(&Form::free(&**exp), &sub),\n",
    "            Form::Quotient(numer, denom) =>\n",
    "                union(&Form::free(&**numer), &Form::free(&**denom)),\n",
    "            Form::P(vars, given) => {\n",
    "                let mut set = Set::new();\n",
    "                vars.iter().for_each(|e| {set.insert(*e);});\n",
    "                given.iter().for_each(|e| {set.insert(*e);});\n",
    "                return set;\n",
    "            },\n",
    "            Form::Product(exprs) => {\n",
    "                let mut set = Set::new();\n",
    "                for expr in exprs.iter() {\n",
    "                    set.extend(Form::free(expr));\n",
    "                }\n",
    "                return set;\n",
    "            },\n",
    "            Form::Hedge => Set::new(),\n",
    "        }\n",
    "    }\n",
    "\n",
    "    /// Finds P(subset | pred(subset)) in terms of p, where pred(x) is the\n",
    "    /// predecessors of x in order.\n",
    "    pub fn factorize_subset(order: Vec<Node>, p: Form, subset: &Set<Node>) -> Form {\n",
    "        let mut free = Form::free(&p);\n",
    "        let mut terms = Vec::new();\n",
    "\n",
    "        for nxt in order.iter().enumerate() {\n",
    "            let (i, v_i) = nxt;\n",
    "            if subset.contains(v_i) {\n",
    "                let v: Set<Node> = [*v_i].into_iter().collect();\n",
    "                let pred = make_set((&order[i..]).iter().map(|e| *e));\n",
    "                let unbound = difference(&free, &union(&pred, &v));\n",
    "                let term = Form::quotient(\n",
    "                    Form::marginal(unbound.clone(), p.clone()),\n",
    "                    Form::marginal(union(&unbound, &v), p.clone())\n",
    "                );\n",
    "                terms.push(term);\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        return Form::product(terms);\n",
    "    }\n",
    "\n",
    "    /// Factorize a form with respect to a given order\n",
    "    pub fn factorize(order: Vec<Node>, p: Form) -> Form {\n",
    "        let subset = make_set(order.iter().map(|e| *e));\n",
    "        Form::factorize_subset(order, p, &subset)\n",
    "    }\n",
    "\n",
    "    /// determine if a form contains a hedge\n",
    "    pub fn contains_hedge(&self) -> bool {\n",
    "        match self {\n",
    "            Form::Marginal(_, exp) => exp.contains_hedge(),\n",
    "            Form::Product(exprs) => {\n",
    "                for expr in exprs {\n",
    "                    if expr.contains_hedge() {\n",
    "                        return true;\n",
    "                    }\n",
    "                }\n",
    "                return false;\n",
    "            },\n",
    "            Form::Quotient(numer, denom) => {\n",
    "                numer.contains_hedge() || denom.contains_hedge()\n",
    "            },\n",
    "            Form::P(_, _) => false,\n",
    "            Form::Hedge => true,\n",
    "        }\n",
    "    }\n",
    "\n",
    "    pub fn form_type(form: &Self) -> i8 {\n",
    "        match form {\n",
    "            Form::Marginal(_, _) => 0,\n",
    "            Form::Product(_) => 1,\n",
    "            Form::Quotient(_, _) => 2,\n",
    "            Form::P(_, _) => 3,\n",
    "            Form::Hedge => 4,\n",
    "        }\n",
    "    }\n",
    "\n",
    "    fn do_cmp(&self, other: &Self) -> Option<std::cmp::Ordering> {\n",
    "        let s_val = Form::form_type(self);\n",
    "        let o_val = Form::form_type(other);\n",
    "\n",
    "        if s_val < o_val {\n",
    "            return Some(std::cmp::Ordering::Less);\n",
    "        } else if s_val > o_val {\n",
    "            return Some(std::cmp::Ordering::Greater);\n",
    "        }\n",
    "\n",
    "        match (self, other) {\n",
    "            (Form::Marginal(s_over, s_exp), Form::Marginal(o_over, o_exp)) => {\n",
    "                if s_over.len() == o_over.len() {\n",
    "                    s_exp.partial_cmp(o_exp)\n",
    "                } else {\n",
    "                    s_over.len().partial_cmp(&o_over.len())\n",
    "                }\n",
    "            },\n",
    "            (Form::Product(s_exprs), Form::Product(o_exprs)) => {\n",
    "                s_exprs.partial_cmp(o_exprs)\n",
    "            },\n",
    "            (Form::Quotient(s_numer, s_denom), Form::Quotient(o_numer, o_denom)) => {\n",
    "                if s_numer == o_numer {\n",
    "                    s_denom.partial_cmp(o_denom)\n",
    "                } else {\n",
    "                    s_numer.partial_cmp(o_numer)\n",
    "                }\n",
    "            },\n",
    "            (Form::P(s_vars, s_given), Form::P(o_vars, o_given)) => {\n",
    "                if s_vars == o_vars {\n",
    "                    s_given.partial_cmp(o_given)\n",
    "                } else {\n",
    "                    s_vars.partial_cmp(o_vars)\n",
    "                }\n",
    "            },\n",
    "            _ => Some(std::cmp::Ordering::Equal),\n",
    "        }\n",
    "    }\n",
    "\n",
    "    /// applies form_map with the same func to child expressions, then applies func to self\n",
    "    pub fn map (&self, func: fn(&Form) -> Form) -> Form {\n",
    "        let mapped = match self {\n",
    "            Form::Marginal(over, exp)\n",
    "                => Form::marginal(over.clone(), exp.map(func)),\n",
    "            Form::Product(exprs)\n",
    "                => Form::product(exprs.iter().map(|e| e.map(func)).collect()),\n",
    "            Form::Quotient(numer, denom)\n",
    "                => Form::quotient(numer.map(func), denom.map(func)),\n",
    "            _ => self.to_owned(),\n",
    "        };\n",
    "        return func(&mapped);\n",
    "    }\n",
    "\n",
    "    /// recursively sorts expressions, returning a new form\n",
    "    pub fn sorted(&self) -> Form {\n",
    "        match self {\n",
    "            Form::Marginal(over, exp) => {\n",
    "                Form::marginal(over.to_owned(), exp.sorted())\n",
    "            },\n",
    "            Form::Product(exprs) => {\n",
    "                let mut exprs: Vec<Form> = exprs\n",
    "                    .iter()\n",
    "                    .map(|e| e.sorted())\n",
    "                    .collect();\n",
    "                exprs.sort();\n",
    "                Form::product(exprs)\n",
    "            },\n",
    "            Form::Quotient(numer, denom) => {\n",
    "                Form::quotient(numer.sorted(), denom.sorted())\n",
    "            },\n",
    "            Form::P(vars, cond) => {\n",
    "                let mut vars = vars.to_owned();\n",
    "                let mut cond = cond.to_owned();\n",
    "                vars.sort();\n",
    "                cond.sort();\n",
    "                Form::cond_prob(vars, cond)\n",
    "            }\n",
    "            _ => self.to_owned(),\n",
    "        }\n",
    "    }\n",
    "\n",
    "    pub fn cond_expand(&self) -> Form {\n",
    "        self.map(|f| {\n",
    "            match f {\n",
    "                Form::P(vars, cond) => {\n",
    "                    Form::quotient(\n",
    "                        Form::prob(\n",
    "                            vars.iter().cloned().chain(cond.iter().cloned()).collect()\n",
    "                        ),\n",
    "                        Form::prob(cond.to_owned())\n",
    "                    )\n",
    "                },\n",
    "                _ => f.to_owned(),\n",
    "            }\n",
    "        })\n",
    "    }\n",
    "\n",
    "    pub fn structural_eq(&self, other: &Form) -> bool {\n",
    "        self.sorted() == other.sorted()\n",
    "    }\n",
    "\n",
    "    /// Sorts and simplifies a form. Suitable for structural equality checks.\n",
    "    pub fn simplify(&self) -> Form {\n",
    "        simplify(&self.sorted())\n",
    "    }\n",
    "}\n",
    "\n",
    "impl PartialOrd for Form {\n",
    "    fn partial_cmp(&self, other: &Self) -> Option<std::cmp::Ordering> {\n",
    "        Some(Form::cmp(&self, other))\n",
    "    }\n",
    "}\n",
    "\n",
    "impl Ord for Form {\n",
    "    fn cmp(&self, other: &Self) -> std::cmp::Ordering {\n",
    "        Form::do_cmp(&self, other).unwrap()\n",
    "    }   \n",
    "}\n",
    "\n",
    "pub fn one () -> Form {\n",
    "    Form::prob(vec![])\n",
    "}\n",
    "\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```rust\n",
    "// mod.rs\n",
    "\n",
    "pub mod form;\n",
    "pub use form::{Form, one, HEDGE};\n",
    "mod simplify;\n",
    "use simplify::simplify;\n",
    "\n",
    "// tests\n",
    "mod test_simplify;\n",
    "mod test_form;\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```rust\n",
    "// simplify.rs\n",
    "\n",
    "\n",
    "use core::num;\n",
    "use std::{\n",
    "    iter::Product,\n",
    "    convert::identity,\n",
    "};\n",
    "\n",
    "use crate::{\n",
    "    utils::{\n",
    "        set_utils::{difference, make_set, union},\n",
    "        defaults::Set,\n",
    "        remove_duplicates_sorted,\n",
    "    },\n",
    "    graph::Node\n",
    "};\n",
    "\n",
    "use super::form::{Form, one, HEDGE};\n",
    "\n",
    "pub fn promote_hedge(f: &Form) -> &Form {\n",
    "    if f.contains_hedge() {\n",
    "        &HEDGE\n",
    "    } else {\n",
    "        f\n",
    "    }\n",
    "}\n",
    "\n",
    "/// Simplify a marginal expression.\n",
    "/// Will reduce terms in a joint probability if it finds one.\n",
    "pub fn simplify_marginal(f: &Form) -> Form {\n",
    "    if let Form::Marginal(over, exp) = f {\n",
    "        let exp_content = *exp.to_owned();\n",
    "\n",
    "        if over.is_empty() {\n",
    "            return exp_content;\n",
    "        } else if let Form::Marginal(over2, exp2) = exp_content {\n",
    "            return Form::marginal(union(&over, &over2), *exp2);\n",
    "        } else if let Form::P(vars, cond) = exp_content {\n",
    "            let vars_set: Set<Node> = vars.iter().cloned().collect();\n",
    "            let new_over = difference(&over, &vars_set);\n",
    "            let new_vars = difference(&vars_set, &over);\n",
    "            let new_p = Form::cond_prob(new_vars.iter().cloned().collect(), cond);\n",
    "\n",
    "            if !new_over.is_empty() {\n",
    "                return Form::marginal(new_over, new_p);\n",
    "            } else {\n",
    "                return new_p;\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    return f.to_owned();\n",
    "}\n",
    "\n",
    "/// Simplify a product of expressions.\n",
    "/// After simplification, product will not contain any product, quotient, or one.\n",
    "pub fn simplify_product(f: &Form) -> Form {\n",
    "    if let Form::Product(exprs) = f {\n",
    "        let mut numer = vec![];\n",
    "        let mut denom = vec![];\n",
    "\n",
    "        for exp in exprs.iter() {\n",
    "            if let Form::Quotient(n, d) = exp {\n",
    "                numer.push(*n.to_owned());\n",
    "                denom.push(*d.to_owned());\n",
    "            } else if let Form::Product(exprs2) = exp {\n",
    "                for exp2 in exprs2.iter() {\n",
    "                    if let Form::Quotient(n, d) = exp2 {\n",
    "                        numer.push(*n.to_owned());\n",
    "                        denom.push(*d.to_owned());\n",
    "                    } else if exp != &one() {\n",
    "                        numer.push(exp2.to_owned());\n",
    "                    }\n",
    "                }\n",
    "            } else if exp != &one() {\n",
    "                numer.push(exp.to_owned());\n",
    "            }\n",
    "        }\n",
    "\n",
    "        let n_simple = if numer.len() > 1 {\n",
    "            Form::product(numer)\n",
    "        } else if numer.len() == 1 {\n",
    "            numer[0].to_owned()\n",
    "        } else {\n",
    "            one()\n",
    "        };\n",
    "\n",
    "        let d_simple = if denom.len() > 1 {\n",
    "            Form::product(denom)\n",
    "        } else if denom.len() == 1 {\n",
    "            denom[0].to_owned()\n",
    "        } else {\n",
    "            one()\n",
    "        };\n",
    "\n",
    "        if d_simple == one() {\n",
    "            return n_simple;\n",
    "        } else {\n",
    "            return Form::quotient(n_simple, d_simple);\n",
    "        }\n",
    "    }\n",
    "\n",
    "    return f.to_owned();\n",
    "}\n",
    "\n",
    "/// Simplify a quotient of expressions.\n",
    "pub fn simplify_quotient (f: &Form) -> Form {\n",
    "    if let Form::Quotient(numer, denom) = f {\n",
    "        // collapse nested quotients\n",
    "        let (top_numer, top_denom) = if let Form::Quotient(n, d) = *numer.to_owned() {\n",
    "            (*n.to_owned(), *d.to_owned())\n",
    "        } else {\n",
    "            (*numer.to_owned(), one())\n",
    "        };\n",
    "\n",
    "        let (bottom_numer, bottom_denom) = if let Form::Quotient(n, d) = *denom.to_owned() {\n",
    "            (*n.to_owned(), *d.to_owned())\n",
    "        } else {\n",
    "            (*denom.to_owned(), one())\n",
    "        };\n",
    "\n",
    "        let collapsed_numer = simplify_product(&Form::product(vec![top_numer, bottom_denom])).sorted();\n",
    "        let collapsed_denom = simplify_product(&Form::product(vec![top_denom, bottom_numer])).sorted();\n",
    "\n",
    "        // cancel duplicates\n",
    "        let mut numer_vec = match collapsed_numer {\n",
    "            Form::Product(exprs) => exprs,\n",
    "            _ => vec![collapsed_numer],\n",
    "        };\n",
    "        numer_vec.sort_unstable();\n",
    "\n",
    "        let mut denom_vec = match collapsed_denom {\n",
    "            Form::Product(exprs) => exprs,\n",
    "            _ => vec![collapsed_denom],\n",
    "        };\n",
    "        denom_vec.sort_unstable();\n",
    "\n",
    "        let (numer_dedup, denom_dedup) = remove_duplicates_sorted(&numer_vec, &denom_vec);\n",
    "        let numer_simple = simplify_product(&Form::product(numer_dedup));\n",
    "        let denom_simple = simplify_product(&Form::product(denom_dedup));\n",
    "\n",
    "        if denom_simple == one() {\n",
    "            return numer_simple;\n",
    "        } else {\n",
    "            return Form::quotient(numer_simple, denom_simple);\n",
    "        }\n",
    "    }\n",
    "\n",
    "    return f.to_owned();\n",
    "}\n",
    "\n",
    "/// Simplify a form (not recursive).\n",
    "pub fn simplify_form(f: &Form) -> Form {\n",
    "    let form_type = Form::form_type(&f);\n",
    "    let func = match f {\n",
    "        Form::Product(_) => simplify_product,\n",
    "        Form::Quotient(_, _) => simplify_quotient,\n",
    "        Form::Marginal(_, _) => simplify_marginal,\n",
    "        _ => |g: &Form| {g.to_owned()},\n",
    "    };\n",
    "    let once = func(f);\n",
    "\n",
    "    // if the form type hasn't changed, return the simplified form\n",
    "    if Form::form_type(&once) == form_type {\n",
    "        once\n",
    "    } else {\n",
    "        simplify_form(&once)\n",
    "    }\n",
    "}\n",
    "\n",
    "/// Recursively simplify a form.\n",
    "pub fn simplify(f: &Form) -> Form {\n",
    "    let hedged = promote_hedge(f);\n",
    "    if hedged == &HEDGE {\n",
    "        return HEDGE.to_owned();\n",
    "    } else {\n",
    "        return f.map(simplify_form).sorted();\n",
    "    }\n",
    "}\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```rust\n",
    "// tikka.rs\n",
    "\n",
    "use crate::{\n",
    "    utils::{defaults::{Map, Set}, set_utils::{union, difference, copy_set, make_set, powerset, symmetric_difference}},\n",
    "    graph::Node,\n",
    "    model::{Model, order::Order}, set,\n",
    "};\n",
    "\n",
    "pub struct Atomic {\n",
    "    s: Set<Node>,\n",
    "    t: Vec<(Node, Set<Node>)>,\n",
    "}\n",
    "\n",
    "pub struct Expression {\n",
    "    s: Set<Node>,\n",
    "    b: Box<Vec<Expression>>,\n",
    "    a: Atomic,\n",
    "}\n",
    "\n",
    "// fn index_of (a: Atomic, j: i32) -> i32 {\n",
    "//     todo!();\n",
    "// }\n",
    "\n",
    "// fn get_missing (a: Atomic, g: Model, j: i32) -> Set<Node> {\n",
    "//     todo!();\n",
    "// }\n",
    "\n",
    "fn insert (j: &Set<Node>, j_cond: &Set<Node>, m: &Node, s: &Node, model: &Model, pi: &Order) -> (Set<Node>, Set<Node>, Set<Node>) {\n",
    "    let an_m_inc = pi.set_predecessors(j).unwrap().iter().cloned().collect();\n",
    "    let g = difference(&an_m_inc, &model.ancestors_inc(*m));\n",
    "    // ???\n",
    "    todo!();\n",
    "}\n",
    "\n",
    "fn join (j_vars: &Set<Node>, j_conditional: &Set<Node>, v: &Node, v_conditional: &Set<Node>, summation_var: &Node, nonpresent_vars: &Set<Node>, model: &Model, pi: &Order) -> (Set<Node>, Set<Node>, Set<Node>) {\n",
    "    if j_vars.is_empty() {\n",
    "        return (Set::from([*v]), copy_set(v_conditional), Set::new());\n",
    "    }\n",
    "\n",
    "    let an_v_inc = model.ancestors_inc(*v);\n",
    "    let an_v = difference(&an_v_inc, &set![*v]);\n",
    "\n",
    "    let pi_before_j = make_set(pi.set_predecessors(j_vars).unwrap().into_iter());\n",
    "    let g = difference(&pi_before_j, &an_v_inc);\n",
    "\n",
    "    for p_i in powerset(&g) {\n",
    "        let a = symmetric_difference(&union(&an_v_inc, &p_i), j_conditional);\n",
    "        let b = symmetric_difference(&union(&an_v, &p_i), v_conditional);\n",
    "\n",
    "        if model.cond(&difference(j_conditional, &a)).independent(&j_vars, &a) &&\n",
    "            model.cond(&difference(v_conditional, &b)).independent(&set![*v], &b) {\n",
    "            \n",
    "            return (union(j_vars, &set![*v]), union(&an_v, &p_i), set![]);\n",
    "        }\n",
    "    }\n",
    "\n",
    "    if !nonpresent_vars.is_empty() {\n",
    "        for m in nonpresent_vars {\n",
    "            if j_conditional.contains(m) && !v_conditional.contains(m) {\n",
    "                let (j_new, j_cond_new, r) = insert(j_vars, j_conditional, m, summation_var, model, pi);\n",
    "                if j_vars.is_subset(&j_new) {\n",
    "                    return (j_new, j_cond_new, r);\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    return (j_vars.clone(), j_conditional.clone(), set![]);\n",
    "}\n",
    "\n",
    "// fn factorize ( )\n",
    "\n",
    "// fn simplify (a: Atomic, g: Model, pi: Map<Node, i32>) -> Atomic {\n",
    "//     let mut j: i32 = 0;\n",
    "//     while j < a.s.len().try_into().unwrap() {\n",
    "//         let mut B = a;\n",
    "//         let mut J = Set::new();\n",
    "//         let mut D = Set::new();\n",
    "//         let mut R = Set::new();\n",
    "//         let mut I = Vec::new();\n",
    "//         j += 1;\n",
    "//         let S_j: Node;\n",
    "\n",
    "//         let mut i = index_of(a, j);\n",
    "//         let mut M = get_missing(a, g, j);\n",
    "//         let mut k = 1;\n",
    "\n",
    "//         while k <= i {\n",
    "//             let V_k: Node;\n",
    "//             let C_k: Set<Node>;\n",
    "//             let (J_new, D_new, R_new) = join(J, D, V_k, C_k, S_j, M, g, pi);\n",
    "//             if J_new.is_subset(J) {\n",
    "//                 break;\n",
    "//             } else {\n",
    "//                 J = J_new;\n",
    "//                 D = D_new;\n",
    "//                 if !R_new.is_empty() {\n",
    "//                     R = union(&R, &R_new);\n",
    "//                     I.push(D);\n",
    "//                     M = difference(&M, &R_new);\n",
    "//                 } else {\n",
    "//                     k += 1;\n",
    "//                 }\n",
    "//             }\n",
    "//         }\n",
    "\n",
    "//         if k = i + 1 {\n",
    "//             let A_new = factorize();\n",
    "//         }\n",
    "\n",
    "//     }\n",
    "\n",
    "//     todo!();\n",
    "// }\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```rust\n",
    "// test_simplify.rs\n",
    "\n",
    "#![cfg(test)]\n",
    "use crate::utils::defaults::{set, Set};\n",
    "use super::{\n",
    "    simplify::{\n",
    "        simplify,\n",
    "        simplify_product,\n",
    "        simplify_quotient,\n",
    "        simplify_marginal,\n",
    "        promote_hedge\n",
    "    },\n",
    "    form::{one, HEDGE},\n",
    "    Form,\n",
    "};\n",
    "\n",
    "#[test]\n",
    "fn test_simplify_marginal() {\n",
    "    let f = Form::marginal(set![0, 1], Form::prob(vec![0, 1, 2]));\n",
    "    let simple = Form::prob(vec![2]);\n",
    "    assert_eq!(simplify_marginal(&f), simple);\n",
    "\n",
    "    // ensure it merges with nested marginals\n",
    "    let f = Form::marginal(set![0, 1], Form::marginal(set![2], Form::prob(vec![3])));\n",
    "    let simple = Form::marginal(set![0, 1, 2], Form::prob(vec![3]));\n",
    "    assert_eq!(simplify_marginal(&f), simple);\n",
    "\n",
    "    // ensure it does nothing if inside is not a probability or marginal\n",
    "    let f = Form::marginal(set![0, 1], Form::product(vec![Form::prob(vec![0, 1, 2])]));\n",
    "    let simple = Form::marginal(set![0, 1], Form::product(vec![Form::prob(vec![0, 1, 2])]));\n",
    "    assert_eq!(simplify_marginal(&f), simple);\n",
    "}\n",
    "\n",
    "#[test]\n",
    "fn test_simplify_product () {\n",
    "\n",
    "    // merging with nested quotients\n",
    "    let f = Form::product(vec![\n",
    "        Form::product(vec![\n",
    "            Form::prob(vec![0, 3])\n",
    "        ]),\n",
    "        Form::quotient(\n",
    "            Form::prob(vec![4]),\n",
    "            Form::prob(vec![6, 7]),\n",
    "        ),\n",
    "    ]);\n",
    "    let simple = Form::quotient(\n",
    "        Form::product(vec![Form::prob(vec![0, 3]), Form::prob(vec![4])]),\n",
    "        Form::prob(vec![6, 7])\n",
    "    );\n",
    "    assert_eq!(simplify_product(&f), simple, \"failed with nested quotients\");\n",
    "\n",
    "    // ensure it merges with nested products\n",
    "    let f = Form::product(vec![\n",
    "        Form::product(vec![\n",
    "            Form::prob(vec![0, 3])\n",
    "        ]),\n",
    "        Form::product(vec![\n",
    "            Form::prob(vec![4]),\n",
    "            Form::prob(vec![6, 7]),\n",
    "        ]),\n",
    "    ]);\n",
    "    let simple = Form::product(vec![\n",
    "        Form::prob(vec![0, 3]),\n",
    "        Form::prob(vec![4]),\n",
    "        Form::prob(vec![6, 7]),\n",
    "    ]);\n",
    "    assert_eq!(simplify_product(&f), simple, \"failed with nested products\");\n",
    "\n",
    "    // nested marginals\n",
    "    let f = Form::product(vec![\n",
    "        Form::product(vec![\n",
    "            Form::prob(vec![0, 3])\n",
    "        ]),\n",
    "        Form::marginal(set![0, 1], Form::prob(vec![0, 1, 2])),\n",
    "    ]);\n",
    "    let simple = Form::product(vec![\n",
    "        Form::prob(vec![0, 3]),\n",
    "        Form::marginal(set![0, 1], Form::prob(vec![0, 1, 2])),\n",
    "    ]);\n",
    "    assert_eq!(simplify_product(&f), simple, \"failed with nested marginals\");\n",
    "}\n",
    "\n",
    "#[test]\n",
    "fn test_simplify_quotient () {\n",
    "    // ensure it merges with nested products\n",
    "    let f = Form::quotient(\n",
    "        Form::quotient(\n",
    "                Form::prob(vec![0, 3]),\n",
    "                Form::product(vec![\n",
    "                    Form::prob(vec![4]),\n",
    "                    Form::prob(vec![6, 7]),\n",
    "                ]),\n",
    "            ),\n",
    "        Form::quotient(Form::prob(vec![8]), Form::prob(vec![9]))\n",
    "    );\n",
    "    let simple = Form::quotient(\n",
    "        Form::product(vec![\n",
    "            Form::prob(vec![0, 3]),\n",
    "            Form::prob(vec![9]),\n",
    "        ]),\n",
    "        Form::product(\n",
    "            vec![\n",
    "                Form::prob(vec![4]),\n",
    "                Form::prob(vec![6, 7]),\n",
    "                Form::prob(vec![8]),\n",
    "            ]\n",
    "        )\n",
    "    );\n",
    "    assert_eq!(simplify_quotient(&f), simple, \"failed with nested quotients top/bottom\");\n",
    "\n",
    "    // ensure it cancels identical terms\n",
    "    let f = Form::quotient(\n",
    "        Form::product(vec![\n",
    "            Form::prob(vec![0]),\n",
    "            Form::prob(vec![1]),\n",
    "        ]),\n",
    "        Form::prob(vec![1]),\n",
    "    );\n",
    "    let simple = Form::prob(vec![0]);\n",
    "    assert_eq!(simplify_quotient(&f), simple, \"failed to cancel\");\n",
    "\n",
    "    let f = Form::quotient(\n",
    "        Form::product(vec![\n",
    "            Form::prob(vec![0, 1, 2]),\n",
    "            Form::prob(vec![1, 2]),\n",
    "            Form::prob(vec![2]),\n",
    "        ]),\n",
    "        Form::product(vec![\n",
    "            Form::prob(vec![2, 1]),\n",
    "            Form::prob(vec![2]),\n",
    "        ])\n",
    "    );\n",
    "    let simple = Form::prob(vec![0, 1, 2]);\n",
    "    assert_eq!(simplify_quotient(&f), simple, \"failed to cancel (#2)\");\n",
    "}\n",
    "\n",
    "#[test]\n",
    "fn test_simplify () {\n",
    "    // test two nested quotients\n",
    "    let f = Form::quotient(\n",
    "        Form::quotient(\n",
    "            Form::prob(vec![0]),\n",
    "            Form::prob(vec![1]),\n",
    "        ),\n",
    "        Form::prob(vec![2, 3])\n",
    "    );\n",
    "    let simplified = simplify(&f).sorted();\n",
    "    let simple = Form::quotient(\n",
    "        Form::prob(vec![0]),\n",
    "        Form::product(vec![\n",
    "            Form::prob(vec![1]),\n",
    "            Form::prob(vec![2, 3]),\n",
    "        ])\n",
    "    ).sorted();\n",
    "    assert_eq!(simplified, simple, \"{:?} should equal {:?}\", simplified, simple);\n",
    "\n",
    "    // test three nested quotients\n",
    "    let f = Form::quotient(\n",
    "        Form::quotient(\n",
    "            Form::quotient(\n",
    "                Form::prob(vec![0]),\n",
    "                Form::prob(vec![1]),\n",
    "            ),\n",
    "            Form::prob(vec![2]),\n",
    "        ),\n",
    "        one()\n",
    "    );\n",
    "    let simplified = simplify(&f).sorted();\n",
    "    let simple = Form::quotient(\n",
    "        Form::prob(vec![0]),\n",
    "        Form::product(vec![\n",
    "            Form::prob(vec![1]),\n",
    "            Form::prob(vec![2]),\n",
    "        ])\n",
    "    );\n",
    "    assert_eq!(simplified, simple, \"{:?} should equal {:?}\", simplified, simple);\n",
    "\n",
    "    // merging with nested quotients\n",
    "    let f = Form::quotient(\n",
    "        Form::product(vec![\n",
    "                Form::prob(vec![0, 3]),\n",
    "                Form::quotient(\n",
    "                    Form::prob(vec![4]),\n",
    "                    Form::prob(vec![6, 7]),\n",
    "                ),\n",
    "            ]),\n",
    "        Form::prob(vec![8, 9])\n",
    "    );\n",
    "    let simplified = simplify(&f).sorted();\n",
    "    let simple = Form::quotient(\n",
    "        Form::product(vec![\n",
    "            Form::prob(vec![0, 3]),\n",
    "            Form::prob(vec![4]),\n",
    "        ]),\n",
    "        Form::product(vec![\n",
    "            Form::prob(vec![6, 7]),\n",
    "            Form::prob(vec![8, 9]),\n",
    "        ])\n",
    "    );\n",
    "    assert_eq!(simplified, simple, \"{:?} should equal {:?}\", simplified, simple);\n",
    "}\n",
    "\n",
    "// #[test]\n",
    "// fn test_factorize() {\n",
    "//     let p = Form::prob(vec![0, 1, 2]);\n",
    "//     let factorized = Form::factorize(vec![0, 1, 2], p);\n",
    "//     assert_eq!(\n",
    "//         factorized,\n",
    "//         Form::product(vec![\n",
    "//             Form::cond_prob(vec![0], vec![1, 2]),\n",
    "//             Form::cond_prob(vec![1], vec![2]),\n",
    "//             Form::prob(vec![2])\n",
    "//         ])\n",
    "//     );\n",
    "// }\n",
    "\n",
    "// #[test]\n",
    "// fn test_simplify() {\n",
    "//     let f = {\n",
    "//         Form::product(vec![\n",
    "//             Form::product(vec![\n",
    "//                 Form::prob(vec![0, 3])\n",
    "//             ]),\n",
    "//             Form::quotient(\n",
    "//                 Form::prob(vec![4]),\n",
    "//                 Form::prob(vec![6, 7]),\n",
    "//             ),\n",
    "//         ])\n",
    "//     };\n",
    "\n",
    "//     let simple = {\n",
    "//         Form::quotient(Form::product(vec![Form::prob(vec![0, 3])]), denom)\n",
    "//     };\n",
    "\n",
    "//     assert_eq!(f.simplify(), Form::marginal(set![], Form))\n",
    "// }\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```rust\n",
    "// test_form.rs\n",
    "\n",
    "use super::{\n",
    "    form::Form,\n",
    "};\n",
    "\n",
    "use crate::{utils::defaults::{set, Set}, model::examples::frontdoor_model, identification::id_no_simplify, api::wrapper::ModelWrapper};\n",
    "\n",
    "#[test]\n",
    "fn test_sort () {\n",
    "    let f = Form::prob(vec![1, 2, 0]).sorted();\n",
    "    let s = Form::prob(vec![0, 1, 2]);\n",
    "    assert_eq!(f, Form::prob(vec![0, 1, 2]), \"{:?} should equal {:?}\", f, s);\n",
    "}\n",
    "\n",
    "#[test]\n",
    "fn test_structural_eq () {\n",
    "    let f1 = Form::product(vec![\n",
    "        Form::prob(vec![0, 3]),\n",
    "        Form::prob(vec![4]),\n",
    "        Form::prob(vec![6, 7]),\n",
    "    ]);\n",
    "    let f2 = Form::product(vec![\n",
    "        Form::prob(vec![6, 7]),\n",
    "        Form::prob(vec![0, 3]),\n",
    "        Form::prob(vec![4]),\n",
    "    ]);\n",
    "    assert!(f1.structural_eq(&f2));\n",
    "\n",
    "    // more complex test involving quotients\n",
    "    let f1 = Form::quotient(\n",
    "        Form::product(vec![\n",
    "            Form::prob(vec![0, 3]),\n",
    "            Form::prob(vec![4]),\n",
    "            Form::prob(vec![6, 7]),\n",
    "        ]),\n",
    "        Form::prob(vec![0, 1, 2]),\n",
    "    );\n",
    "    let f2 = Form::quotient(\n",
    "        Form::product(vec![\n",
    "            Form::prob(vec![6, 7]),\n",
    "            Form::prob(vec![0, 3]),\n",
    "            Form::prob(vec![4]),\n",
    "        ]),\n",
    "        Form::prob(vec![0, 1, 2]),\n",
    "    );\n",
    "    assert!(f1.structural_eq(&f2));\n",
    "\n",
    "    // joint probabilities with different orders\n",
    "    let f1 = Form::prob(vec![0, 1, 2]);\n",
    "    let f2 = Form::prob(vec![2, 0, 1]);\n",
    "    assert!(f1.structural_eq(&f2), \"{:?} should equal {:?}\", f1, f2);\n",
    "\n",
    "    // test nested unorder probabilities\n",
    "    let f1 = Form::product(vec![\n",
    "        Form::prob(vec![0, 3]),\n",
    "        Form::prob(vec![4]),\n",
    "        Form::prob(vec![6, 7]),\n",
    "    ]);\n",
    "    let f2 = Form::product(vec![\n",
    "        Form::prob(vec![6, 7]),\n",
    "        Form::prob(vec![3, 0]),\n",
    "        Form::prob(vec![4]),\n",
    "    ]);\n",
    "    assert!(f1.structural_eq(&f2), \"{:?} should equal {:?}\", f1, f2);\n",
    "\n",
    "    // test involving quotients of marginals\n",
    "    let f1 = Form::quotient(\n",
    "        Form::marginal(\n",
    "            set![0, 1],\n",
    "            Form::product(vec![\n",
    "                Form::prob(vec![0, 1, 2]),\n",
    "                Form::prob(vec![3, 4, 5]),\n",
    "                ])),\n",
    "        Form::prob(vec![0, 1, 2]),\n",
    "    );\n",
    "    let f2 = Form::quotient(\n",
    "        Form::marginal(\n",
    "            set![1, 0],\n",
    "            Form::product(vec![\n",
    "                Form::prob(vec![3, 4, 5]),\n",
    "                Form::prob(vec![0, 1, 2]),\n",
    "                ])),\n",
    "        Form::prob(vec![0, 1, 2]),\n",
    "    );\n",
    "    assert!(f1.structural_eq(&f2), \"{:?} should equal {:?}\", f1, f2);  \n",
    "\n",
    "    // test involving quotients of marginals\n",
    "    let f1 = Form::quotient(\n",
    "        Form::marginal(\n",
    "            set![0, 1],\n",
    "            Form::product(vec![\n",
    "                Form::prob(vec![0, 1, 2]),\n",
    "                Form::prob(vec![3, 4, 5]),\n",
    "                ])),\n",
    "        Form::prob(vec![0, 1, 2]),\n",
    "    );\n",
    "    let f2 = Form::quotient(\n",
    "        Form::marginal(\n",
    "            set![1, 0],\n",
    "            Form::product(vec![\n",
    "                Form::prob(vec![4, 5, 3]),\n",
    "                Form::prob(vec![0, 1, 2]),\n",
    "                ])),\n",
    "        Form::prob(vec![0, 1, 2]),\n",
    "    );\n",
    "    assert!(f1.structural_eq(&f2), \"{:?} should equal {:?}\", f1, f2);   \n",
    "\n",
    "}\n",
    "\n",
    "#[test]\n",
    "fn test_factorize_subset() {\n",
    "    let model = frontdoor_model();\n",
    "    let order = model.order_vec();\n",
    "    let p = model.p();\n",
    "\n",
    "    let f = Form::factorize_subset(order, p, &set![0, 2]);\n",
    "    let ans = Form::quotient(\n",
    "        Form::product(vec![Form::prob(vec![0]), Form::cond_prob(vec![0, 1, 2], vec![])]),\n",
    "        Form::prob(vec![0, 1])\n",
    "    );\n",
    "\n",
    "    assert_eq!(f.simplify(), ans.simplify());\n",
    "}\n",
    "\n",
    "#[test]\n",
    "fn demonstrate_simplify() {\n",
    "    let m = frontdoor_model();\n",
    "    let f_raw = id_no_simplify(&m, &set![2], &set![0]);\n",
    "    let f = m.id(&set![2], &set![0]);\n",
    "\n",
    "    let mut foo = ModelWrapper::new();\n",
    "    foo.add_effect(\"X\", \"Z\");\n",
    "    foo.add_effect(\"Z\", \"Y\");\n",
    "    foo.add_confounding(\"X\", \"Y\");\n",
    "\n",
    "    let f_json = ModelWrapper::form_sub(&foo, f).to_json();\n",
    "    let f_raw_json = ModelWrapper::form_sub(&foo, f_raw).to_json();\n",
    "\n",
    "    println!(\"f_raw = {:?}\", f_raw_json);\n",
    "    println!(\"f = {:?}\", f_json);\n",
    "    assert!(false);\n",
    "}\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```rust\n",
    "// bigraph.rs\n",
    "\n",
    "use super::{Graph, Constructable, Set, Map, Node, GraphBuilder};\n",
    "use std::rc::Rc;\n",
    "use crate::utils::set_utils::{union, difference};\n",
    "\n",
    "#[derive(Debug, Clone)]\n",
    "pub struct BiGraph {\n",
    "    edges: Rc<Map<Node, Set<Node>>>,\n",
    "    nodes: Box<Set<Node>>,\n",
    "}\n",
    "\n",
    "impl Constructable for BiGraph {\n",
    "    fn from_elems(edges: Map<Node, Set<Node>>, nodes: Set<Node>) -> Self {\n",
    "        BiGraph {\n",
    "            edges: Rc::new(edges),\n",
    "            nodes: Box::new(nodes),\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "impl Graph for BiGraph {\n",
    "    fn get_nodes(&self) -> &Set<Node> {\n",
    "        &self.nodes\n",
    "    }\n",
    "\n",
    "    fn subgraph(&self, nodes: &Set<Node>) -> Self {\n",
    "        BiGraph {\n",
    "            edges: self.edges.clone(),\n",
    "            nodes: Box::new(nodes.clone()),\n",
    "        }\n",
    "    }\n",
    "\n",
    "    fn r#do(&self, nodes: &Set<Node>) -> Self {\n",
    "        let mut edges = Map::new();\n",
    "        for (from, to) in self.edges.iter() {\n",
    "            if !nodes.contains(from) {\n",
    "                edges.insert(*from, difference(to, nodes));\n",
    "            }\n",
    "        }\n",
    "\n",
    "        BiGraph {\n",
    "            edges: Rc::new(edges),\n",
    "            nodes: self.nodes.clone(),\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "impl BiGraph {\n",
    "    pub fn from_edges(edges: Vec<(Node, Node)>) -> BiGraph {\n",
    "        GraphBuilder::to_bigraph(GraphBuilder::from_edges(edges))\n",
    "    }\n",
    "\n",
    "    pub fn from_edges_nodes(edges: Vec<(Node, Node)>, nodes: Vec<Node>) -> BiGraph {\n",
    "        GraphBuilder::to_bigraph(GraphBuilder::from_edges_nodes(edges, nodes))\n",
    "    }\n",
    "\n",
    "    pub fn get_component (&self, node: Node) -> Set<Node> {\n",
    "        let mut acc = Set::new();\n",
    "        let mut queue = Vec::from([node]);\n",
    "        loop {\n",
    "            match queue.pop() {\n",
    "                None => break,\n",
    "                Some(node) => {\n",
    "                    if self.nodes.contains(&node) && acc.insert(node) {\n",
    "                        match self.edges.get(&node) {\n",
    "                            Some(siblings) => queue.extend(siblings),\n",
    "                            None => {}\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "        return acc;\n",
    "    }\n",
    "\n",
    "    pub fn c_components (&self) -> Vec<Set<Node>> {\n",
    "        let mut unvisited: Set<Node> = self.nodes.iter().cloned().collect();\n",
    "        let mut components = Vec::new();\n",
    "\n",
    "        for node in self.nodes.iter() {\n",
    "            if unvisited.contains(node) {\n",
    "                let node_component = self.get_component(*node);\n",
    "                for sibling in node_component.iter() {\n",
    "                    unvisited.remove(sibling);\n",
    "                }\n",
    "                components.push(node_component);\n",
    "            }\n",
    "        }\n",
    "\n",
    "        return components;\n",
    "    }\n",
    "}\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```rust\n",
    "// digraph.rs\n",
    "\n",
    "use crate::{utils::set_utils::{difference, make_set}, set};\n",
    "\n",
    "use super::{Graph, Constructable, Set, Map, Node, GraphBuilder};\n",
    "use std::rc::Rc;\n",
    "\n",
    "#[derive(Debug, Clone)]\n",
    "pub struct DiGraph {\n",
    "    edges: Rc<Map<Node, Set<Node>>>,\n",
    "    nodes: Box<Set<Node>>,\n",
    "}\n",
    "\n",
    "impl DiGraph {\n",
    "    pub fn from_edges (edges: Vec<(Node, Node)>) -> DiGraph {\n",
    "        GraphBuilder::to_digraph(GraphBuilder::from_edges(edges))\n",
    "    }\n",
    "\n",
    "    pub fn from_edges_nodes(edges: Vec<(Node, Node)>, nodes: Vec<Node>) -> DiGraph {\n",
    "        GraphBuilder::to_digraph(GraphBuilder::from_edges_nodes(edges, nodes))\n",
    "    }\n",
    "\n",
    "    pub fn children(&self, x: &Node) -> Set<Node> {\n",
    "        let mut acc = set![];\n",
    "        for (k, v) in self.edges.iter() {\n",
    "            if self.nodes.contains(&k) && v.contains(x) {\n",
    "                acc.insert(*k);\n",
    "            }\n",
    "        }\n",
    "        return acc;\n",
    "    }\n",
    "\n",
    "    pub fn parents (&self, x: Node) -> Set<Node> {\n",
    "        let empty = Set::new();\n",
    "        let elems = match self.edges.get(&x) {\n",
    "            Some(kids) => kids,\n",
    "            None => &empty,\n",
    "        };\n",
    "        let filtered = elems.into_iter()\n",
    "            .filter(|elem| self.nodes.contains(*elem))\n",
    "            .map(|elem| *elem);\n",
    "        return Set::from_iter(filtered);\n",
    "    }\n",
    "\n",
    "    pub fn ancestors (&self, x: Node) -> Set<Node> {\n",
    "        self.ancestors_set(&Set::from([x]))\n",
    "    }\n",
    "\n",
    "    // TODO: by default, x should be considered a subset of ancestors of x\n",
    "    // otherwise semantics too tricky when one element in set is ancestor of another\n",
    "    pub fn ancestors_set (&self, x: &Set<Node>) -> Set<Node> {\n",
    "        if !x.is_subset(&self.nodes) {\n",
    "            panic!(\"cannot find ancestors of {:?} in DiGraph {:?} because not all queried\n",
    "                nodes were found in the graph\", x, self);\n",
    "        }\n",
    "\n",
    "        let mut acc = make_set(x.iter().cloned());\n",
    "        let mut queue = Vec::new();\n",
    "        queue.extend(x);\n",
    "        \n",
    "        for _ in 0..(self.nodes.len() + 1) {\n",
    "            match queue.pop() {\n",
    "                Some(elem) => {\n",
    "                    for parent in self.parents(elem) {\n",
    "                        if self.nodes.contains(&parent) {\n",
    "                            if acc.insert(parent) {\n",
    "                                queue.push(parent);\n",
    "                            }\n",
    "                        }\n",
    "                    }\n",
    "                },\n",
    "                None => {\n",
    "                    // TODO this is awkward\n",
    "                    for val in x {\n",
    "                        acc.remove(val);\n",
    "                    }\n",
    "                    return acc;\n",
    "                },\n",
    "            }\n",
    "        }\n",
    "\n",
    "        panic!(\"infinite loop detected: cannot find ancestors of {:?} in DiGraph {:?}\",\n",
    "            x, self);\n",
    "    }\n",
    "\n",
    "    pub fn root_set(&self) -> Vec<Node> {\n",
    "        return self.count_parents().iter()\n",
    "            .filter(|(_, v)| **v == 0)\n",
    "            .map(|(k, _)| *k)\n",
    "            .collect();\n",
    "    }\n",
    "\n",
    "    pub fn count_parents(&self) -> Map<Node, i32> {\n",
    "        let mut n_parents: Map<Node, i32> = Map::new();\n",
    "        for x in self.nodes.iter() {\n",
    "            n_parents.insert(*x, 0);\n",
    "        }\n",
    "\n",
    "        for x in self.nodes.iter() {\n",
    "            for p in self.parents(*x) {\n",
    "                n_parents.entry(p).and_modify(|e| {*e += 1});\n",
    "            }\n",
    "        }\n",
    "\n",
    "        return n_parents;\n",
    "    }\n",
    "\n",
    "    pub fn order(&self) -> Vec<Node> {\n",
    "        let mut n_parents = self.count_parents();\n",
    "        let mut lst = vec![];\n",
    "        let mut queue = vec![];\n",
    "        for (k, v) in n_parents.iter() {\n",
    "            if *v == 0 {\n",
    "                lst.push(*k);\n",
    "                queue.push(*k);\n",
    "            }\n",
    "        }\n",
    "\n",
    "        loop {\n",
    "            match queue.pop() {\n",
    "                Some(x) => {\n",
    "                    for p in self.parents(x) {\n",
    "                        n_parents.entry(p).and_modify(|e| *e -= 1);\n",
    "                        if n_parents[&p] == 0 {\n",
    "                            queue.push(p);\n",
    "                            lst.push(p);\n",
    "                        }\n",
    "                    }\n",
    "                },\n",
    "                None => break\n",
    "            }\n",
    "        }\n",
    "\n",
    "        return lst;\n",
    "    }\n",
    "\n",
    "}\n",
    "\n",
    "impl Constructable for DiGraph {\n",
    "    fn from_elems(edges: Map<Node, Set<Node>>, nodes: Set<Node>) -> Self {\n",
    "        DiGraph {\n",
    "            edges: Rc::new(edges),\n",
    "            nodes: Box::new(nodes),\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "impl Graph for DiGraph {\n",
    "    fn get_nodes(&self) -> &Set<Node> {\n",
    "        &*self.nodes\n",
    "        // yo mama so ugly\n",
    "    }\n",
    "\n",
    "    fn subgraph(&self, nodes: &Set<Node>) -> Self {\n",
    "        DiGraph {\n",
    "            edges: Rc::clone(&self.edges),\n",
    "            nodes: Box::new(nodes.clone()),\n",
    "        }\n",
    "    }\n",
    "\n",
    "    fn r#do(&self, nodes: &Set<Node>) -> Self {\n",
    "        let mut edges = Map::new();\n",
    "        for (from, to) in self.edges.iter() {\n",
    "            if !nodes.contains(from) {\n",
    "                edges.insert(*from, to.clone());\n",
    "            }\n",
    "        }\n",
    "\n",
    "        DiGraph {\n",
    "            edges: Rc::new(edges),\n",
    "            nodes: self.nodes.clone(),\n",
    "        }\n",
    "    }\n",
    "}\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```rust\n",
    "// graph_builder.rs\n",
    "\n",
    "use std::fmt::Debug;\n",
    "use super::{\n",
    "    Constructable,\n",
    "    Node,\n",
    "    BiGraph,\n",
    "    DiGraph,\n",
    "    Map,\n",
    "    Set, Graph,\n",
    "};\n",
    "\n",
    "#[derive(Debug, Clone)]\n",
    "pub struct GraphBuilder {\n",
    "    pub nodes: Set<Node>,\n",
    "    pub edges: Map<Node, Set<Node>>\n",
    "}\n",
    "\n",
    "impl GraphBuilder {\n",
    "    pub fn new () -> GraphBuilder {\n",
    "        return GraphBuilder {\n",
    "            edges: Map::new(),\n",
    "            nodes: Set::new(),\n",
    "        };\n",
    "    }\n",
    "\n",
    "    pub fn from_edges(edges: Vec<(Node, Node)>) -> GraphBuilder {\n",
    "        let mut gb = GraphBuilder::new();\n",
    "        for (a, b) in edges {\n",
    "            gb.add_edge(a, b);\n",
    "        }\n",
    "        return gb;\n",
    "    }\n",
    "\n",
    "    pub fn from_edges_nodes(edges: Vec<(Node, Node)>, nodes: Vec<Node>) -> GraphBuilder {\n",
    "        let mut gb = GraphBuilder::from_edges(edges);\n",
    "        for n in nodes {\n",
    "            gb.add_node(n);\n",
    "        }\n",
    "        return gb;\n",
    "    }\n",
    "\n",
    "    pub fn add_node(&mut self, node: Node) {\n",
    "        self.nodes.insert(node);\n",
    "    }\n",
    "\n",
    "    pub fn add_edge(&mut self, from: Node, to: Node) {\n",
    "        self.nodes.extend([from, to]);\n",
    "        self.edges.entry(from).or_insert(Set::new());\n",
    "        self.edges.entry(from).and_modify(|s| {s.insert(to);});\n",
    "    }\n",
    "\n",
    "    pub fn get_nodes(&self) -> Set<Node> {\n",
    "        let mut new = Set::new();\n",
    "        for node in self.nodes.iter() {\n",
    "            new.insert(*node);\n",
    "        }\n",
    "        return new;\n",
    "    }\n",
    "\n",
    "    pub fn get_edges (&self) -> &Map<Node, Set<Node>> {\n",
    "        &self.edges\n",
    "    }\n",
    "\n",
    "    pub fn to_digraph (builder: GraphBuilder) -> DiGraph {\n",
    "        DiGraph::from_elems(builder.edges, builder.nodes)\n",
    "    }\n",
    "\n",
    "    pub fn to_bigraph<'a>(builder: GraphBuilder) -> BiGraph {\n",
    "        let mut edges: Map<Node, Set<Node>> = Map::new();\n",
    "        for (from, to) in builder.edges.iter() {\n",
    "            edges.entry(*from).or_insert(Set::new());\n",
    "            for target in to {\n",
    "                edges.entry(*target).or_insert(Set::new());\n",
    "                edges.entry(*from).and_modify(|b| {b.insert(*target);});\n",
    "                edges.entry(*target).and_modify(|b| {b.insert(*from);});\n",
    "            }\n",
    "        }\n",
    "        BiGraph::from_elems(edges, builder.nodes)\n",
    "    }\n",
    "}\n",
    "\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```rust\n",
    "// graph.rs\n",
    "\n",
    "use super::{Node, Map, Set, GraphBuilder};\n",
    "\n",
    "pub trait Graph {\n",
    "    fn subgraph(&self, nodes: &Set<Node>) -> Self;\n",
    "    fn r#do(&self, nodes: &Set<Node>) -> Self;\n",
    "    fn get_nodes(&self) -> &Set<Node>;\n",
    "}\n",
    "\n",
    "pub trait Constructable {\n",
    "    fn from_elems(edges: Map<Node, Set<Node>>, nodes: Set<Node>) -> Self;\n",
    "}\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```rust\n",
    "// mod.rs\n",
    "\n",
    "mod tests;\n",
    "mod graph;\n",
    "mod graph_builder;\n",
    "mod bigraph;\n",
    "mod digraph;\n",
    "mod node;\n",
    "\n",
    "pub use graph_builder::GraphBuilder;\n",
    "pub use graph::{Graph, Constructable};\n",
    "pub use digraph::DiGraph;\n",
    "pub use bigraph::BiGraph;\n",
    "pub use node::{Node, make_nodes};\n",
    "\n",
    "use std::collections::{HashMap as Map, HashSet as Set};\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```rust\n",
    "// node.rs\n",
    "\n",
    "use rand::{thread_rng, Rng};\n",
    "\n",
    "pub type Node = i32;\n",
    "\n",
    "pub fn make_nodes(n: i32) -> Vec<Node> {\n",
    "    let mut nodes: Vec<Node> = Vec::new();\n",
    "    let mut rng = rand::thread_rng();\n",
    "    for _ in 0..n {\n",
    "        nodes.push(rng.gen());\n",
    "    }\n",
    "    nodes\n",
    "}\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```rust\n",
    "// tests.rs\n",
    "\n",
    "#![cfg(test)]\n",
    "\n",
    "use crate::{model::{self, examples::frontdoor_model}, utils::set_utils::make_set, set};\n",
    "use super::{GraphBuilder, Set, DiGraph, BiGraph, Graph, node::{Node, make_nodes}};\n",
    "\n",
    "#[test]\n",
    "fn test_graph_builder () {\n",
    "    let mut gb = GraphBuilder::new();\n",
    "    let (a, b, c, d) = (1, 2, 3, 4);\n",
    "\n",
    "    gb.add_edge(a, b);\n",
    "    assert!(gb.get_nodes().contains(&a));\n",
    "    assert!(!gb.get_nodes().contains(&c));\n",
    "\n",
    "    gb.add_node(c);\n",
    "    assert!(gb.get_nodes().contains(&c));\n",
    "    assert!(!gb.get_nodes().contains(&d));\n",
    "    assert!(gb.get_edges().contains_key(&a));\n",
    "    assert!(gb.get_edges()[&a] == Set::from([b]));\n",
    "}\n",
    "\n",
    "#[test]\n",
    "fn test_to_digraph () {\n",
    "    let mut gb = GraphBuilder::new();\n",
    "    let (a, b, c) = (1, 2, 3);\n",
    "\n",
    "    gb.add_edge(a, b);\n",
    "    gb.add_node(c);\n",
    "    let dg = GraphBuilder::to_digraph(gb);\n",
    "\n",
    "    assert_eq!(make_set(dg.root_set().into_iter()), set![a, c], \"root set\");\n",
    "    assert_eq!(dg.ancestors(a), Set::from([b]), \"ancestors a\");\n",
    "    assert_eq!(dg.order().last(), Some(&b));\n",
    "    assert_eq!(dg.order().len(), 3);\n",
    "    assert_eq!(dg.count_parents()[&b], 1);\n",
    "    assert_eq!(dg.count_parents()[&a], 0);\n",
    "    assert_eq!(dg.count_parents()[&c], 0);\n",
    "}\n",
    "\n",
    "#[test]\n",
    "fn test_ancestors () {\n",
    "    let (a, b, c, d) = (1, 2, 3, 4);\n",
    "    let graph = DiGraph::from_edges(vec![\n",
    "        (a, b),\n",
    "        (a, c),\n",
    "        (b, d),\n",
    "        (c, d),\n",
    "    ]);\n",
    "    assert_eq!(graph.ancestors(a), Set::from([b, c, d]), \"ancestors a\");\n",
    "    assert_eq!(graph.ancestors(b), Set::from([d]), \"ancestors b\");\n",
    "    assert_eq!(graph.ancestors(c), Set::from([d]), \"ancestors d\");\n",
    "    assert_eq!(graph.ancestors(d), Set::from([]), \"ancestors c\");\n",
    "\n",
    "    let abd = graph.subgraph(&Set::from([a, b, d]));\n",
    "    assert_eq!(abd.ancestors(a), Set::from([b, d]), \"subg ancestors a\");\n",
    "    assert_eq!(abd.ancestors(b), Set::from([d]), \"subg ancestors b\");\n",
    "    \n",
    "    let intv = graph.r#do(&Set::from([b, c]));\n",
    "    assert_eq!(intv.ancestors(a), Set::from([b, c]), \"intv ancestors a\");\n",
    "    assert_eq!(intv.ancestors(b), Set::new(), \"intv ancestors b\");\n",
    "}\n",
    "\n",
    "#[test]\n",
    "fn test_ancestors_set () {\n",
    "    /*\n",
    "    causal diagram\n",
    "\n",
    "    1 <--- 2 <------ 4 <--\n",
    "        |        |        |\n",
    "         -- 3 <--         |\n",
    "        |                 |\n",
    "    5 <------------------ 6\n",
    "\n",
    "    */\n",
    "    let graph = DiGraph::from_edges(vec![\n",
    "        (1, 2),\n",
    "        (1, 3),\n",
    "        (2, 4),\n",
    "        (3, 4),\n",
    "        (5, 3),\n",
    "        (4, 6),\n",
    "        (5, 6),\n",
    "    ]);\n",
    "    assert_eq!(graph.ancestors_set(&Set::from([])), Set::from([]));\n",
    "    assert_eq!(graph.ancestors_set(&Set::from([2, 5])), Set::from([3, 4, 6]));\n",
    "    assert_eq!(\n",
    "        graph.r#do(&set![4]).ancestors_set(&Set::from([1])),\n",
    "        Set::from([2, 3, 4])\n",
    "    );\n",
    "    assert_eq!(\n",
    "        graph.r#do(&set![4]).ancestors_set(&set![1, 5]),\n",
    "        Set::from([2, 3, 4, 6])\n",
    "    );\n",
    "\n",
    "}\n",
    "\n",
    "#[test]\n",
    "fn test_ancestors_backdoor() {\n",
    "    let graph = DiGraph::from_edges(vec![\n",
    "        (1, 0),\n",
    "        (2, 1),\n",
    "        (2, 0),\n",
    "    ]);\n",
    "    assert_eq!(graph.ancestors(2), set!(0, 1));\n",
    "\n",
    "    let a_y_intervene_x = graph.r#do(&set![1]).ancestors(2);\n",
    "    assert_eq!(a_y_intervene_x, set![0, 1]);\n",
    "}\n",
    "\n",
    "#[test]\n",
    "fn test_ancestors_frontdoor() {\n",
    "    let fd = frontdoor_model();\n",
    "    assert_eq!(fd.ancestors_set_inc(&set!(2, 0)), set!(2, 1, 0));\n",
    "}\n",
    "\n",
    "#[test]\n",
    "fn test_root_set () {\n",
    "    let (a, b, c, d) = (1, 2, 3, 4);\n",
    "\n",
    "    let graph = DiGraph::from_edges(vec![\n",
    "        (a, b),\n",
    "        (a, c),\n",
    "        (b, d),\n",
    "        (c, d),\n",
    "    ]);\n",
    "    assert_eq!(graph.root_set(), Vec::from([a]));\n",
    "\n",
    "    let graph = DiGraph::from_edges(vec![\n",
    "        (a, c),\n",
    "        (b, c),\n",
    "        (c, d),\n",
    "    ]);\n",
    "    assert_eq!(make_set(graph.root_set().into_iter()), Set::from([a, b]));\n",
    "}\n",
    "\n",
    "#[test]\n",
    "fn test_to_bigraph () {\n",
    "    let mut gb = GraphBuilder::new();\n",
    "    let (a, b, c) = (1, 2, 3);\n",
    "\n",
    "    gb.add_edge(a, b);\n",
    "    gb.add_node(c);\n",
    "    let bg = GraphBuilder::to_bigraph(gb);\n",
    "\n",
    "    assert!(bg.c_components() == vec![Set::from([a, b]), Set::from([c])] ||\n",
    "            bg.c_components() == vec![Set::from([c]), Set::from([a, b])],\n",
    "            \"Failed because: bg.c_components() == {:#?}\", bg.c_components())\n",
    "}\n",
    "\n",
    "#[test]\n",
    "fn test_c_components () {\n",
    "\n",
    "    fn component_products(components: Vec<Set<i32>>) -> Set<i32> {\n",
    "        let mut acc = Set::new();\n",
    "        for c in components {\n",
    "            let mut val = 1;\n",
    "            for el in c {\n",
    "                val = val * el;\n",
    "            }\n",
    "            acc.insert(val);\n",
    "        }\n",
    "        return acc;\n",
    "    }\n",
    "\n",
    "    let (a, b, c, d, e, f) = (2, 3, 5, 7, 11, 13);\n",
    "    let graph = BiGraph::from_edges_nodes(vec![\n",
    "        (a, b),\n",
    "        (b, c),\n",
    "        (c, d),\n",
    "        (e, c),\n",
    "    ], vec![f]);\n",
    "    let cs = component_products(graph.c_components());\n",
    "    assert_eq!(cs.len(), 2);\n",
    "    assert!(cs.contains(&f));\n",
    "\n",
    "    let graph = BiGraph::from_edges_nodes(vec![\n",
    "        (a, b),\n",
    "        (b, c),\n",
    "        (c, b),\n",
    "        (e, f),\n",
    "    ], vec![d]);\n",
    "    let cs = component_products(graph.c_components());\n",
    "    assert_eq!(cs, Set::from([30, 143, 7]));\n",
    "\n",
    "    let graph = BiGraph::from_edges_nodes(vec![], vec![a, b, c, d, e, f]);\n",
    "    let cs = component_products(graph.c_components());\n",
    "    assert_eq!(cs, Set::from([a, b, c, d, e, f]));\n",
    "\n",
    "}\n",
    "\n",
    "#[test]\n",
    "fn test_c_components_backdoor() {\n",
    "    let model = model::examples::backdoor_model();\n",
    "\n",
    "    let c_components = model.confounded.c_components();\n",
    "    assert_eq!(c_components.len(), 3);\n",
    "    for component in c_components.iter() {\n",
    "        assert_eq!(component.len(), 1);\n",
    "    }\n",
    "    \n",
    "    let subgraph_c_components =  model.subgraph(&set![0, 2]).confounded.c_components();\n",
    "    assert_eq!(subgraph_c_components.len(), 2);\n",
    "    assert_ne!(subgraph_c_components[0], subgraph_c_components[1]);\n",
    "}\n",
    "\n",
    "#[test]\n",
    "fn test_random_nodes_len () {\n",
    "    let n0 = make_nodes(0);\n",
    "    let n1 = make_nodes(1);\n",
    "    let n15 = make_nodes(15);\n",
    "\n",
    "    assert_eq!(n0.len(), 0);\n",
    "    assert_eq!(n1.len(), 1);\n",
    "    assert_eq!(n15.len(), 15);\n",
    "}\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```rust\n",
    "// mod.rs\n",
    "\n",
    "mod shpitser;\n",
    "mod tests;\n",
    "pub use shpitser::{id, id_no_simplify};\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```rust\n",
    "// shpitser.rs\n",
    "\n",
    "use cute::c;\n",
    "use crate::{\n",
    "    graph::{Node, Graph},\n",
    "    form::Form,\n",
    "    model::Model,\n",
    "    utils::{\n",
    "        defaults::{Set, Map},\n",
    "        set_utils::{union, intersection, difference, make_set},\n",
    "    }\n",
    "};\n",
    "\n",
    "pub fn id_no_simplify(model: &Model, y: &Set<Node>, x: &Set<Node>) -> Form {\n",
    "    let observed = model.get_observed();\n",
    "    if observed.is_empty() {\n",
    "        return _id(model, y, x, model.p());\n",
    "    } else {\n",
    "        let model_hidden = &model.hide(&observed);\n",
    "        let p_prime = _id(\n",
    "            &model_hidden,\n",
    "            &union(y, &observed),\n",
    "            x,\n",
    "            model_hidden.p()\n",
    "        );\n",
    "        let p = Form::quotient(\n",
    "            p_prime.to_owned(),\n",
    "            Form::marginal(y.to_owned(), p_prime)\n",
    "        );\n",
    "        return p;\n",
    "    };\n",
    "}\n",
    "\n",
    "pub fn id(model: &Model, y: &Set<Node>, x: &Set<Node>) -> Form {\n",
    "    id_no_simplify(model, y, x).simplify()\n",
    "}\n",
    "\n",
    "fn _id(model: &Model, y: &Set<Node>, x: &Set<Node>, p: Form) -> Form {\n",
    "\n",
    "    let v = model.get_nodes();\n",
    "    \n",
    "    // step 1\n",
    "    // in the case of no intervention, return the marginal\n",
    "    if x.len() == 0 {\n",
    "        return Form::marginal(difference(v, &y), p);\n",
    "    }\n",
    "\n",
    "    // step 2\n",
    "    // restrict graph to y and ancestors of y\n",
    "    {\n",
    "        let ancestors_y_and_y = union(&model.dag.ancestors_set(&y), &y);\n",
    "        if v != &ancestors_y_and_y {\n",
    "                // replace with length equality check?\n",
    "            let subg = model.subgraph(&ancestors_y_and_y);\n",
    "            return _id(\n",
    "                    &subg,\n",
    "                    y,\n",
    "                    &intersection(x, &ancestors_y_and_y),\n",
    "                    Form::marginal(difference(v, &ancestors_y_and_y), p)\n",
    "                );\n",
    "        }\n",
    "    }\n",
    "\n",
    "    // step 3\n",
    "    // force an action where this would have no effect on y\n",
    "    {\n",
    "        let a_y_do_x = model.dag\n",
    "            .r#do(x)\n",
    "            .ancestors_set(y);\n",
    "        // simplify w? do we need to subtract x?\n",
    "        let w = difference(v, &union(x, &union(&a_y_do_x, &y)));\n",
    "        if !w.is_empty() {\n",
    "            return _id(model, y, &union(&x, &w), p);\n",
    "        }\n",
    "    }\n",
    "\n",
    "    // step 4\n",
    "    // c_component factorization of the problem\n",
    "\n",
    "    let less_x = model.subgraph(&difference(v, &x));\n",
    "    let mut c_components_less_x = less_x\n",
    "        .confounded\n",
    "        .c_components();\n",
    "    \n",
    "    if c_components_less_x.len() > 1 {\n",
    "        return Form::marginal(\n",
    "            difference(v, &union(&y, &x)),\n",
    "                // will this difference ever contain anything?\n",
    "            Form::product(c![\n",
    "                _id(model, &s_i, &difference(v, &s_i), p.clone()),\n",
    "                for s_i in c_components_less_x\n",
    "            ])\n",
    "        );\n",
    "    }\n",
    "\n",
    "    // step 5\n",
    "    // fail if a hedge is discovered\n",
    "    let c_components = model.confounded.c_components();\n",
    "    if c_components.len() == 1 {\n",
    "        return Form::Hedge;\n",
    "    }\n",
    "\n",
    "    // homestretch woot\n",
    "    let s = c_components_less_x.pop()\n",
    "        .expect(\"no c_components found in derived model\");\n",
    "    for s_prime in c_components {\n",
    "        if s.is_subset(&s_prime) {\n",
    "            // step 6\n",
    "            // if x is contained in isolated c_components, condition and win\n",
    "            if s.len() == s_prime.len() {\n",
    "                return Form::marginal(\n",
    "                    difference(&s, y),\n",
    "                    Form::factorize_subset(model.order_vec(), p, &s)\n",
    "                );\n",
    "            // step 7\n",
    "            // partition x into confounded and uncounfounded\n",
    "            } else {\n",
    "                return _id(\n",
    "                    &model.subgraph(&s_prime),\n",
    "                    y,\n",
    "                    &intersection(&x, &s_prime),\n",
    "                    Form::factorize_subset(model.order_vec(), p, &s_prime)\n",
    "                );\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    panic!(\"id assumptions violated\");\n",
    "    \n",
    "}\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```rust\n",
    "// tests.rs\n",
    "\n",
    "#![cfg(test)]\n",
    "\n",
    "use super::id;\n",
    "use crate::{\n",
    "    model::{\n",
    "        Model,\n",
    "        examples::frontdoor_model\n",
    "    },\n",
    "    utils::defaults::{set, Set}, form::{Form, HEDGE},\n",
    "};\n",
    "\n",
    "#[test]\n",
    "fn test_backdoor() {\n",
    "    let model = Model::from_elems(\n",
    "        vec![\n",
    "            (2, vec![0, 1]),\n",
    "            (1, vec![0]),\n",
    "        ],\n",
    "        vec![]\n",
    "    );\n",
    "    let estimand = id(&model, &set![2], &set![1]).simplify();\n",
    "    let answer = Form::marginal(set![0], Form::product(vec![\n",
    "        Form::prob(vec![0]),\n",
    "        Form::cond_prob(vec![2], vec![0, 1]),\n",
    "    ])).cond_expand().simplify();\n",
    "\n",
    "    assert_eq!(estimand, answer);\n",
    "}\n",
    "\n",
    "#[test]\n",
    "fn test_frontdoor() {\n",
    "    let model = frontdoor_model();\n",
    "    let estimand = id(&model, &set![2], &set![0]);\n",
    "    let answer = Form::marginal(set![1],\n",
    "        Form::product(vec![\n",
    "            Form::cond_prob(vec![1], vec![0]),\n",
    "            Form::marginal(set![0],\n",
    "                Form::product(vec![\n",
    "                    Form::prob(vec![0]),\n",
    "                    Form::cond_prob(vec![2], vec![0, 1]),\n",
    "                ])\n",
    "            )\n",
    "        ])\n",
    "    ).cond_expand().simplify();\n",
    "    assert_eq!(estimand.simplify(), answer);\n",
    "}\n",
    "\n",
    "#[test]\n",
    "fn test_bowgraph () {\n",
    "    let model = Model::from_elems(\n",
    "        vec![(1, vec![0])],\n",
    "        vec![(0, 1)]\n",
    "    );\n",
    "    assert_eq!(id(&model, &set!(1), &set![0]).simplify(), Form::Hedge);\n",
    "}\n",
    "\n",
    "#[test]\n",
    "fn test_shp_hedge () {\n",
    "    let model = Model::from_elems(\n",
    "        vec![\n",
    "            (1, vec![0]),\n",
    "            (2, vec![1]),\n",
    "            (3, vec![0]),\n",
    "            (4, vec![3]),\n",
    "\n",
    "        ],\n",
    "        vec![\n",
    "            (0, 2),\n",
    "            (0, 3),\n",
    "            (0, 4),\n",
    "            (1, 3)\n",
    "        ]\n",
    "    );\n",
    "\n",
    "    assert_eq!(id(&model, &set![2, 4], &set![1]).simplify(), Form::Hedge);\n",
    "}\n",
    "\n",
    "#[test]\n",
    "fn test_shp_good () {\n",
    "    // Example he keeps using in the paper\n",
    "    // 0 <- 1\n",
    "    // 2 <- 1\n",
    "    // 4 <- 3\n",
    "    // 0 <> 2\n",
    "    // 0 <> 3\n",
    "    // 0 <> 4\n",
    "    // 1 <> 3\n",
    "    let model = Model::from_elems(\n",
    "        vec![\n",
    "            (1, vec![0]),\n",
    "            (2, vec![1]),\n",
    "            (4, vec![3]),\n",
    "\n",
    "        ],\n",
    "        vec![\n",
    "            (0, 2),\n",
    "            (0, 3),\n",
    "            (0, 4),\n",
    "            (1, 3)\n",
    "        ]\n",
    "    );\n",
    "\n",
    "    assert_ne!(id(&model, &set![2, 4], &set![1]).simplify(), Form::Hedge);\n",
    "}\n",
    "\n",
    "#[test]\n",
    "fn test_shp_p14() {\n",
    "    // Example from p. 14 of the dissertation, should all identify\n",
    "\n",
    "    // 0 <- 1\n",
    "    let model1 = Model::from_elems(\n",
    "        vec![(1, vec![0])],\n",
    "        vec![]\n",
    "    );\n",
    "    assert_ne!(id(&model1, &set![1], &set![0]).simplify(), Form::Hedge, \"example 1\");\n",
    "\n",
    "    // 1 <- 0\n",
    "    // 2 <- [0, 1]\n",
    "    // 1 <> 2\n",
    "    let model2 = Model::from_elems(\n",
    "        vec![\n",
    "            (1, vec![0]),\n",
    "            (2, vec![0, 1]),\n",
    "        ],\n",
    "        vec![(1, 2)]\n",
    "    );\n",
    "    assert_ne!(id(&model2, &set![2], &set![0]).simplify(), Form::Hedge, \"example 2\");\n",
    "\n",
    "    // 0 <- 1\n",
    "    // 2 <- [1, 0]\n",
    "    // 1 <> 2\n",
    "    let model3 = Model::from_elems(\n",
    "        vec![\n",
    "            (1, vec![0]),\n",
    "            (2, vec![1, 0]),\n",
    "        ],\n",
    "        vec![(1, 2)]\n",
    "    );\n",
    "    assert_ne!(id(&model3, &set![2], &set![0]).simplify(), Form::Hedge, \"example 3\");\n",
    "\n",
    "    // 0 <- 1\n",
    "    // 2 <- [0, 1]\n",
    "    // 0 <> 1\n",
    "    let model4 = Model::from_elems(\n",
    "        vec![\n",
    "            (0, vec![1]),\n",
    "            (2, vec![0, 1]),\n",
    "        ],\n",
    "        vec![(0, 1)]\n",
    "    );\n",
    "    assert_ne!(id(&model4, &set![2], &set![0]).simplify(), Form::Hedge, \"example 4\");\n",
    "\n",
    "    // 1 <- 0\n",
    "    // 2 <- 1\n",
    "    // 0 <> 2\n",
    "    let model5 = Model::from_elems(\n",
    "        vec![\n",
    "            (1, vec![0]),\n",
    "            (2, vec![1]),\n",
    "        ],\n",
    "        vec![(0, 2)]\n",
    "    );\n",
    "    assert_ne!(id(&model5, &set![2], &set![0]).simplify(), Form::Hedge, \"example 5\");\n",
    "\n",
    "    // 1 <- 0\n",
    "    // 2 <- 1\n",
    "    // 3 <- [0, 1, 2]\n",
    "    // 0 <> 2\n",
    "    // 1 <> 3\n",
    "    let model6 = Model::from_elems(\n",
    "        vec![\n",
    "            (1, vec![0]),\n",
    "            (2, vec![1]),\n",
    "            (3, vec![0, 1, 2]),\n",
    "        ],\n",
    "        vec![(0, 2), (1, 3)]\n",
    "    );\n",
    "    assert_ne!(id(&model6, &set![3], &set![0]).simplify(), Form::Hedge, \"example 6\");\n",
    "\n",
    "    // 0 <- 2\n",
    "    // 1 <- [0, 2]\n",
    "    // 3 <- 2\n",
    "    // 4 <- [1, 3]\n",
    "    // 0 <> 2\n",
    "    // 0 <> 4\n",
    "    // 0 <> 3\n",
    "    // 2 <> 4\n",
    "    let model7 = Model::from_elems(\n",
    "        vec![\n",
    "            (0, vec![2]),\n",
    "            (1, vec![0, 2]),\n",
    "            (3, vec![2]),\n",
    "            (4, vec![1, 3]),\n",
    "        ],\n",
    "        vec![(0, 2), (0, 4), (0, 3), (2, 4)]\n",
    "    );\n",
    "    assert_ne!(id(&model7, &set![4], &set![0]).simplify(), Form::Hedge, \"example 7\");\n",
    "\n",
    "}\n",
    "\n",
    "fn test_shp_p13 () {\n",
    "    // Example from p. 13\n",
    "\n",
    "    // 1 <- 0\n",
    "    // 0 <> 1\n",
    "    let model1 = Model::from_elems(\n",
    "        vec![(1, vec![0])],\n",
    "        vec![(0, 1)]\n",
    "    );\n",
    "    assert_eq!(id(&model1, &set![1], &set![0]).simplify(), Form::Hedge, \"example 1\");\n",
    "\n",
    "    // 1 <- 0\n",
    "    // 2 <- 1\n",
    "    // 0 <> 1\n",
    "    let model2 = Model::from_elems(\n",
    "        vec![\n",
    "            (1, vec![0]),\n",
    "            (2, vec![1]),\n",
    "        ],\n",
    "        vec![(0, 1)]\n",
    "    );\n",
    "    assert_eq!(id(&model2, &set![2], &set![0]).simplify(), Form::Hedge, \"example 2\");\n",
    "\n",
    "    // 1 <- 0\n",
    "    // 2 <- 1, 0\n",
    "    // 0 <> 1\n",
    "    let model3 = Model::from_elems(\n",
    "        vec![\n",
    "            (1, vec![0]),\n",
    "            (2, vec![1, 0]),\n",
    "        ],\n",
    "        vec![(0, 1)]\n",
    "    );\n",
    "    assert_eq!(id(&model3, &set![2], &set![0]).simplify(), Form::Hedge, \"example 3\");\n",
    "\n",
    "    // 2 <- 1, 0\n",
    "    // 0 <> 1\n",
    "    // 1 <> 2\n",
    "    let model4 = Model::from_elems(\n",
    "        vec![\n",
    "            (2, vec![1, 0]),\n",
    "        ],\n",
    "        vec![(0, 1), (1, 2)]\n",
    "    );\n",
    "    assert_eq!(id(&model4, &set![2], &set![0]).simplify(), Form::Hedge, \"example 4\");\n",
    "\n",
    "    // 0 <- 1\n",
    "    // 2 <- 0\n",
    "    // 0 <> 1\n",
    "    // 1 <> 2\n",
    "    let model5 = Model::from_elems(\n",
    "        vec![\n",
    "            (0, vec![1]),\n",
    "            (2, vec![0]),\n",
    "        ],\n",
    "        vec![(0, 1), (1, 2)]\n",
    "    );\n",
    "    assert_eq!(id(&model5, &set![2], &set![0]).simplify(), Form::Hedge, \"example 5\");\n",
    "\n",
    "    // 1 <- 0\n",
    "    // 2 <- 1\n",
    "    // 0 <> 2\n",
    "    // 1 <> 2\n",
    "    let model6 = Model::from_elems(\n",
    "        vec![\n",
    "            (1, vec![0]),\n",
    "            (2, vec![1]),\n",
    "        ],\n",
    "        vec![(0, 2), (1, 2)]\n",
    "    );\n",
    "    assert_eq!(id(&model6, &set![2], &set![0]).simplify(), Form::Hedge, \"example 6\");\n",
    "\n",
    "    // 1 <- 0\n",
    "    // 3 <- 1, 2\n",
    "    // 0 <> 2\n",
    "    // 1 <> 2\n",
    "    let model7 = Model::from_elems(\n",
    "        vec![\n",
    "            (1, vec![0]),\n",
    "            (3, vec![1, 2]),\n",
    "        ],\n",
    "        vec![(0, 2), (1, 2)]\n",
    "    );\n",
    "    assert_eq!(id(&model7, &set![3], &set![0]).simplify(), Form::Hedge, \"example 7\");\n",
    "\n",
    "    // 0 <- 1\n",
    "    // 2 <- 0\n",
    "    // 3 <- 2\n",
    "    // 1 <> 0, 2, 3\n",
    "    // 0 <> 3\n",
    "    let model8 = Model::from_elems(\n",
    "        vec![\n",
    "            (0, vec![1]),\n",
    "            (2, vec![0]),\n",
    "            (3, vec![2]),\n",
    "        ],\n",
    "        vec![(1, 0), (1, 2), (1, 3), (0, 3)]\n",
    "    );\n",
    "    assert_eq!(id(&model8, &set![3], &set![0]).simplify(), Form::Hedge, \"example 8\");\n",
    "\n",
    "\n",
    "}\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```rust\n",
    "// examples.rs\n",
    "\n",
    "use super::Model;\n",
    "use crate::graph::Graph;\n",
    "\n",
    "pub fn backdoor_model() -> Model {\n",
    "    Model::from_elems(\n",
    "        vec![\n",
    "            (2, vec![0, 1]),\n",
    "            (1, vec![1])\n",
    "        ],\n",
    "        vec![]\n",
    "    )\n",
    "}\n",
    "\n",
    "pub fn frontdoor_model() -> Model {\n",
    "    Model::from_elems(\n",
    "        vec![\n",
    "            (2, vec![1]),\n",
    "            (1, vec![0])\n",
    "        ],\n",
    "        vec![(2, 0)]\n",
    "    )\n",
    "}\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```rust\n",
    "// mod.rs\n",
    "\n",
    "mod model;\n",
    "mod tests;\n",
    "\n",
    "pub mod order;\n",
    "pub mod examples;\n",
    "pub use model::{Model, ModelBuilder};\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```rust\n",
    "// model.rs\n",
    "\n",
    "use cute::c;\n",
    "use crate::form::Form;\n",
    "use crate::set;\n",
    "use crate::utils::defaults::{Set, Map};\n",
    "use crate::utils::set_utils::{union, make_set, difference, intersection};\n",
    "use crate::graph::{GraphBuilder, DiGraph, BiGraph, Graph, Node};\n",
    "use crate::identification::id;\n",
    "\n",
    "use super::order::Order;\n",
    "\n",
    "#[derive(Debug, Clone)]\n",
    "pub struct ModelBuilder {\n",
    "    dag: GraphBuilder,\n",
    "    confounded: GraphBuilder,\n",
    "}\n",
    "\n",
    "impl<'a> ModelBuilder {\n",
    "    pub fn new() -> ModelBuilder {\n",
    "        ModelBuilder { dag: GraphBuilder::new(), confounded: GraphBuilder::new() }\n",
    "    }\n",
    "\n",
    "    pub fn add_node(&mut self, node: Node) {\n",
    "        self.dag.add_node(node);\n",
    "        self.confounded.add_node(node);\n",
    "    }\n",
    "\n",
    "    pub fn add_directed_edge(&mut self, from: Node, to: Node) {\n",
    "        self.dag.add_edge(from, to);\n",
    "    }\n",
    "\n",
    "    pub fn add_confounded_edge(&mut self, from: Node, to: Node) {\n",
    "        self.confounded.add_edge(from, to);\n",
    "    }\n",
    "\n",
    "    pub fn from_elems(dag: Vec<(Node, Vec<Node>)>, confounded: Vec<(Node, Node)>) -> ModelBuilder {\n",
    "        let mut builder = ModelBuilder::new();\n",
    "        for (from, to) in dag {\n",
    "            for target in to {\n",
    "                builder.dag.add_edge(from, target);\n",
    "\n",
    "                builder.confounded.add_node(target);\n",
    "            }\n",
    "            builder.confounded.add_node(from);\n",
    "        }\n",
    "\n",
    "        for (a, b) in confounded {\n",
    "            builder.confounded.add_edge(a, b);\n",
    "            builder.dag.add_node(a);\n",
    "            builder.dag.add_node(b);\n",
    "        }\n",
    "\n",
    "        return builder;\n",
    "    }\n",
    "\n",
    "    pub fn to_model (builder: Box<ModelBuilder>) -> Model {\n",
    "        let vars = union(&builder.dag.get_nodes(), &builder.confounded.get_nodes());\n",
    "        Model {\n",
    "            dag: GraphBuilder::to_digraph(builder.dag),\n",
    "            confounded: GraphBuilder::to_bigraph(builder.confounded),\n",
    "            cond_vars: set![],\n",
    "            vars\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "#[derive(Debug)]\n",
    "pub struct Model {\n",
    "    pub dag: DiGraph,\n",
    "    pub confounded: BiGraph,\n",
    "    cond_vars: Set<Node>,\n",
    "    vars: Set<Node>,\n",
    "}\n",
    "\n",
    "impl Graph for Model {\n",
    "    fn subgraph(&self, nodes: &Set<Node>) -> Self {\n",
    "        Model {\n",
    "            dag: self.dag.subgraph(nodes),\n",
    "            confounded: self.confounded.subgraph(nodes),\n",
    "            vars: nodes.clone(),\n",
    "            cond_vars: self.cond_vars.clone(),\n",
    "        }\n",
    "    }\n",
    "\n",
    "    fn r#do(&self, nodes: &Set<Node>) -> Self {\n",
    "        Model {\n",
    "            dag: self.dag.r#do(nodes),\n",
    "            confounded: self.confounded.r#do(nodes),\n",
    "            vars: self.vars.clone(),\n",
    "            cond_vars: self.cond_vars.clone(),\n",
    "        }\n",
    "    }\n",
    "\n",
    "    fn get_nodes(&self) -> &Set<Node> {\n",
    "        &self.vars\n",
    "    }\n",
    "}\n",
    "\n",
    "impl Model {\n",
    "    pub fn id(&self, y: &Set<Node>, x: &Set<Node>) -> Form {\n",
    "        id(&self, y, x)\n",
    "    }\n",
    "\n",
    "    pub fn from_elems (dag: Vec<(Node, Vec<Node>)>, confounded: Vec<(Node, Node)>) -> Model {\n",
    "        ModelBuilder::to_model(Box::new(ModelBuilder::from_elems(dag, confounded)))\n",
    "    }\n",
    "\n",
    "    pub fn from_graphs (dag: DiGraph, confounded: BiGraph) -> Model {\n",
    "        let vars = union(&dag.get_nodes(), &confounded.get_nodes());\n",
    "        Model {dag, confounded, vars, cond_vars: set![]}\n",
    "    }\n",
    "\n",
    "    /// Sets variables as observed in the model.\n",
    "    pub fn cond (&self, cond: &Set<Node>) -> Model {\n",
    "        Model {\n",
    "            dag: self.dag.to_owned(),\n",
    "            confounded: self.confounded.to_owned(),\n",
    "            vars: self.vars.to_owned(),\n",
    "            cond_vars: union(&self.cond_vars, &cond)\n",
    "        }\n",
    "    }\n",
    "\n",
    "    /// Sets variables as not observed in the model. Inverse of `cond`.\n",
    "    pub fn hide(&self, observed: &Set<Node>) -> Model {\n",
    "        Model {\n",
    "            dag: self.dag.to_owned(),\n",
    "            confounded: self.confounded.to_owned(),\n",
    "            vars: self.vars.to_owned(),\n",
    "            cond_vars: difference(&self.cond_vars, &observed)\n",
    "        }\n",
    "    }\n",
    "\n",
    "    /// Returns the set of variables that are observed in the model.\n",
    "    pub fn get_observed(&self) -> Set<Node> {\n",
    "        self.cond_vars.to_owned()\n",
    "    }\n",
    "\n",
    "    /// Returns the set of variables that are not observed in the model.\n",
    "    pub fn get_unobserved(&self) -> Set<Node> {\n",
    "        difference(&self.vars, &self.cond_vars)\n",
    "    }\n",
    "\n",
    "    // pub fn independent(&self, a: &Set<Node>, b: &Set<Node>) -> bool {\n",
    "    //     todo!();\n",
    "\n",
    "    //     // let target: Set<Node> = b.iter().cloned().filter(|node| self.vars.contains(node)).collect();\n",
    "    //     // let mut confounded: Vec<Node> = a.iter().cloned().filter(|node| self.vars.contains(node)).collect();\n",
    "    //     // let mut visited: Set<Node> = set!();\n",
    "\n",
    "    //     // let add_confounded = |node| {\n",
    "    //     //     if visited.insert(node) {\n",
    "    //     //         confounded.push(node);\n",
    "    //     //     }\n",
    "    //     // };\n",
    "\n",
    "    //     // while !confounded.is_empty() && !visited.len() == self.vars.len() {\n",
    "\n",
    "\n",
    "    //     // }\n",
    "\n",
    "    //     // return true;\n",
    "    // }\n",
    "\n",
    "    pub fn order_vec(&self) -> Vec<Node> {\n",
    "        let res_set = difference(\n",
    "            self.confounded.get_nodes(), \n",
    "            self.dag.get_nodes()\n",
    "        );\n",
    "        let mut res = Vec::new();\n",
    "        for r in res_set {\n",
    "            res.push(r);\n",
    "        }\n",
    "        res.extend(self.dag.order());\n",
    "        return res;\n",
    "    }\n",
    "\n",
    "    pub fn order(&self) -> Order {\n",
    "        let order_vec = self.order_vec();\n",
    "        Order::from_vec(order_vec).expect(\"error creating order\")\n",
    "    }\n",
    "\n",
    "    /// Joint distribution of unobserved variables in the model, conditioned on observed.\n",
    "    pub fn p(&self) -> Form {\n",
    "        Form::cond_prob(\n",
    "            self.vars.iter().cloned().collect(),\n",
    "            self.cond_vars.iter().cloned().collect()\n",
    "        )\n",
    "    }\n",
    "\n",
    "    pub fn get_dag(&self) -> &DiGraph {\n",
    "        &self.dag\n",
    "    }\n",
    "\n",
    "    pub fn get_confounded(&self) -> &BiGraph {\n",
    "        &&self.confounded\n",
    "    }\n",
    "\n",
    "    pub fn ancestors(&self, node: Node) -> Set<Node> {\n",
    "        self.dag.ancestors(node)\n",
    "    }\n",
    "\n",
    "    pub fn ancestors_set(&self, s: &Set<Node>) -> Set<Node> {\n",
    "        self.dag.ancestors_set(s)\n",
    "    }\n",
    "\n",
    "    pub fn ancestors_inc(&self, node: Node) -> Set<Node> {\n",
    "        let mut s = self.ancestors(node);\n",
    "        s.insert(node);\n",
    "        return s;\n",
    "    }\n",
    "\n",
    "    pub fn ancestors_set_inc(&self, nodes: &Set<Node>) -> Set<Node> {\n",
    "        let mut s = self.dag.ancestors_set(nodes);\n",
    "        s = union(&s, nodes);\n",
    "        return s;\n",
    "    }\n",
    "\n",
    "}\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```rust\n",
    "// order.rs\n",
    "\n",
    "use std::{collections::HashSet, hash::Hash};\n",
    "\n",
    "use crate::{\n",
    "    utils::{\n",
    "        defaults::{Map, Set},\n",
    "        set_utils::{make_set, get_one}\n",
    "    },\n",
    "    graph::Node\n",
    "};\n",
    "\n",
    "pub struct Order {\n",
    "    map: Map<Node, i32>,\n",
    "    vars: Vec<Node>,\n",
    "}\n",
    "\n",
    "impl Order {\n",
    "    pub fn from_vec(vec: Vec<Node>) -> Option<Order> {\n",
    "        let mut map: Map<Node, i32> = Map::new();\n",
    "        for (i, val) in vec.iter().enumerate() {\n",
    "            match map.insert(*val, i as i32) {\n",
    "                None => (),\n",
    "                Some(_) => {\n",
    "                    return None;\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "        Some(Order {vars: vec, map})\n",
    "    }\n",
    "\n",
    "    pub fn from_map(map: Map<Node, i32>) -> Option<Order> {\n",
    "        let mut vars: Vec<Node> = map.keys().cloned().collect();\n",
    "\n",
    "        let index: HashSet<i32> = map.values().cloned().collect();\n",
    "        let index_should: HashSet<i32> = (0..vars.len()).map(|e| e as i32).collect();\n",
    "        if index != index_should {\n",
    "            return None;\n",
    "        }\n",
    "\n",
    "        let mut vars_set = HashSet::new();\n",
    "\n",
    "        for (node, val) in map.iter() {\n",
    "            if vars_set.insert(*node) {\n",
    "                vars[*val as usize] = *node;\n",
    "            } else {\n",
    "                return None\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        Some(Order {vars, map})\n",
    "    }\n",
    "\n",
    "    pub fn val(&self, node: &Node) -> Option<&i32> {\n",
    "        self.map.get(node)\n",
    "    }\n",
    "\n",
    "    pub fn order(&self) -> &Vec<Node> {\n",
    "        &self.vars\n",
    "    }\n",
    "\n",
    "    pub fn lt(&self, a: &Node, b: &Node) -> Option<bool> {\n",
    "        if let Some(a_val) = self.map.get(a) {\n",
    "            if let Some(b_val) = self.map.get(b) {\n",
    "                return Some(a_val < b_val);\n",
    "            }\n",
    "        }\n",
    "        None\n",
    "    }\n",
    "\n",
    "    pub fn predecessors(&self, var: &Node) -> Option<Vec<Node>> {\n",
    "        match self.map.get(var) {\n",
    "            None => None,\n",
    "            Some(val) => {\n",
    "                let mut vars = Vec::new();\n",
    "                for i in 0..*val {\n",
    "                    vars.push(self.vars[i as usize]);\n",
    "                }\n",
    "                Some(vars)\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    pub fn min(&self, vars: &Set<Node>) -> Option<Node> {\n",
    "        let mut min_v = get_one(vars)?;\n",
    "        for node in vars.iter() {\n",
    "            if let Some(lt) = self.lt(node, &min_v) {\n",
    "                if lt {\n",
    "                    min_v = *node;\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "        return Some(min_v);\n",
    "    }\n",
    "\n",
    "    pub fn set_predecessors(&self, vars: &Set<Node>) -> Option<Vec<Node>> {\n",
    "        match self.min(vars) {\n",
    "            None => Some(self.vars.clone()),\n",
    "            Some(min) => self.predecessors(&min)\n",
    "        }\n",
    "    }\n",
    "}\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```rust\n",
    "// tests.rs\n",
    "\n",
    "#![cfg(test)]\n",
    "\n",
    "use crate::{\n",
    "    model::{Model, ModelBuilder},\n",
    "    graph::{\n",
    "        Graph,\n",
    "        make_nodes,\n",
    "    },\n",
    "    utils::{\n",
    "        defaults::{Set, Map},\n",
    "        set_utils::make_set,\n",
    "    }, set\n",
    "};\n",
    "\n",
    "use super::{order::Order, examples::frontdoor_model};\n",
    "\n",
    "#[test]\n",
    "fn subgraphing() {\n",
    "    let (a, b, c, d) = (1, 2, 3, 4);\n",
    "    let model = Model::from_elems(\n",
    "        vec![\n",
    "            (a, vec![b, c, d]),\n",
    "            (b, vec![c, d]),\n",
    "            (c, vec![d])\n",
    "        ],\n",
    "        vec![(a, d)]\n",
    "    );\n",
    "\n",
    "    let abd = model.subgraph(&Set::from([a, b, d]));\n",
    "    assert_eq!(make_set(abd.order_vec().into_iter()), Set::from([a, b, d]));\n",
    "    assert_eq!(abd.dag.ancestors(d), Set::new());\n",
    "    assert_eq!(abd.dag.ancestors(a), Set::from([b, d]));\n",
    "}\n",
    "\n",
    "#[test]\n",
    "fn c_components_subgraph () {\n",
    "    let model = frontdoor_model();\n",
    "\n",
    "    fn vec_and_sort(cs: Vec<Set<i32>>) -> Vec<Vec<i32>> {\n",
    "        let mut new = vec![];\n",
    "        for c in cs {\n",
    "            let mut c_vec: Vec<i32> = c.into_iter().collect();\n",
    "            c_vec.sort();\n",
    "            new.push(c_vec);\n",
    "        }\n",
    "        new.sort();\n",
    "        return new;\n",
    "    }\n",
    "\n",
    "    let c_components = model.confounded.c_components();\n",
    "    assert_eq!(vec_and_sort(c_components), vec![\n",
    "        vec![0, 2],\n",
    "        vec![1],\n",
    "    ]);\n",
    "\n",
    "    let graph_sub_c_components = model.confounded.subgraph(&set![1, 2]).c_components();\n",
    "    assert_eq!(vec_and_sort(graph_sub_c_components), vec![\n",
    "        vec![1],\n",
    "        vec![2],\n",
    "    ], \"test 1\");\n",
    "\n",
    "    let sub_c_components = model.subgraph(&set![1, 2]).confounded.c_components();\n",
    "    assert_eq!(vec_and_sort(sub_c_components), vec![\n",
    "        vec![1],\n",
    "        vec![2],\n",
    "    ]);\n",
    "\n",
    "\n",
    "}\n",
    "\n",
    "#[test]\n",
    "fn order() {\n",
    "    let (a, b, c, d) = (1, 2, 3, 4);\n",
    "    let model = Model::from_elems(\n",
    "        vec![\n",
    "            (a, vec![b, c]),\n",
    "            (c, vec![d]),\n",
    "        ],\n",
    "        vec![]\n",
    "    );\n",
    "    let order = model.order_vec();\n",
    "    assert_eq!(order[3], d);\n",
    "    assert_eq!(order[0], a);\n",
    "}\n",
    "\n",
    "#[test]\n",
    "fn test_nodes_added_graphs() {\n",
    "    let model = Model::from_elems(\n",
    "        vec![\n",
    "            (2, vec![0, 1]),\n",
    "            (1, vec![0]),\n",
    "        ],\n",
    "        vec![(1, 4)],\n",
    "    );\n",
    "\n",
    "    assert_eq!(model.get_nodes(), model.get_dag().get_nodes());\n",
    "    assert_eq!(model.get_nodes(), model.get_confounded().get_nodes());\n",
    "}\n",
    "\n",
    "#[test]\n",
    "fn test_order_from_vec () {\n",
    "    assert!(!Order::from_vec(Vec::new()).is_none());\n",
    "    assert!(!Order::from_vec(Vec::from([1])).is_none());\n",
    "    assert!(!Order::from_vec(make_nodes(10)).is_none());\n",
    "    assert!(Order::from_vec(Vec::from([1, 2, 1])).is_none());\n",
    "}\n",
    "\n",
    "#[test]\n",
    "fn test_order_from_map () {\n",
    "    assert!(!Order::from_map(Map::from([(0, 0), (1, 1), (2, 2)])).is_none());\n",
    "    assert!(Order::from_map(Map::from([(0, 0), (0, 1), (2, 2)])).is_none());\n",
    "    assert!(Order::from_map(Map::from([(0, 0), (1, 2), (2, 2)])).is_none());\n",
    "}\n",
    "\n",
    "#[test]\n",
    "fn test_order_utils () {\n",
    "    let vec = make_nodes(10);\n",
    "    let order = Order::from_vec(vec.clone()).expect(\"failure intializing Order\");\n",
    "\n",
    "    assert!(order.lt(&vec[4], &vec[5]).expect(\"lt failed to return\"));\n",
    "    assert!(order.lt(&vec[0], &vec[2]).expect(\"lt failed to return\"));\n",
    "    assert_eq!(order.predecessors(&vec[5]).expect(\"failed to get predecessors\").len(), 5);\n",
    "    assert_eq!(order.val(&vec[5]), Some(&5));\n",
    "    assert_eq!(order.val(&vec[9]), Some(&9));\n",
    "    assert_eq!(order.val(&10), None)\n",
    "}\n",
    "\n",
    "#[test]\n",
    "fn test_order_predecessors_set() {\n",
    "    let order_vec = make_nodes(10);\n",
    "    let order = Order::from_vec(order_vec.clone()).expect(\"failure intializing Order\");\n",
    "\n",
    "    let s1 = set![order_vec[4], order_vec[6], order_vec[8]];\n",
    "    let a1 = vec![order_vec[0], order_vec[1], order_vec[2], order_vec[3]];\n",
    "    assert_eq!(order.set_predecessors(&s1), Some(a1));\n",
    "\n",
    "    assert_eq!(order.set_predecessors(&set![order_vec[0]]), Some(vec![]),\n",
    "        \"set_predecessors should return empty vec when none exist\");\n",
    "\n",
    "    assert_eq!(order.set_predecessors(&set![]), Some(order_vec.clone()),\n",
    "        \"set_predecessors should return full order on empty query\");\n",
    "\n",
    "    assert_eq!(order.set_predecessors(&set![15]), None,\n",
    "        \"set_predecessors should return None when no queries in order\");\n",
    "    \n",
    "    // assert_eq!(order.set_predecessors(&set![15, order_vec[1]]), Some(vec![order_vec[0]]),\n",
    "    //     \"set_predecessors should return when at least one query is good\");\n",
    "}\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```rust\n",
    "// defaults.rs\n",
    "\n",
    "pub use std::collections::{HashMap as Map, HashSet as Set};\n",
    "\n",
    "#[macro_export]\n",
    "macro_rules! set {\n",
    "    ( $( $x:expr ),* ) => {\n",
    "        {\n",
    "            let mut temp_vec = Set::new();\n",
    "            $(\n",
    "                temp_vec.insert($x);\n",
    "            )*\n",
    "            temp_vec\n",
    "        }\n",
    "    };\n",
    "}\n",
    "\n",
    "pub(crate) use set;\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```rust\n",
    "// mod.rs\n",
    "\n",
    "pub mod defaults;\n",
    "pub mod set_utils;\n",
    "mod utils;\n",
    "pub use utils::remove_duplicates_sorted;\n",
    "mod tests;\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```rust\n",
    "// set_utils.rs\n",
    "\n",
    "use::std::collections::HashSet as Set;\n",
    "use::std::hash::Hash;\n",
    "\n",
    "use crate::graph::Node;\n",
    "\n",
    "pub fn copy_set <T: Eq + Hash + Copy>(s: &Set<T>) -> Set<T> {\n",
    "    s.iter().map(|e| *e).collect()\n",
    "}\n",
    "\n",
    "// TODO: make this lazy\n",
    "// TODO: return values sorted by size\n",
    "// adapted from https://gist.github.com/synecdoche/9ade913c891dda6fcf1cdac823e7d524\n",
    "pub fn powerset<T: Clone + Eq + Hash>(s: &Set<T>) -> Vec<Set<T>> {\n",
    "    let elems: Vec<T> = s.iter().cloned().collect();\n",
    "    let mut v: Vec<Set<T>> = Vec::new();\n",
    "\n",
    "    for mask in 0..(1 << elems.len()) {\n",
    "        let mut ss: Set<T> = Set::new();\n",
    "        let mut bitset = mask;\n",
    "        while bitset > 0 {\n",
    "            // isolate the rightmost bit to select one item\n",
    "            let rightmost: u64 = bitset & !(bitset - 1);\n",
    "            // turn the isolated bit into an array index\n",
    "            let idx = rightmost.trailing_zeros();\n",
    "            let item = (*elems.get(idx as usize).unwrap()).clone();\n",
    "            ss.insert(item);\n",
    "            // zero the trailing bit\n",
    "            bitset &= bitset - 1;\n",
    "        }\n",
    "        v.push(ss);\n",
    "    }\n",
    "    \n",
    "    return v;\n",
    "}\n",
    "\n",
    "pub fn make_set<'a, T: Hash + Eq>(elems: impl Iterator<Item=T>) -> Set<T> {\n",
    "    let mut s = Set::new();\n",
    "    elems.for_each(|e| {s.insert(e);});\n",
    "    return s;\n",
    "}\n",
    "\n",
    "pub fn get_one(a: &Set<Node>) -> Option<Node> {\n",
    "    for node in a.iter() {\n",
    "        return Some(*node);\n",
    "    }\n",
    "    None\n",
    "}\n",
    "\n",
    "pub fn difference(a: &Set<Node>, b: &Set<Node>) -> Set<Node> {\n",
    "    a.difference(b).map(|e| *e).collect()\n",
    "}\n",
    "\n",
    "pub fn union(a: &Set<Node>, b: &Set<Node>) -> Set<Node> {\n",
    "    a.union(b).map(|e| *e).collect()\n",
    "}\n",
    "\n",
    "pub fn intersection(a: &Set<Node>, b: &Set<Node>) -> Set<Node> {\n",
    "    a.intersection(b).map(|e| *e).collect()\n",
    "}\n",
    "\n",
    "// TODO: speed\n",
    "pub fn symmetric_difference(a: &Set<Node>, b: &Set<Node>) -> Set<Node> {\n",
    "    return difference(&union(a, b), &intersection(a, b));\n",
    "}\n",
    "\n",
    "\n",
    "// pub fn find_superset<T>(sets: HashSet<HashSet<T>>, s: HashSet<T>) -> HashSet<T> {\n",
    "//     for superset in sets {\n",
    "//         if s.is_subset(superset) {\n",
    "//             return s;\n",
    "//         }\n",
    "//     }\n",
    "//     None;\n",
    "// }\n",
    "\n",
    "// fn calculate_hash<T: Hash>(t: &T) -> u64 {\n",
    "//     let mut s = DefaultHasher::new();\n",
    "//     t.hash(&mut s);\n",
    "//     s.finish()\n",
    "// }\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```rust\n",
    "// tests.rs\n",
    "\n",
    "#![cfg(test)]\n",
    "use super::{defaults::{set, Set}, set_utils::{powerset, get_one}};\n",
    "\n",
    "#[test]\n",
    "fn test_set() {\n",
    "    assert_eq!(set![1, 2, 3], Set::from([1, 2, 3]));\n",
    "    let s: Set<i32> = Set::new();\n",
    "    assert_eq!(set![], s);\n",
    "}\n",
    "\n",
    "#[test]\n",
    "fn test_powerset() {\n",
    "    let s = set!(2, 3, 5);\n",
    "    let answers = powerset(&s);\n",
    "    let mut ans_prods = set!();\n",
    "    for ans in answers {\n",
    "        let mut x = 1;\n",
    "        for elem in ans {\n",
    "            x *= elem;\n",
    "        }\n",
    "        ans_prods.insert(x);\n",
    "    }\n",
    "    assert_eq!(ans_prods, set!(1, 2, 3, 5, 6, 10, 15, 30));\n",
    "}\n",
    "\n",
    "#[test]\n",
    "fn test_powerset_edge () {\n",
    "    let empty: Set<i32> = set!();\n",
    "    assert_eq!(powerset(&empty), vec!(set!()));\n",
    "\n",
    "    let one = set!(1);\n",
    "    assert!(powerset(&one).contains(&empty));\n",
    "    assert!(powerset(&one).contains(&one));\n",
    "    assert_eq!(powerset(&one).len(), 2)\n",
    "}\n",
    "\n",
    "#[test]\n",
    "fn test_get_one() {\n",
    "    assert_eq!(get_one(&set![]), None);\n",
    "    assert!(set![1, 2, 3].contains(&get_one(&set![1, 2, 3]).expect(\"get_one did not return\")));\n",
    "}\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```rust\n",
    "// utils.rs\n",
    "\n",
    "\n",
    "/// Remove duplicates from two sorted vectors simultaneously\n",
    "/// Elements may appear more than once, in this case only the first occurence is removed\n",
    "pub fn remove_duplicates_sorted<T: Ord + Eq + Clone>(v1: &Vec<T>, v2: &Vec<T>) -> (Vec<T>, Vec<T>) {\n",
    "    let mut a = v1.to_owned();\n",
    "    let mut b = v2.to_owned();\n",
    "\n",
    "    let mut i = 0;\n",
    "    let mut j = 0;\n",
    "    while i < a.len() && j < b.len() {\n",
    "        if a[i] == b[j] {\n",
    "            a.remove(i);\n",
    "            b.remove(j);\n",
    "        } else if a[i] < b[j] {\n",
    "            i += 1;\n",
    "        } else {\n",
    "            j += 1;\n",
    "        }\n",
    "    }\n",
    "\n",
    "    return (a.to_vec(), b.to_vec());\n",
    "}\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```rust \n",
    "// lib.rs\n",
    "\n",
    "#![allow(dead_code, unused_mut, unused_imports)]\n",
    "mod test;\n",
    "mod utils;\n",
    "\n",
    "mod form;\n",
    "mod graph;\n",
    "mod model;\n",
    "mod identification;\n",
    "\n",
    "mod api;\n",
    "use api::python::pqp;\n",
    "\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```rust\n",
    "// test.rs\n",
    "\n",
    "#![cfg(test)]\n",
    "\n",
    "use crate::{\n",
    "    model::examples::frontdoor_model,\n",
    "    identification::id,\n",
    "    utils::defaults::{set, Set},\n",
    "};\n",
    "\n",
    "#[test]\n",
    "fn foo() {\n",
    "    let a = String::from(\"a\");\n",
    "    let b = String::from(\"a\");\n",
    "    assert_eq!(a, b);\n",
    "}\n",
    "\n",
    "#[test]\n",
    "fn do_stuff() {\n",
    "    let fd = frontdoor_model();\n",
    "    println!(\"{:?}\", fd);\n",
    "    println!(\"{:?}\", id(&fd, &set!(2), &set!(0)));\n",
    "}\n",
    "\n",
    "// \"Marginal({1}, Product([Marginal({}, Product([Quotient(Marginal({}, Marginal({2}, P([2, 0, 1], []))), Marginal({1}, Marginal({2}, P([2, 0, 1], [])))), Quotient(Marginal({1}, Marginal({2}, P([2, 0, 1], []))), Marginal({1, 0}, Marginal({2}, P([2, 0, 1], []))))])), Marginal({}, Product([Quotient(Marginal({}, P([2, 0, 1], [])), Marginal({2}, P([2, 0, 1], []))), Quotient(Marginal({2}, P([2, 0, 1], [])), Marginal({1, 2}, P([2, 0, 1], []))), Quotient(Marginal({1, 2}, P([2, 0, 1], [])), Marginal({1, 0, 2}, P([2, 0, 1], [])))]))]))\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bbbf304047aac1d8dfa956a63cc2cea0a93c42bcd915750832b2326b8115e97d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
