{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract\n",
    "Causal inference under Pearl’s framework of structural causal models has been the subject of intense theoretical study, but performant open-source implementations of many of the key algorithms are still lacking or, where they exist, are not widely adopted or maintained. I present `pqp` (short for *Pourquoi-pas?*), a end-to-end library for structural causal inference that includes an implementation of Shpitser’s IDC algorithm for identification of conditional causal effects in semi-Markovian causal models as well as tools for estimation. The library includes sophisticated memory-sharing graph data structures, a symbolic simplification routine, and it comes wrapped in an elegant Python interface. FInally, I have created a number of educational resources to help users get started with the library."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Executive Summary\n",
    "\n",
    "Causal inference is a fundamental task in many fields, including epidemiology, economics, and data science. One popular framework for causal inference is Pearl's structural causal modeling framework, which utilizes directed acyclic graphs (DAGs) and the do-calculus to explicitly model potential causal relationships. (Pearl, 2000) This approach allows for a clear and intuitive representation of causal assumptions, while also helping to avoid common biases that can arise with other methodologies. However, a crucial step in this framework is identification: translating a causal question into an abstract statistical estimator that can be estimated using a combination of a model and parametric assumptions.\n",
    "\n",
    "One important algorithm for identification in the structural causal modeling framework is Shpitser's algorithm for conditional interventional effects. (Shpitser, 2008) This algorithm is polynomial time and guarantees a result when one is possible. However, existing open-source implementations of this algorithm are often incorrect, slow, or unmaintained. In this paper, I present a novel implementation of Shpitser's algorithm, written in Rust for efficient cross-functional use. Our implementation is production-quality code and includes extensive testing routines to ensure performance and correctness.\n",
    "\n",
    "To bridge the gap between theoretical algorithm and practical tool, I developed two techniques as subroutines to the algorithm. I developed and implemented a heuristic symbolic simplification algorithm. To protect the speed and memory efficiency of the program, I designed a memory-sharing graph datastructure which allows similar graphs to share memory via a system of references and immutable data. Further, I am close to finishing an implementation of a estimation technique which will extend the work in Brule (2018).\n",
    "\n",
    "To aid in adoption of this algorithm, I designed and implemented a user-friendly Python wrapper. This wrapper allows for the specification and visualization of causal graphs using a concise and elegant API, as well as giving the user full access to the underlying algorithms. In addition, this wrapper tracks steps in a user's analysis, constructing a computational graph of intermediate results. This graph tracks assumptions made by the various subroutines of the algorithm, allowing the user to access a list of the assumptions made during an analysis so they can understand potential limitations. The wrapper is available as a Python package on PyPi, and I created a website with documentation.\n",
    "\n",
    "I created a number of educational resources to share my work: a Medium article detailed some of the theoretical background and two explainer videos covering practical use of the library."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "The paper is organized as follows: in the first section, I provide an overview of much of the literature on structural causal modeling. I review the literature on available implementations of the algorithm and justify the need for this implementation.\n",
    "\n",
    "In the Implementation section, I describe technical insights I employed and analysis I performed on my implementation. I detail techniques I developed for simplication and memory-sharing, and I describe the extensive testing procedures I used to ensure correctness. I describe the Python wrapper I developed to make the algorithm accessible to a wider audience. I outline my technique for tracking assumptions made during analysis. I evaluate my implementation on correctness, performance, and ease of use.\n",
    "\n",
    "Following the implementation, I provide an end-to-end example of using the library to estimate an effect. Then, I overview the educational resources I created as part of the project.\n",
    "\n",
    "Appendices include HC/LO footnotes, documentation, and code."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contributions\n",
    "\n",
    "In this work, I present a novel implementation of Shpitser's ID algorithm, including a comprehensive set of graph routines and a heuristic-based simplification algorithm. The implementation is written in Rust and the code is provided in the appendix. Additionally, I have developed Python bindings to facilitate usage of the algorithm. These bindings track assumptions made during the analysis in a computational graph that allows users to track the dependencies between various intermediate results and the assumptions they rely on.\n",
    "\n",
    "In order to share my work with the broader community, I developed a high quality project website with detailed documentation. I wrote a Medium article which overviews some of the theory and introduces the library. I also created two explainer videos which provide a practical intro to using the library.\n",
    "\n",
    "It is important to note that while this implementation and techniques for simplification and memory-sharing are novel, the underlying algorithm and all the material covered in the Background section is not a contribution of this paper and is instead a summary of the current state of the field."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Links\n",
    "\n",
    "- Documentation: [https://leo-ware.github.io/pqp/index.html](https://leo-ware.github.io/pqp/index.html)\n",
    "- Source code: [https://github.com/leo-ware/pqp](https://github.com/leo-ware/pqp)\n",
    "- PyPI Distribution: [https://pypi.org/project/pqp/](https://pypi.org/project/pqp/)\n",
    "- Medium Article: [https://medium.com/@leoware/causal-inference-a-four-stage-framework-7fc2f8deafe2](https://medium.com/@leoware/causal-inference-a-four-stage-framework-7fc2f8deafe2)\n",
    "- Video 1: [https://www.loom.com/share/91dc669b931d487a84c8030c80d2391c](https://www.loom.com/share/91dc669b931d487a84c8030c80d2391c)\n",
    "- Video 2: [https://www.loom.com/share/7d8feab2b4f54a7caa59c495a9ce9858](https://www.loom.com/share/7d8feab2b4f54a7caa59c495a9ce9858)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note\n",
    "\n",
    "AI text generation algorithms were used in the production of this text. Specifically, the OpenAI model ChatPGT was used extensively to edit for tone and concision."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structural Causal Models\n",
    "\n",
    "### Overview\n",
    "\n",
    "Structural Causal Models (SCM) provide a framework for modeling the generating process of a distribution. A structural causal model has four components: a set of observed variables $\\textbf{V} = {v_1, v_2, ..., v_n}$, a set of unobserved variables $\\textbf{U} = {u_1, u_2, ..., u_m}$, a distribution $P(U)$ over unobserved variables, and a set of functions $\\textbf{F} = {f_1, f_2...f_n}$ such that each $f_i$ is a function from a subset of $\\textbf{U} \\cup \\textbf{V} \\backslash V_i$ to $v_i$. The arguments to $f_i$ are called the parents of $v_i$ or $pa(v_i)$ and they uniquely determine the value of $v_i$. Together, $P(\\textbf{U})$ and $\\textbf{F}$ induce $P(\\textbf{V})$, a distribution over $\\textbf{V}$.\n",
    "\n",
    "We represent the causal assumptions in an SCM via a causal diagram. This is a directed acyclic graph (DAG) where each node corresponds to a variable in the model. A directed edge from $x_i$ to $x_j$ indicates that the value of $x_j$ depends on the value of $x_i$, or $x_i \\in pa(x_j)$. To ensure the validity of an SCM, we restrict the set of valid models to those that can be represented by acyclic graphs, to prevent circular definitions between variables [1]. Algebraically, we can interpret a causal diagram as defining a set of conditional independence assumptions. In particular, as the parents of $v_i$ completely determine its value, $v_i$ will be independent of every other variable in the model, conditional on its parents.\n",
    "\n",
    "Note the acyclicity assumption does not restrict the class of distributions that can be represented by an SCM because by the definition of joint probability any joint distribution $P(x_1, x2…x_n)$ can be factorized as $P(x_1 | x_2…x_n)P(x_2 | x_3…x_n)...P(x_n-1 | x_n) P(x_n)$. But, this can be represented as an SCM where $pa(x_i) = \\{x_{i+1}, x_{i+2}…x_n\\}$ without violating the acyclicity assumption. However, the any given causal graph may be consistent with only a subset of all possible distributions over the variables in the graph.\n",
    "\n",
    "For the purposes of this paper, we make the additional assumption that each unobserved variable is the parent of at most two observed variables. This simplifies the graphical representation by replacing each unobserved variable and its outgoing edges with a single undirected edge connecting its two children. This can be interpreted as representing potential confounding between the two variables. An example of such a simplified graph is shown in Figure 1."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Figure 1. Using Bidirected Edges to Represent Confounding**\n",
    "![](2023-01-14-13-06-10.png)\n",
    "*This figure shows an unobserved variable $C$ with two children being replaced with a bidirected, dashed edge. The bidirected edge represents the same information as $C$ did in the first diagram, but it is only possible to represent confounders with bidirected edges if they have exactly two children.*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conditional Independence Properties of Causal Diagrams\n",
    "\n",
    "One of the key properties of causal diagrams is that they can provide insight into the conditional independence properties of a distribution $P(\\textbf{U} \\cup \\textbf{V})$. As previously discussed, a variable $v_i$ is independent of all other variables in the model, conditional on its parents. This concept of a \"flow of dependence\" along edges connecting a node to its parent is a useful tool for understanding the conditional independence assumptions encoded in a causal diagram.\n",
    "\n",
    "However, it is important to note that dependence does not flow along every path in the diagram. Paths can be blocked by conditioning on certain variables, which alters the conditional independence properties of the distribution. We can view a path as a collection of vertices, each of which must have one of the following forms:\n",
    "\n",
    "$$X \\leftarrow Y \\leftarrow Z$$\n",
    "$$X \\rightarrow Y \\rightarrow Z$$\n",
    "$$X \\leftarrow Y \\rightarrow Z$$\n",
    "$$X \\rightarrow Y \\leftarrow Z$$\n",
    "\n",
    "In the first three cases, dependence will flow through the vertex as long as we do not condition on $Y$. In this case, we call the vertex unblocked. Conditioning on $Y$ blocks the path and prevents dependence from traveling along it. This means that, as long as this is the only path connecting $X$ and $Y$, the causal diagram is predicting that $X$ and $Z$ will be independent conditional on $Y$.\n",
    "\n",
    "The third case, known as a collider, is slightly different. The last vertex will be unblocked if and only if we condition on $Y$.\n",
    "\n",
    "To illustrate the concept of colliders, consider the example of college admissions. Without knowledge of whether a student was admitted, learning her SAT scores tells us nothing about her admissions essays. However, if we know that the student was admitted, and we observe that her SAT scores were low, we can infer that her essays must have been good.\n",
    "\n",
    "A path is considered blocked if any vertex along it is blocked. If, after conditioning on a set of variables $\\textbf{Z}$, there are no unblocked paths connecting two variables $v_i$ and $v_j$, then the model predicts that $v_i$ and $v_j$ are independent conditional on $\\textbf{Z}$. In this case, we say that $v_i$ and $v_j$ are d-separated by $\\textbf{Z}$. This concept of d-separation provides a means to connect the ideas of statistical association in the joint distribution with properties of the graph, and allows us to use graphical models of causal relationships to make testable predictions about datasets."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Figure 2. Examples of D-Separation**\n",
    "\n",
    "![](2023-01-14-13-52-24.png)\n",
    "\n",
    "*The figure shows an example of a causal graphical model. Nodes represent random variables, and edges represent direct causal influence.*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, in figure 2 we can make the following predictions about distribution $P(\\textbf{V})$ based on the causal diagram:\n",
    "\n",
    "- $A \\perp\\!\\!\\!\\!\\perp C$ but not $A \\perp\\!\\!\\!\\!\\perp C | D$\n",
    "- $A \\perp\\!\\!\\!\\!\\perp B | C$ but not $A \\perp\\!\\!\\!\\!\\perp B | C, D$\n",
    "- $B \\perp\\!\\!\\!\\!\\perp D | C$ but not $B \\perp\\!\\!\\!\\!\\perp D$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph Surgery and Causal Effects\n",
    "\n",
    "In causal inference, a fundamental task is to measure the causal effect of one set of variables, $X$, on another, $Y$. To operationalize this task within the Structural Causal Model (SCM) framework, we utilize the concept of interventions. Specifically, in the SCM, the values of $X$ are determined by its parents, $pa(X)$. However, we are interested in understanding the effect of altering the value of $X$ through intervention, rather than allowing it to be set by its natural causes. To model this intervention process, we perform \"graph surgery\" by cutting all incoming edges into $X$, and examining the resulting interventional distribution. This allows us to isolate any remaining conditional effect of $X$ on $Y$, which can then be interpreted as a causal effect.\n",
    "\n",
    "To gain further insight into this process, we can consider two types of paths that may connect $X$ and $Y$: backdoor paths and frontdoor paths. Backdoor paths are those that connect to $X$ through its parents, while frontdoor paths connect through its children. These paths represent different mechanisms through which $X$ may affect $Y$; frontdoor paths indicate direct causal effects, while backdoor paths indicate indirect effects through other variables (i.e. confounding). By performing graph surgery and cutting all backdoor paths, we effectively isolate any causal effects flowing through frontdoor paths.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Do-Calculus\n",
    "\n",
    "In the Structural Causal Model (SCM) framework, causal queries are represented by the use of the \"do-operator.\" The do-operator is indicated by its placement behind the conditioning bar in a probability expression, and it represents a modification of the underlying generating process. To illustrate, for sets of variables $X$, $Y$, and $Z$, the expression $P(Y | do(X), Z)$ represents the conditional probability $P(Y | X, Z)$ in the model that results from performing graph surgery on $X$. This represents a hypothetical scenario in which $X$ is fixed through intervention, rather than being determined by \"nature.\" A \"do-expression\" is any probability expression containing the do-operator.\n",
    "\n",
    "Both the average treatment effect (ATE) and the conditional average treatment effect (CATE) can be expressed in terms of do-expressions. The ATE is given by:\n",
    "\n",
    "$ATE = E(P(y | do(x = 1))) - E(P(y | do(x = 0)))$\n",
    "\n",
    "while the CATE is given by:\n",
    "\n",
    "$CATE = E(P(y | z, do(x = 1))) - E(P(y | z, do(x = 0)))$\n",
    "\n",
    "The manipulation of do-expressions is facilitated by Pearl's \"do-calculus\", which references properties of the model in which the do-expression is evaluated. The do-calculus provides conditions under which do-operators can be removed from an expression or replaced with conditioning. This is advantageous because it allows us to transform do-expressions, which cannot be estimated from the data, into traditional statistical estimands (e.g., $P(Y | X, Z)$), which can be estimated using parametric assumptions.\n",
    "\n",
    "$\n",
    "\\textbf{Rule 1 } \\text{Insertion/deletion of observations:}\\\\\n",
    "P(Y | do(X), Z, W) = P(Y | do(X), W) \\\\\n",
    "\\text{if } (Y \\perp\\!\\!\\!\\!\\perp Z | X, W)_{G_{\\overline{X}}}\n",
    "$\n",
    "\n",
    "$\n",
    "\\textbf{Rule 2 } \\text{Action/observation interchange:}\\\\\n",
    "P(Y | do(X), do(Z), W) = P(Y | do(X), Z, W) \\\\\n",
    "\\text{if } (Y \\perp\\!\\!\\!\\!\\perp Z | X, W)_{G_{\\overline{X} \\underline{Z}}}\n",
    "$\n",
    "\n",
    "$\n",
    "\\textbf{Rule 3 } \\text{Insertion/deletion of actions:}\\\\\n",
    "P(Y | do(X), do(Z), W) = P(Y | do(X), W) \\\\\n",
    "\\text{if } (Y \\perp\\!\\!\\!\\!\\perp Z | X, W)_{G_{\\overline{X} \\overline{Z(W)}}}\n",
    "$\n",
    "\n",
    "The task of removing the do-operators from a do-expression and turning it into a statistical estimand is called \"identification.\" It is a crucial step in the process of causal inference in the SCM framework. General procedures for identification allow us to express causal queries in the rich language of do-expressions and then algorithmically translate these queries into statistical estimands that can be directly estimated from the data. Additionally, because identification does not make any parametric assumptions about the data, it allows us to decouple our causal assumptions from our parametric assumptions during modeling."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Four Stages of Causal Inference\n",
    "\n",
    "Structured causal effect estimation is a four-step process consisting of modeling, identification, estimation, and robustness checks.\n",
    "\n",
    "1. Modeling: This step involves identifying plausible causal relationships in the form of a directed acyclic graph (DAG). The DAG serves as a representation of the causal structure of the system being studied.\n",
    "\n",
    "2. Identification: Once the causal structure is represented in the form of a DAG, the next step is to translate a causal query into an abstract estimator in the context of these assumptions. This process is known as identification, and it is a crucial step in the process of causal inference.\n",
    "\n",
    "3. Estimation: After the abstract estimator has been derived, the next step is to add parametric assumptions and pick a specific model to represent the abstract estimator. This model is then fitted to the data, and an estimate of the causal effect is extracted.\n",
    "\n",
    "4. Robustness checks: The final step is to assess the robustness of the analysis to the specifics of the assumptions made in the modeling process. This is done by perturbing the assumptions of the modeling process and determining the sensitivity of the analysis to these perturbations. These robustness checks are important for ensuring the validity and generalizability of the causal estimates.\n",
    "\n",
    "It's important to note that the modeling, identification, estimation and robustness checks are interrelated, and that making progress in one step may require revisiting the others."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Problem of Identification\n",
    "\n",
    "### Overview\n",
    "\n",
    "It is important to note that not every causal estimand can be unambiguously estimated in every model. Identification, or the process of determining the causal estimand from the joint distribution, may fail when it is impossible to unambiguously determine $P(Y | do(X))$ from $P$. Identification is always possible in a graph with no confounding, but in some cases it is not possible because it is not possible to disentangle the effect from possible confounding. For example, in a model with a bidirected edge between variables, it may be impossible to identify $P(Y | do(X))$ because any observed effect could be explained by confounding along the bidirected edge, and there is no way to control for this."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Figure 4. The Bow Graph**\n",
    "\n",
    "![](2023-01-14-14-22-06.png)\n",
    "\n",
    "*The bow graph is the simplest example of a graph with a non-identifiable interventional distribution.*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rules of the do-calculus provide complete conditions for identification of causal estimands; if it is possible to convert the causal estimand to a statistical estimand, then it is possible using the do-calculus. However, manually applying the rules of the do-calculus to derive an abstract estimator is time-consuming and requires the researcher to make reference to complex properties of the causal graph, which is a task humans are ill-suited to, especially as the complexity of the graph grows. In the general case, it is too complex a task to be performed by hand.\n",
    "\n",
    "Thus, it is necessary to find algorithms by which identification can be performed automatically. This is a nontrivial problem; naive approaches often have exponential time complexity in the size of the graph, and the best algorithms, while polynomial time, rest on complex graph theory.\n",
    "\n",
    "Some researchers have simplified this problem by sidestepping direct application of the do-calculus and instead using the concept of adjustment sets. These methods rely on finding a set of variables which, when controlled for, block all backdoor-paths from the intervention set to the outcome set. However, these approaches face two distinct challenges. First, naive approaches to adjustment set search, such as those implemented in Knupple (2010), Breitling (2010), and Sharma (2020) rely on enumerating the set of all possible adjustment sets and then checking whether each successfully blocks all backdoor paths. This is an issue because the number of possible adjustment sets grows exponentially in the number of nodes in the graph. This makes these approaches infeasible for even fairly small graphs.\n",
    "\n",
    "More efficient algorithms exist for adjustment set search, such as the one proposed in Textor and Liskiewicz (2011), which works in polynomial time. However, the drawback of these algorithms is that although every valid adjustment set corresponds to a valid statistical estimator for the query, not every valid statistical estimator can be represented as an adjustment set. Because these algorithms are only searching among adjustment sets, they fail in cases where other classes of estimator are needed.\n",
    "\n",
    "To illustrate, in the famous front-door model, the interventional distribution $P(Y | do(X))$ is identified by the simple statistical estimator $P(Y | do(X)) = \\sum_z P(Z | X) \\sum_x P(Y | Z, X) P(X)$. This estimator works by breaking the problem into two subproblems: first identifying the interventional distributions $P(M | do(X))$ and $P(Y | do(M))$ and then combining these to identify $P(Y | do(X))$. Each subproblem can be solved using an adjustment set operator, but there is no adjustment set estimator which identifies $P(Y | do(X))$."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C-components\n",
    "\n",
    "Front-door estimation is an interesting technique, but it also illustrates a larger concept in causal inference known as c-component factorization. C-components, or connected components, are subsets of the graph that are connected via bidirectional (confounding) edges. Two nodes, $A$ and $B$, in a causal graph are in the same c-component if and only if there is a path from $A$ to $B$ that only follows bidirectional edges. It has been shown that any causal graph can be uniquely partitioned into a minimal set of c-components (Tian, 2002).\n",
    "\n",
    "More importantly, Tian (2002) showed that for any c-component $C$ in a graph $G$, the interventional distribution $P(C | do(V \\backslash C))$ is identifiable, where $V$ denotes the set of nodes in $G$ and $\\backslash$ represents set difference. This means that the problem of identifying $P(Y | do(X))$ can be broken down into a set of subproblems, one for each c-component in the graph $G \\backslash X$. This is the first critical insight that enables efficient identification and is known as c-component factorization.\n",
    "\n",
    "C-components also allow for the introduction of more complex graphical structures, such as the c-tree. A $Y$-rooted c-tree is a graph $G$ that contains both directed and bidirected edges, where the entire graph is a single c-component and every node has at most one child. Additionally, there is a single node $Y$ that has no children. If there are multiple nodes with no children, these nodes are referred to as the root-set of $G$, and the graph is called a c-forest."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Figure 4. A C-Tree and  C-Forest**\n",
    "\n",
    "![](2023-01-14-15-01-52.png)\n",
    "\n",
    "*This figure shows a c-tree (left) and a c-forest (right). Note that both are c-components because they are completely connected by bidirectional edges. In addition, in both, no node has more than one child. However, in the c-tree, C is the only node without children. This makes this a $C$-rooted c-tree. On the other hand, the graph on the right has two nodes without children: $C$ and $G$. This makes it a $\\{C, G\\}$-rooted c-forest.*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By utilizing c-forests, the concept of a hedge can be defined. Hedges are graphical structures that prevent the identification of interventional distributions. In a causal graphical model with graph $G$, if an interventional distribution $P(Y | do(X))$ is sought for two sets of random variables $X$ and $Y$, and if there exist two subgraphs $F$ and $F'$ such that the intersection of $F$ and $X$ is non-empty, but the intersection of $F'$ and $X$ is empty, and if $F'$ is a subgraph of $F$, and both form $Z$-rooted c-forests, where $Z$ is a subset of $Y$, the interventional distribution $P(Y | do(X))$ will be identifiable if and only if such $F$, $F'$, and $Z$ do not exist.\n",
    "\n",
    "In other words, if two nested c-forests are found, where at least some elements from $Y$ are in their root set, and the smaller one does not contain any elements from $X$ but the bigger one does, the interventional distribution is not identifiable."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shpitser's Algorithm\n",
    "\n",
    "Shpitser’s ID algorithm exploits the properties of c-components to identify interventional distributions. It is polynomial time and can always derive an estimator if one exists. The algorithm works as follows (Shpitser, 2008):\n",
    "\n",
    "$\n",
    "\\text{function }\\textbf{ID}(y, x, P, G)\\\\\n",
    "\\text{INPUT: x, y value assignments, P a probability distribution, G a causal diagram}\\\\\n",
    "\\text{OUTPUT: Expression for } P_x(y) \\text{in terms of } P \\text{ or } \\textbf{FAIL}\n",
    "$\n",
    "\n",
    "$\n",
    "\\text{1. if } x = \\emptyset \\text{ return } \\sum_{v \\setminus y} P(v)\\\\ \\\\\n",
    "$\n",
    "\n",
    "$\n",
    "\\text{2. if } V \\setminus An(Y)_G \\ne \\emptyset \\\\ \\text{ return } \\textbf{ID}(y, x \\cap An(Y)_G, \\sum_{v \\setminus An(Y)_G} P, G_{An(Y)})\n",
    "$\n",
    "\n",
    "$\n",
    "\\text{3. let } W = (V \\setminus X) \\setminus An(Y)_{G_{\\overline{x}}} \\\\\n",
    "\\text{if } W \\ne \\emptyset \\text{, return } \\textbf{ID}(y, x\\cup w, P, G)\n",
    "$\n",
    "\n",
    "$\n",
    "\\text{4. if } C(G \\setminus X) = {S_1...S_k}\\\\\n",
    "\\text{return } \\sum_{v \\setminus (y \\cup x)} \\prod_{i} \\textbf{ID}(s_i, v \\setminus s_i, P, G)\n",
    "$\n",
    "\n",
    "If line 4 does not return, then $C(G \\setminus X) = {S}$\n",
    "\n",
    "$\n",
    "\\text{5. if } C(G) = {G} \\text{, throw } \\textbf{FAIL}\n",
    "$\n",
    "\n",
    "$\n",
    "\\text{6. } S \\isin C(G) \\text{ return } \\sum_{s \\setminus y}\\prod_{ \\{i | V_i \\subset S \\} } P(v_i | v_\\pi^{(i - 1)})\n",
    "$\n",
    "\n",
    "$\n",
    "\\text{7. if } (\\exists S') S \\subset S' \\in C(G) \\\\\n",
    "\\text{ return } \\textbf{ID}(y, x \\cap S', \\prod_{ \\{i | V_i \\subset S' \\} }P(V_i | V_\\pi^{(i - 1)} \\cap S', v_\\pi^{(i - 1)} \\setminus S'), G_{S'})\n",
    "$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first three lines set up the algorithm. Line one is a base-case for identifiability. Lines two and three perform simplification.\n",
    "\n",
    "Line four works by breaking up the identification problem into subproblems. Considering the subgraph $G’ = G \\setminus X$, we find the c-components $\\{s_i\\}$ of $G’$. If there is more than one, then we can identify $P(Y | do(X))$ by finding the interventional distribution $P(s_i | do(G \\ s_i))$ for each $s_i$. Because of c-component factorization, we know that all such terms will be identifiable if and only if $P(Y | do(X))$ is identifiable. We can then take the product of all such terms to get a joint interventional distribution over the nodes in $G’$. By marginalizing all variables other than those in $X$ and $Y$, we can identify the interventional distribution.\n",
    " \n",
    "After repeated application of the above step, we will be in a position where $G’$ consists of a single c-component. There are three possible ways in which $X$ could relate to $G’$. $X$ and $G’$ could together form a single c-component. In this case, we have discovered a hedge, proving the interventional distribution is not identifiable (line 5). There could be no bidirectional edges connecting elements of $G’$ to elements of $X$. In this case, there are no backdoor paths from $X$ to $G’$ and we can identify the interventional distribution by conditioning on $X$ (line 6). It could be that some elements $Z \\subset X$ are connected via bidirectional edges to elements in $G’$, while others $W \\subset X$ are not. In this case, we can condition on $W$ and make a recursive call to the algorithm, attempting to identify the interventional distribution $P(G’ | do(Z))$ (line 7).\n",
    " \n",
    "The algorithm as described so far can only deal with queries of the form $P(Y | do(X))$, but often we will wish to calculate conditional interventional effects of the form $P(Y | do(X), Z)$. Thankfully, queries of this form can be mapped to queries without a conditional term with only a minimal transformation. This modification of the algorithm is known as IDC, or ID with conditioning, and it eliminates conditional variables in two ways. The first way is using Rule 22 of the do-calculus: if a conditional variable $z \\in Z$ has no back door paths to $Y$ when conditioning on $X$ and $Z \\ z$, then conditioning on z is equivalent to intervening on it, and it can be put inside the do operator. The second way is to treat $z$ as an outcome, run the algorithm, and then condition on $z$. Together, these two techniques can be used to eliminate all conditional variables from the query."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-existing Implementations\n",
    "\n",
    "A number of open source implementations of the ID algorithm existed prior to my work. Dowhy is a popular python library developed by Microsoft Research, but its implementation is too slow. Researchers working on the dowhy project explicitly asked me to create a faster implementation and integrate it with their library. There is also an implementation in Clojure called Whittemore which is quite fast, but because Clojure is a JVM language it is not possible to integrate this implementation with Python, R, or Javascript code. I based my implementation on Whittemore. Ananke is a causal inference library developed by Shpitser’s team, and it has an implementation of a related algorithm, but Ananke has not seen widespread adoption, and it is unmaintained. FInally, the Javascript/R tool Daggity has an implementation of adjustment set operators, which suffer from the drawbacks discussed above."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation\n",
    "\n",
    "## Technical Challenges\n",
    "\n",
    "### Graph Representation and Subroutines\n",
    "As a prerequisite to the rest of the work I did for this project, I implemented a set of graph routines to capture key operations that need to be performed during the algorithm. The key operations here are c-component factorization and ancestor search. C-component factorization is breaking partitioning the graph $G$ into subgraphs $S_i$ that obey the following constraints. Any two nodes ${a, b} \\subset S_i$ there exists a path from $a$ to $b$ along bidirectional edges, and for any two nodes $c \\in S_i$ and $d \\in S_j$ if $i \\ne j$ then there does not exist such a path. Ancestor search is the problem of finding the set $An(y)$ for a nodes $y$ such that a node $w$ is a member of $An(y)$ if and only if there is a directed path from $w$ to $y$.\n",
    "\n",
    "Because of of these operations only requires access to one kind of edge (directed or bidirected), I model a causal graphical model as consisting of two graphs: one directional and one bidirectional. The directional graph data structure handles ancestor queries, and the bidirectional graph data structure handles c-component factorization. Each of these problems is trivially solvable in $O(E)$ (order of number of edges in the graph) using breadth-first search. The subtlety here is because of the way the algorithm recursively parititons the graph into subproblems, we will be repeatedly rerunning ancestor and c-components queries on slightly modified versions of the graph. The causal graph data structure needs to efficiently handle arbitrary series of the following four operations:\n",
    "\n",
    "- c-component queries\n",
    "- ancestor queries\n",
    "- graph surgery (maintaining a copy of the original graph)\n",
    "- node deleletion (maintaining a copy of the original graph)\n",
    "\n",
    "Specifically, lines 2 and 3 of the algorithm require ancestor queries, and in the case of line 3, this query is performed after surgey. Lines 4 and 5 require c-component queries, and line 4 requires first removing $x$ from $G$.\n",
    "\n",
    "Since a structure representing the original graph must be maintained through deletions, we cannot just apply these as mutable changes to the data structure. So, a naive approach would be to make a copy of the graph at each modification and run the queries on this copied graph. This is quite wasteful from a resource standpoint though because it requires a linear-time $O(N + E)$ copy operation (order of number of nodes plus number of edges) at each modification. Since the algorithm has a worst case recursion-depth of $O(N)$, this amounts to an an additional quadratic order $O(N^2 + NE)$ runtime cost. The more concerning term here is the $NE$, because number of edges can grow with $O(N^2)$, so this term could be cubic. Although this is unlikely to be an issue in manually-specified models, it could become a real problem is models derived via automated causal discovery (e.g. in geothermal or econometric datasets) or in bioinfomatics applications, where causal networks are used to study genetic data, and models can get quite complicated.\n",
    "\n",
    "To address this problem, I implemented a set of routines that allows small modifications to be performed to the original graphs in such a way that a new data structure is created which is logically distinct inside the program but which uses most of the same memory. This reduces the memory footprint of the algorithm as well as reducing time spent copying data.\n",
    "\n",
    "Instead of copying the causal graph when subgraphing, the data structure maintains a reference to the original graph, and each subgraph tracks the nodes which it currently contains and the nodes which have been the subject of surgery. It is still possible to perform c-component and ancestors queries with the same time complexity. This requires a $O(N)$ operation, but it avoids the especially costly $O(NE)$ term in the final time complexity."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simplification\n",
    "Simplification is an important step in computational identification because the ID algorithm tends to return symbolic expressions that are quite complex and require simplification. The complexity of these outputs is not indicative of the complexity of the \"answer\", but they tend to contain many elements which are algebraically redundant. E.g., frequently identical terms will appear in the numerator and denominator of a quotient. A few lines of mathematical manipulation can reduce the complexity of these expressions significantly, but it is a nontrivial problem to write a program that can do this.\n",
    "\n",
    "It is important to simplify the results for a couple of reasons. Simpler expressions are easier for humans to understand. They make it easier to test the program because they reduce the number of “correct” answers to an identification problem. And, maybe most importantly, simpler expressions are easier to evaluate numerically. It is both computationally cheaper and more accurate to simplify an expression before applying numerical estimation techniques.\n",
    "\n",
    "Whittemore, which I have borrowed from extensively, uses a heuristic-based simplification algorithm with just a couple of rules. My original plan was to just use this, but their algorithm contains idiosyncracies that I think may indicate a mathematical error. I plan to present an example failure case in the next iteration of this report.\n",
    "\n",
    "Tikka and Karvanen (2017) describe a simplification routine that uses properties of the graphical model to find ways to reduce conditional terms. I was originally optimistic about this approach as it has nice guarantees on the degree of simplification. However, this approach has a time complexity that gorws significantly faster than exponential in the number of variables, and so would not prove practical for real problems.\n",
    "\n",
    "Instead of relying on these solutions, I developed my own heuritsitc simplification algorithm. This algorithm relis on an observation that most of the redundancy in the estimands generated by the algorithm can be remedied by fairly simple algebra. I implemented a simple recursive algorithm that applies a series of transformations on elements in the symbolic expression. It traverses the expression tree, replacing each node with a simplified version.\n",
    "\n",
    "For each possible type of subexpression, the following transformations are applied:\n",
    "\n",
    "expression type | transformations | example | example (simplified)\n",
    "---|---|---|---\n",
    "Quotient | Merge nested quotients and products. Cancel identical terms. | ${P(a)(P(b)P(c)) \\over {P(b) \\over P(d))}}$ | $P(a)P(c)P(d)$\n",
    "Product | Merge nested products and quotients. | ${P(a) \\over P(b)} P(c)$ | $P(a)P(c) \\over P(b)$\n",
    "Marginal | Convert sum over joint distribution to marginal distribution. | $\\sum_{a} P(a,b)$ | $P(b)$\n",
    "Conditional Probability | Convert to quotient. | $P(a \\| b)$ | ${P(a, b) \\over P(b)}$\n",
    "\n",
    "This scheme has the disadvantage that no conditional probability expressions are left in the final result, which can make the formulas less readable. But, this is worth it because in quotient form it is much easier to identify redundant terms and cancel them. So, the formulas end up simpler on balance."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To demonstrate the effectiveness of this technique, I apply this algorithm to the front door estimator. This expression is unsimplified expression, and it represents the form of the expression that is derived using ID. \n",
    "\n",
    "$$\n",
    "P(y | do(x)) = \\sum_{Z} \\big(\\sum_{} \\big(\\sum_{X} \\big({\\sum_{} \\big(P(X, Z, Y)\\big) \\over \\sum_{Y} \\big(P(X, Z, Y)\\big)} {\\sum_{Z, Y} \\big(P(X, Z, Y)\\big) \\over \\sum_{Z, Y, X} \\big(P(X, Z, Y)\\big)}\\big)\\big) \\sum_{} \\big({\\sum_{} \\big(\\sum_{Y} \\big(P(X, Z, Y)\\big)\\big) \\over \\sum_{Z} \\big(\\sum_{Y} \\big(P(X, Z, Y)\\big)\\big)}\\big)\\big)\n",
    "$$\n",
    "\n",
    "After simplification, the expression is reduced to the following form. This example highlights the need for a simplification algorithm, and it shows that the heuristic simplification algorithm is surprisingly effective for outputs of this size.\n",
    "\n",
    "$$\n",
    "P(y | do(x)) = \\sum_{Z} \\big({\\sum_{X} \\big({P(X) P(X, Z, Y) \\over P(X, Z)}\\big) P(X, Z) \\over P(X)}\\big)\n",
    "$$\n",
    "\n",
    "Both of the above expressions were generated by `pqp`."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A limitation of simplification is that, because it is implemented in Rust, it is only applied to the results of calls to the underlying Rust library, which is only for identifying specific interventional distributions. These expressions may be assembled into more complex estimands inside the Python library which cannot currently be simplified."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimation\n",
    "\n",
    "In order for the estimator to be useful, we need to be able to use it to actually estimate a treatment effect in the precense of real data and a set of parametric assumptions. I have implemented a feature that allows for parametric modeling and causal estimation on statistical quantities. This feature is implemented as part of the Python wrapper.\n",
    "\n",
    "In general, estimation of useful quantities from identified estimands can be quite hard because they involve a large number of nested sums (or integrals, in the continuous case). The computational complexity of evaluating nested sums grows exponentially in the number of these sums, and there is no way to reduce this cost in the general case while still computing an exact value.\n",
    "\n",
    "There are many approaches to this problem. A number of numerical approximation tools have been developed in the field of Bayesian statistics, but these a often quite finicky and most are heavy weight solutions. Shpitser (2012) shows how the conditional independence properties of causal graphs can be exploited to reduce the practical difficulty, but their algorithm is still exponential time. Bhattacharya et. al. (2021) used a variety of sampling techniques, but this is a heavyweight solution, and although the estimators they propose are doubly-robust, they still require fitting a number of intermediate linear models which carry undesirable parametric assumptions.\n",
    "\n",
    "Due to the complex tradeoffs between algorithms and difficulty of implementation, I have chosen to extend Brule (2018) and implement a brute-force solution. Brule's estimator relies on directly calculating the sums, and as such remains completely non parametric and is tractable for small number of variables. Brule assumes that all variables in the model are discrete, which is needed for the brute-force approach, so to extend to the continuous case I plan to use quantization.\n",
    "\n",
    "In addition to the computational difficulties, a further, slightly more subtle, difficulty has to do with the *positivity*. All useful estimators identified by ID will have conditional probability terms, and these remained defined only when the conditioning variable can be guaranteed to have positive probability in the model. Brule (2018) uses a maximum likelihood multinomial estimator, which does not guarantee positivity. To get around this issue, I use a Bayesian multinomial estimator with a Dirichlet prior, which does guarantee positivity."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretability"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One problem with a large number of existing statistical software is that users often approach these tools with little udnerstanding of how they work or what exactly they are doing. This can lead to two main classes of issues: (1) users may not understand the assumptions that are being made by the software and thus fail to understand the limitation of an analysis, and (2) users may feel disempowered or \"out of the loop\". If the options are to either use a tool blindly or to dig into the source code or a dense textbook, then the former is often the more attractive option.\n",
    "\n",
    "This is often okay in the context of predictive inference, as the goal is usually to simply make accurate predictions, and this can be checked against ground truth using a holdout set. But, in the context of causal inference, the goal is to make causal claims, and so there is no easily accessible ground truth against which to check the results. Additionally, many of the assumptions made in causal inference are often numerous and complex, and so users cannot be expected to know (or necessarily understand) them.\n",
    "\n",
    "To approach these problem, I decided that it was important that users of `pqp` be able to access a summary of the intermediate steps, transformations, and underlying assumptions performed by the algorithms. As such, I implemented the Python wrapper to automatically construct a computational graph to track the dependencies between different intermediate results derived during an analysis. This allows the user to inspect the steps actually performed by the library during an analysis and understand the assumptions that are being made.\n",
    "\n",
    "To achieve this technically, I implemented a `Result` class which stores the outputs of key computations, such as data preprocessing, model fitting, identification, and estimation. A higher order function (called `entrypoint` in the code) wraps the key subroutines which perform these calculations. When they are called, it dynamically captures inputs to these functions, saving them for reproducability or sensitivity analysis. It then searches the inputs for any instances of `Result` and, if found, adds these as dependencies of the current calculation. Then, it wraps the output of these functions in a `Result` which can access information about its logical dependencies. In addition, the subroutines report any transformations or assumptions they make, and these are captured by `entrypoint` and included in the metadata inside `Result`. As such, any `Result` object can be used to reconstruct the entire analysis up to that point, and it knows all the assumptions underlying it.\n",
    "\n",
    "To use these in the code, you can call the `.explain()` and `.explain_all()` methods in the code to get an overall summary. A demonstration of this method is shown in the example below."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "\n",
    "The primary goals for this implementation were correctness and ease of use. In this section, I examine the library in light of each of these goals."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correctness\n",
    "\n",
    "One of the main impetus for this project was to improve on the many correctness issues with existing implementations of the algorithm. To this end, I implemented a large number of tests. I used hand derived answers to test the algorithm on a number of famous examples (backdoor, frontdoor, IV, bowgraph). Then, I copied all of the other examples of identification from Shpitser's dissertation (Shpitser, 2008). He gives 15 examples of identifiable and nonidentifiable graphs, and I test the algorithm the on each of these examples."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Figure 5. Examples of identifiable graphs**\n",
    "\n",
    "![](2023-02-25-09-07-36.png)\n",
    "\n",
    "*This figure, taken from Shpitser (2008) shows several examples of identifiable graphs. My implementation recovers the correct estimator for each.*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To demonstrate typical output from the algorithm, I apply the algorithm to find estimators for each of these graphs. These estimators are shown below. The algorithm successfully recovers the estimator in each case. The only issue highlighted by this example is that the simplification routine still stuggles to achieve an acceptable outcome as graphs get larger. This is an area of active work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\textbf{Model a: } P(y | do(x)) = {P(x, y) \\over P(x)}$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\textbf{Model b: } P(y | do(x)) = \\sum_{z} \\big({P(z, y, x) \\over P(x)}\\big)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\textbf{Model c: } P(y | do(x)) = \\sum_{z} \\big({P(x, y, z) P(z) \\over P(x, z)}\\big)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\textbf{Model d: } P(y | do(x)) = \\sum_{z} \\big({P(z) P(z, y, x) \\over P(z, x)}\\big)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\textbf{Model e: } P(y | do(x)) = \\sum_{z} \\big({\\sum_{x} \\big({P(z, y, x) P(x) \\over P(z, x)}\\big) P(z, x) \\over P(x)}\\big)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\textbf{Model f: } P(y | do(x)) = \\sum_{z1, z2} \\big({\\sum_{x} \\big({P(z1, z2, x) P(x) \\over P(z1, x)}\\big) P(z1, z2, x, y) P(z1, x) \\over P(z1, z2, x) P(x)}\\big)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\textbf{Model g: } P(y | do(x)) = \\sum_{z2, z3, z1} \\big({\\sum_{z1, x} \\big({P(z3, y, z1, z2, x) P(z3, z2, x) \\over P(z3, z1, z2, x)}\\big) \\sum_{z1, z3, y, x} \\big({P(z3, y, z1, z2, x) P(z3, z2, x) \\over P(z3, z1, z2, x)}\\big) P(z3, z2) P(z1, z2, x) \\over \\sum_{z1, y, x} \\big({P(z3, y, z1, z2, x) P(z3, z2, x) \\over P(z3, z1, z2, x)}\\big) \\sum_{z3, x, z1, y, z2} \\big({P(z3, y, z1, z2, x) P(z3, z2, x) \\over P(z3, z1, z2, x)}\\big) P(z2) P(z2, x)}\\big)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Math\n",
    "from string import ascii_lowercase\n",
    "from supplement import g1, g2, g3, g4, g5, g6, g7, x, y\n",
    "from pqp.symbols import *\n",
    "\n",
    "for i, g in enumerate([g1, g2, g3, g4, g5, g6, g7]):\n",
    "    estimand = g.identify(P(y, given=do(x)))\n",
    "    display(Math(\"\\\\textbf{Model \" + ascii_lowercase[i] +\n",
    "        \": } P(y | do(x)) = \" + estimand.identified_estimand.to_latex()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, Shpitser (2008) supplies of a number of examples of nonidentifiable graphs. The algorithm correctly identifies these as nonidentifiable. The examples from Shpitser (2008), along with estimators derived by the algorithm, are shown below.\n",
    "\n",
    "**Figure 6. Examples of nonidentifiable graphs**\n",
    "\n",
    "![](2023-02-25-09-22-50.png)\n",
    "\n",
    "*This figure, taken from Shpitser (2008) shows several examples of nonidentifiable graphs. My implementation correctly identifies these as nonidentifiable.*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When run on each of these graphs, the algorithm successfully recovers a hedge, demonstrating non identifiability of each graph."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ease of Use\n",
    "The Rust code underlying the library is extremely fast, but Rust is a language used by few in the causal inference community. To make the library more accessible, I created a Python library that wraps the Rust code. Although Python is definitely second to R in terms of adoption in the community, it is much more common among industrial practicioners.\n",
    "\n",
    "While the focus of the Rust implementation is correctness and performance, the focus of the Python bindings is on elegance and usability. I used Python's magic methods to create an API for specifying and querying causal models that is extremely simple and readable. I created a website with documentation for the python library, and I have published the library on PyPI.\n",
    "\n",
    "By utilizing Python's infix operators, I was able to create an API in which graphs can be created via an intuitive embedded syntax. It is possible to create a new causal model using the library in just a few lines. The `<=` operator creates a directed edge in the graph, while the `&` operator creates a bidirected edge. See the following example, which implements the front-door model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pqp.symbols import *\n",
    "from pqp.identification import Graph\n",
    "\n",
    "x, y, z = make_vars(\"xyz\")\n",
    "g = Graph([\n",
    "    z <= x,\n",
    "    y <= z,\n",
    "    x & y\n",
    "])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identification of arbitrary estimands is accessed through the `.identify()` method of the `Graph` class. Causal estimands can be specified using a set of symbolic operators that provide a high degree of leverage in specifying the desired quantity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\sum_{z} \\big({\\sum_{x} \\big({P(z, y, x) P(x) \\over P(z, x)}\\big) P(z, x) \\over P(x)}\\big)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# identification of interventional distribution\n",
    "interventional = P(y, given=do(x))\n",
    "g.identify(interventional).identified_estimand.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle E_{y} \\big[\\sum_{z} \\big({\\sum_{x} \\big({P(z, y, x) P(x) \\over P(z, x)}\\big) P(z, x = 1) \\over P(x = 1)}\\big) - \\sum_{z} \\big({\\sum_{x} \\big({P(z, y, x) P(x) \\over P(z, x)}\\big) P(z, x = 0) \\over P(x = 0)}\\big)\\big]$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# identification of ATE\n",
    "ate = Expectation(y, P(y, given=do(x.val == 1)) -\n",
    "    P(y, given=do(x.val == 0)))\n",
    "g.identify(ate).identified_estimand.display()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A number of convenience subroutines are also available for more complex common queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle E_{y} \\big[{\\sum_{x} \\big({P(z = 1, y, x) P(x) \\over P(z = 1, x)}\\big) P(z = 1, x = 1) \\over \\sum_{y} \\big({\\sum_{x} \\big({P(z = 1, y, x) P(x) \\over P(z = 1, x)}\\big) P(z = 1, x = 1) \\over P(x = 1)}\\big) P(x = 1)}\\big] - E_{y} \\big[{\\sum_{x} \\big({P(z = 1, y, x) P(x) \\over P(z = 1, x)}\\big) P(z = 1, x = 0) \\over \\sum_{y} \\big({\\sum_{x} \\big({P(z = 1, y, x) P(x) \\over P(z = 1, x)}\\big) P(z = 1, x = 0) \\over P(x = 0)}\\big) P(x = 0)}\\big]$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pqp.identification import CATE\n",
    "\n",
    "cate = CATE(\n",
    "    outcome=y,\n",
    "    treatment_condition={x: 1},\n",
    "    control_condition={x: 0},\n",
    "    subpopulation={z: 1}\n",
    ")\n",
    "g.identify(cate).identified_estimand.display()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The library also supports visualization using the `networkx` library as an optional dependency. Although this feature is not entirely polished yet, it is useful to quickly visualize the model. Bidirected edges are indicated using a dashed line. This feature is demonstrated in the examples section below."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, I show how my code can be used to estimate an average treatment effect using the front door model on a simulated dataset. The dataset has four variables: $x$, $z$, $y$, and $m$. The variable $x$ represents a treatment which influences an outcome $y$ via a mediator $m$. The variable $z$ is a confounder which influences both $x$ and $y$. The following graph shows the causal structure of the model. All are binary except for $y$, which is on ${1, 2, 3}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgMAAAGFCAYAAABg2vAPAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA210lEQVR4nO3deXRU9533+U+V9rUQIBYJCcwOQlR5CQQ7ATtgYxZjlrpgY5vEaWdp9zhuO7Y7Y/dDTsdjT/LE3Zk5z3M6yUym00078WOQNxw7sWPHhnhp8IaQQCAWg0DsIEobaKm684esshZAKqnq3lrer3NyEgmp7jcJrt+n7ud373WYpmkKAAAkLKfdAwAAAHsRBgAASHCEAQAAEhxhAACABEcYAAAgwREGAABIcIQBAAASXHJ/figQCOjYsWPKycmRw+GI9EwAACAMTNNUQ0ODCgoK5HRe/vN/v8LAsWPHVFRUFLbhAACAdY4cOaIxY8Zc9s/7FQZycnKCL5abmxueyQAAQETV19erqKgouI5fTr/CQGc1kJubSxgAACDG9FXxs4EQAIAERxgAACDBEQYAAEhwhAEAABIcYQAAgARHGAAAIMERBgAASHCEAQAAEhxhAACABEcYAAAgwREGAABIcIQBAAASHGEAAIAE16+nFgIAYlObP6A9JxpUUetTZa1Ppxpa1NruV2pykkbkpGlGoUulhS5NHZWjlCQ+HyYqwgAAxKGjdc36/fYa/W5bjXwX2iRJyU6H2gNm8GeSnQ79fnuNJMmVkaK7Zhdr7axijcnLtGVm2MdhmqbZ1w/V19fL5XLJ5/MpNzfXirkAAANQf7FNT79Wpec/PiKHQwr0+Q7/JadDMiWtubZITyyZppz0lIjNCWv0d/3mnBAAxImt1ac1/5+3aOMnR2QqtCCgL37eNKWNnxzR/H/Zoq3VpyMyJ6IPYQAA4sB/fHBI6367XWebWkIOAT0FTOlMY4vW/Xa7Nnx4KCzzIboRBgAgxm348JB+/OouSaGfDbicztdZv3kXgSABEAYAIIZtrT6t9Zt3RfQY6zfvojKIc4QBAIhR9Rfb9MNN5XI6Inscp0N6pKxcDRfbInsg2IYwAAAx6unXqsKyR6AvnXsInnq9KrIHgm0IAwAQg47UNev5j49EPAh0CpjS8x8f0dG6ZmsOCEsRBgAgBj23vUaOCNcDPTm/OC7iD2EAAGJMmz+g322rseysQCe/KT27rUZt/oC1B0bEcTtiAIgxe040BG8xfCXn//o7+d5/TgXf/bV87z+n5v3b5XAmK+fqRXJ9/W75G87o3Ju/0sWanXKkpMk1a6VyZ6+84mv6LrRp74kGzSh0heu/DqIAZwYAIMZU1PpC+vnTL/9Mpmkqb963lFYwRb4PnlfDR6/o5P/6b0rKGaa8G+9VSl6B6t75N12sqQz78RH9CAMAEGMqa31KDuF6wrSCycpf9qhyrlms/FX/qKSc4ar7y/+n7JkLNGzh/cq5ZrFGeNfLkZymxp1/vuJrJTsdhIE4RBgAgBhzqqGl29MH+5LtviX4nx3OJKWOmijJVPbMm4Pfd6ZnK3loodrPn7jia7UHTJ1ubAl5ZkQ3wgAARLmtW7fqlVdeUWNjoySptd0f0u8n5+Z3+9qZliVHcqqSMl09vp+pQEtjn6/X0hba8RH92EAIAFHuoYce0qeffqrk5GR97Wtfk+Z+T1JO/1/AcYnPfZf6ntTx2MI+pKUk9f/YiAmcGQCAKFdSUiKn06n29nZt2bJFO7e9J9PfbsssyU6H8rPTbDk2IoczAwAQhRobG7Vz506Vl5dr3759CgQ6ru03TVOtJ/ZLnlttmas9YKqUywrjDmEAAGxkmqaOHj2qHTt2qLy8PPjvBw4ckGmaSk5OVlFRUbffaT15QA6rbz/YBWEg/hAGAMAira2t2r17d3DB71z86+rqJEl5eXlyu91aunSp3G633G63pk+frvr6eo0YMSL4Ot9bs1Rb0pPlu2h9VeDKSNGUUSHsV0BMcJhm37tF6uvr5XK55PP5lJuba8VcABDTzpw50+2Tfnl5uXbv3q329o4FfOLEiXK73fJ4PMGFv6io6LKf+AsKCtTQ0KANGzZoxYoV+u9v7NGvthyw9JbESQ7p+/Mm6NGFU607KAalv+s3ZwYAYBD8fr/279/f7ZN+eXm5amtrJUkZGRmaOXOmvvrVr+p73/uePB6PSktLlZMT2qfrN998U0OGDNGYMWMkSWtnFeuX7x4I+3+fKwlIunNWsaXHhDUIAwDQT1039XUu/BUVFWpu7nisb0FBgdxut9atWxf81D9x4kQlJQ3+UrwZM2Z0+3pMXqbWXFekjZ9Y8xhjp0NafV2RxuRlRv5gsBxhAAB66Lmpr3Ph77qpb9q0aXK73TIMI3iaPz8/v+8XD6MnlkzTX/ae0pnGlogGAqdDGp6dpicWT4vcQWArwgCAhNa5qa/rKf6um/qGDBkij8ejJUuWBPv96dOnKy3N/mvtc9JT9IzXrXW/3R7R4wRM6RmvWznpKRE9DuxDGACQMDo39XVd+Ltu6pswYYI8Ho8eeuih4MJ/pU190WDu5Hz9ZFmJ1m/eFbFjPLmsRHMnW3vWA9YiDACIO36/XwcOHOh17X7XTX2lpaXBTX1ut1szZ84MeVNftFg3Z5wkaf3mXXI6FJbKoPN1nlxWonu+eH3EL8IAgJjW2NioioqKbgv/lTb1ud1uTZo0KSyb+qLJujnjNG5Ylh4pKx/0HoLOPQLPeN2cEUgQ3GcAQEzo3NTX89r9/fv399rU1/X6fas39dmt/mKbnn6tSs9/ckROSf4QQkGSo+PywTXXFumJJdPYIxAH+rt+EwYARJ2um/q6Lv7nzp2T1LGpr+uC7/F4omZTX7Q4Wtes57bX6NltNfJdaJPU8ZCh9i6nDLp93dKk+xfO1NpZxVw+GEcIAwBiQtdNfZ0Lf1VVldraOhawCRMm9Fr4o31TXzRp8we090SDKmp9qqj16XRji1ra/EpLSVJ+dppKC11qOlql7xhL9PH2bbr22mvtHhlhxB0IAUSVnpv6Ohf+npv6Zs+eHdzUV1paygeQQUpJcmpGoUszCl268zI/035NgX6UN0RlZWWEgQTFmQEAYddzU195ebl27twZ3NQ3evTobp/043VTXyz5zne+o3feeUf79u3jrEsc4cwAgIjruqmva7ffuakvKSlJ06ZNk8fj0apVqxJ2U18s8Hq9+s1vfqMdO3bo6quvtnscWIwwAKBfWltbVVVV1eva/Z6b+hYvXsymvhj0jW98Q0OHDlVZWRlhIAFREwDo5ezZs71uz3ulTX1ut1vFxcWcXo5xf/M3f6O//vWv2rt3L/9fxglqAgB9CgQCwcfvdl342dSXmLxer/7t3/5NO3fulNvttnscWIgwACSIzk19XRf+iooKNTU1SfpyU98999wT/NTPpr7EMn/+fA0Z0nFVAWEgsVATAHHGNE3V1tb2uoSv56a+nqf5R4wYYffoiAL33nuvPvzwQ1VVVVEVxAFqAiAB9NzU17nw99zUt2jRom6P301PT7d5ckQrwzD07//+76qsrFRpaand48AihAEgRnRu6uv5+N3OTX3jx4+Xx+PRgw8+GFz42dSHUC1YsEAul0ubNm0iDCQQagIgynTd1Nd14T969KgkKT09XaWlpd1u2sOmPoTTN7/5TX300UfavXu33aNgkKgJgBjQdVNf18fvdt3U53a7dffdd3d7/G5yMv/oInIMw9CGDRu0a9culZSU2D0OLMA7CmCBzk19PS/hu9SmvlWrVrGpD7a6+eablZubq02bNhEGEgQ1ARBmnZv6ei78nZv6XC5Xt138nXfqY1Mfosk999yjzz77TJWVlXaPgkGgJgAs0J9NfW63Ww8++GBw4WdTH2KBYRh69tlnVVVVpWnTptk9DiKMMAD0QyAQ6Pb43ctt6vvKV76i73znO3K73Zo5cyZn0hCzbrnlFuXk5GjTpk1av3693eMgwqgJgB6ampou+fjdnpv6ej5+l019iDd33XWXdu7cqYqKCrtHwQBREwB96Lqpr+un/X379gU39U2dOlUej0crVqwILvxs6kOiMAxDv//977Vnzx5NnTrV7nEQQYQBJISum/q6Lvxnz56V1LGpz+1269Zbb9U//MM/sKkPkLRw4UJlZ2errKxM//iP/2j3OIggagLEnXPnzvXayX+pTX1db9rDpj7g0u68807t3r1b5eXldo+CAaAmQNzr3NTXc+FnUx8QPoZhaNWqVaqurtbkyZPtHgcRQhhATOjc1Nd14b/Upr677rqLTX1AGC1atEhZWVkqKyvT448/bvc4iBBqAkQV0zR17NixXpfwXWpTX9dT/WzqAyLnjjvu0N69e/XZZ5/ZPQpCRE2AqNfa2qo9e/b0WvjZ1AdEF6/XK8MwtH//fk2cONHucRABhAFYor+b+n7wgx+wqQ+IMosXL1ZmZqbKysr0ox/9yO5xEAHUBAirS23qKy8v15EjRyR9uamv6yl+NvUB0W/16tU6cOCAPvnkE7tHQQioCRBxXTf1dS7+XTf1jRo1Sh6PR2vXrmVTHxDjvF6v1qxZo4MHD2r8+PF2j4Mw410Zfeq5qa9z4edOfUDiWLJkiTIyMlRWVqbHHnvM7nEQZjFfE7T5A9pzokEVtT5V1vp0qqFFre1+pSYnaUROmmYUulRa6NLUUTlKSXLaPW7Ua2tru+Tjd3tu6uu6m59NfUBi8Hq9Onz4sD766CO7R0E/xX1NcLSuWb/fXqPfbauR70LHJrRkp0PtgS+zTbLTod9vr5EkuTJSdNfsYq2dVawxeZm2zBxtOjf1dV34d+3axaY+AJdkGIbuuOMOff7557rqqqvsHgdhFHNnBuovtunp16r0/MdH5HBIgT6n/5LTIZmS1lxbpCeWTFNOekrE5owmXTf1dV342dQHIBSNjY3Kz8/Xk08+qUceecTucdAP/V2/YyoMbK0+rR9uKtfZppaQQkBPToc0PDtNz3jdmjs5P3wDRoGmpiZVVlZ2O8VfUVGhxsZGSV9u6uPxuwAGYuXKlaqtrdW2bdvsHgX9EHdh4D8+OKQfv7pLzhDPBlxO5+v8ZFmJ1s0ZN/gXtFjnpr6e3T536gMQSc8995zWrl2rQ4cOaezYsXaPgz7E1Z6BDR92BAEpPEGg6+us39zxutEcCC61qa+8vFxnzpyR1PtOfW63WyUlJWzqAxB2S5cuVVpamsrKyvTDH/7Q7nEQJlF/ZmBr9Wmt++32iB9nw72zoqIyuNSmvt27d6u1tVUSj98FYL/ly5fr5MmT+vDDD+0eBX2IizMD9Rfb9MNN5WGrBi7H6ZAeKSvX2w/Ps2xTYSAQ0MGDB3tdu99zU991112n++67j019AKKGYRi6++67deTIERUVFdk9DsIgqsPA069VDXqzYH8ETOlMY4ueer1KP105M+yv39zcfMnH7/bc1Med+gDEgttuu02pqakqKyvTQw89ZPc4CIOorQmO1DVr7n9/RxHOAd04HNJfH71pwPch6Lqpr+vCX11dzaY+AHFl2bJlOnv2rN5//327R8EVxHxN8Nz2GjkcUt9RJXycXxz30YVT+/zZtra2Sz5+t+emvoULF+qxxx5jUx+AuGIYhtatW6ejR49qzJgxdo+DQYrKMNDmD+h322oiXg/05DelZ7fV6O8XTO526+K6urpLPn6356a+Bx54QG63W263W2PHjmVTH4C4tWzZMqWkpOiFF17Qgw8+aPc4GKSorAkqan267X++1++fD7S16PhvO/4yjr73/5YzJU2S5L/QoOO/uV/JQ0Zq5F0/k8OZ1K/Xe2hai87s+yx4ur+mpuOWxtypDwC+tHTpUp0/f17vvdf/92tYK6ZrgopaX0g/70xJ0/ClD+nEfz6q81s3aOj870iSzr35SwVamjVsyUP9DgKmaeof/+X/UfbJcnk8Ht15553BxZ9NfQDwJcMw9K1vfUu1tbUqLCy0exwMQlSubJW1vl4PHepLWsEU5X51ler/6wVlTp4jf9N5NVdtVd787yhlaP//kiY7HbrvsZ/oF2tnDWR0AEgYnVXBiy++qAceeMDucTAIUflM31MNLSEFgU5DvrZWKcOLdfYPv9C5N3+ptKIZyrluWUiv4TelRn9U/s8CAFElLy9PCxYs0KZNm+weBYMUlatea7t/QL/nSErRsMUPqt13UmbrBQ1b8vcD2sTX0jaw4wNAojEMQ++9956OHz9u9ygYhKgMA6nJ/ev3L+Xi559Kksz2VrXXHRvQa6SlDPz4AJBIbr/9diUlJenFF1+0exQMQlSGgRE5aUp2hv6JvvXU5zr//nPKKl2g1JETdPaP/0OBi00hvUay06H87LSQjw0AiWjo0KFUBXEgKsPAjEJXyHsGTH+7zr72fykpe5iGLviuhi35e/mb6nTu7f83pNdpD5gqLXSF9DsAkMi8Xq+2bt2qkydP2j0KBigqw8BAFmPfB8+r9eRBDV/8oJxpmUodcZWG3HCnmire0oUDH0X8+ACQqJYvXy6n00lVEMOiMgxMHZUjV0b/nx7YcmK/fB9uVM61S5U+9ssHDeV+1avU0ZO+qAsa+/VarowUTRmVE/LMAJCohg0bpvnz51MVxLCovM9ASpJTd80u1q+2HOjXLYnTRk3U2Mde6fV9hzNJo7/5i34fN8kh3T27uNutiAEAffN6vfr+97+vU6dO8fC1GBS1q97aWcWWPqRIkgKS7pxVbO1BASAOrFixQg6HQy+99JLdo2AAojYMjMnL1JrrijSAiwoGxOmQ1lxXNODHFwNAIhs+fLhuuukmqoIYFbVhQJKeWDJNw7PTIh4InA5peHaanlg8LbIHAoA4ZhiG3nnnHZ0+fdruURCiqA4DOekpesbrjvijjAOm9IzXrZz0/m9aBAB0t3z5cknSyy+/bOscCF1UhwFJmjs5Xz9ZVhLRYzy5rERzJ+dH9BgAEO9GjBihG2+8kaogBkV9GJCkdXPGBQNBuCqDztd5clmJ7pkzLjwvCgAJzjAM/eUvf9GZM2fsHgUhiIkwIHUEgg33zgrLHoLOPQIb7p1FEACAMFqxYoVM06QqiDExEwakjsrgrYfnafW1RXI4Ou4LEAqHTDkc0upri/T2w/OoBgAgzEaOHKm5c+eqrKzM7lEQgpgKA5KUm56in66aqb8+epO+P29CtzsV9ny4UbLToc6bFfgvNOj8Bxu1MnmHfrpqJpsFASBCDMPQ22+/rXPnztk9CvrJYZp939qnvr5eLpdLPp9Pubm5VszVb23+gPaeaFBFrU8VtT6dbmxRS5tfaSlJys9O06Zf/7Nqdryn1tOHpIBfkrR+/Xr90z/9k72DA0CcOnHihAoKCvSb3/xG3/72t+0eJ6H1d/2O+TBwJYFAQJmZmWppaen1Z3/605+0cOFCG6YCgPg3b948ZWVl6fXXX7d7lITW3/U75mqCUBw/fjwYBByOjgph3Lhxevzxx3XDDTfYORoAxDXDMPTWW2+prq7O7lHQD3EdBpqbmyV1BIDOm2G89dZbeuqpp5SdnW3jZAAQ31auXKn29na98krvh8gh+sR1GJg0aZLOnTungwcP6j//8z+VkZHBDlcAsEBBQYFuuOEGbkAUI+I6DEhSXl6eHA6HsrKytGTJEv5iAoBFDMPQn//8Z50/f97uUdCHuA8DXRmGoU8++UQHDx60exQAiHurVq1SW1ubNm/ebPco6ENChYElS5YoIyODswMAYIHCwkKqghiRUGGAqgAArOX1evXmm2/K5/PZPQquIKHCgERVAABW8nq9am1t1auvvmr3KLiChAsDVAUAYJ0xY8Zozpw5vOdGuYQLA1QFAGAtr9erN954Q/X19XaPgstIuDAgURUAgJW8Xq9aWlr0hz/8we5RcBkJGQaoCgDAOsXFxZo9ezbvuVEsIcMAVQEAWMswDP3xj39UQ0OD3aPgEhIyDEjS6tWrqQoAwCKrVq1SS0uLXnvtNbtHwSUkbBhYvHgxVQEAWGTcuHH6yle+wntulErYMEBVAADWMgxDr7/+uhobG+0eBT0kbBiQqAoAwEper1cXL17U66+/bvco6CGhwwBVAQBY56qrrtK1117Le24USugwQFUAANYyDEOvvfaampqa7B4FXSR0GJCoCgDASl6vVxcuXKAqiDIJHwaoCgDAOhMmTNDVV1+tsrIyu0dBFwkfBqgKAMBahmHoD3/4g5qbm+0eBV9I+DAgURUAgJW8Xq+am5v1xz/+0e5R8AXCgKgKAMBKkyZNktvtpiqIIoQBURUAgNUMw9Crr76qCxcu2D0KRBgIoioAAOsYhqGmpib96U9/snsUiDAQRFUAANaZPHmyZs6cSVUQJQgDX8jKytLSpUu1ceNGu0cBgITg9Xr16quv6uLFi3aPkvAIA10YhqFPP/2UqgAALGAYhhoaGvTGG2/YPUrCIwx0QVUAANaZOnWqZsyYwXtuFCAMdEFVAADW8nq92rx5s1paWuweJaERBnqgKgAA63RWBW+++abdoyQ0wkAPVAUAYJ3p06dr+vTpvOfajDDQA1UBAFjLMAyqApsRBi6BqgAArOP1euXz+fTWW2/ZPUrCIgxcAlUBAFinpKREU6dO5T3XRoSBS6AqAADrOBwOGYahV155Ra2trXaPk5AIA5dBVQAA1vF6vTp//rzefvttu0dJSISBy6AqAADrlJaWavLkybzn2oQwcBlUBQBgnc6q4OWXX1ZbW5vd4yQcwsAVUBUAgHUMw1BdXZ3+8pe/2D1KwiEMXAFVAQBYZ+bMmZo4cSLvuTYgDFwBVQEAWKezKnjppZeoCixGGOhDZ1Vw4MABu0cBgLhnGIbOnTund955x+5REgphoA+LFy9WZmYmp60AwAIej0fjx49XWVmZ3aMkFMJAH7KysrRkyRLCAABYoGtV0N7ebvc4CYMw0A9UBQBgHcMwdObMGb377rt2j5IwCAP9QFUAANa55pprdNVVV1EVWIgw0A9UBQBgHYfDIa/XqxdffJGqwCKEgX6iKgAA6xiGodOnT2vr1q12j5IQCAP9RFUAANa57rrrNHbsWKoCixAG+omqAACs07Uq8Pv9do8T9wgDIaAqAADrGIahkydP6q9//avdo8Q9wkAIqAoAwDqzZs1ScXEx77kWIAyEgKoAAKxDVWAdwkCIqAoAwDper1cnTpzQ+++/b/cocY0wECKqAgCwzuzZszVmzBjecyOMMBAiqgIAsI7T6ZTX69ULL7ygQCBg9zhxizAwAKtXr6YqAACLeL1eHT9+XB988IHdo8QtwsAAUBUAgHXmzJmjwsJC3nMjiDAwAJmZmVQFAGARp9OpVatWqaysjKogQggDA0RVAADWMQxDx44d03/913/ZPUpcIgwMEFUBAFjn+uuv1+jRo3nPjRDCwABRFQCAdagKIoswMAhUBQBgHcMwdPToUW3fvt3uUeIOYWAQqAoAwDo33HCDRo4cyXtuBBAGBoGqAACsk5SUFKwKTNO0e5y4QhgYJKoCALCOYRiqqamhKggzwsAgURUAgHW+/vWva8SIESorK7N7lLhCGBgkqgIAsE5SUpJWrlypTZs2URWEEWEgDKgKAMA6hmHo8OHD+vjjj+0eJW4QBsKAqgAArDN37lzl5+dTFYQRYSAMqAoAwDrJyclasWIFVUEYEQbChKoAAKxjGIY+//xzffrpp3aPEhcIA2FCVQAA1rnxxhs1bNgw3nPDhDAQJpmZmVq6dKk2btxo9ygAEPc6qwJuQBQehIEwMgxDn332GVUBAFjAMAwdOHBAO3bssHuUmEcYCCOqAgCwzk033aShQ4fynhsGhIEwoioAAOukpKRwVUGYEAbCjKoAAKzj9Xq1f/9+7dy50+5RYhphIMyoCgDAOvPnz1deXh7vuYNEGAgzqgIAsE5KSoqWL19OVTBIhIEIoCoAAOt4vV5VV1ersrLS7lFiFmEgAqgKAMA6CxYs0JAhQ3jPHQTCQARQFQCAdVJTU3X77bdTFQwCYSBCqAoAwDqGYWjPnj3avXu33aPEJMJAhFAVAIB1FixYoNzcXN5zB4gwECFUBQBgnbS0tGBVgNARBiKIqgAArGMYhnbv3k1VMACEgQiiKgAA69x8883KyclRWVmZ3aPEHMJABFEVAIB10tPTtWzZMj6ADQBhIMI6q4L9+/fbPQoAxD3DMFRZWak9e/bYPUpMIQxEGFUBAFhn4cKFys7OpioIEWEgwjqrAsIAAEReenq6brvtNt5zQ0QYsABVAQBYxzAM7dy5U9XV1XaPEjMIAxagKgAA69x6663KysqiKggBYcACVAUAYJ2MjAzec0NEGLAIVQEAWMcwDO3YsYP33H4iDFiEqgAArLNo0SLec0NAGLAIVQEAWCczM1NLlixh30A/EQYsRFUAANYxDEOffvqpDh48aPcoUY8wYCGqAgCwzuLFi5WRkcF7bj8QBixEVQAA1snKyqIq6CfCgMWoCgDAOl6vVx9//LE+//xzu0eJaoQBi1EVAIB1lixZovT0dM4O9IEwYDGqAgCwTnZ2thYvXsx7bh8IAzZYvXo1VQEAWMTr9eqjjz7S4cOH7R4lahEGbMDNMADAOkuXLlVaWhpVwRUQBmxAVQAA1snJydGiRYt4z70CwoBNqAoAwDqGYWjbtm2qqamxe5SoRBiwCVUBAFinsyp44YUX7B4lKhEGbEJVAADWyc3N1cKFC3nPvQzCgI2oCgDAOoZh6MMPP9TRo0ftHiXqEAZsRFUAANa57bbblJqaSlVwCYQBG1EVAIB1XC6XbrnlFt5zL4EwYDOqAgCwjmEYev/991VbW2v3KFGFMGAzqgIAsM6yZcuUkpKiF1980e5RogphwGZUBQBgnSFDhujmm2/mPbcHwkAUoCoAAOsYhqH33ntPx48ft3uUqEEYiAJUBQBgndtvv11JSUlUBV0QBqIAVQEAWCcvL08LFizgPbcLwkCUoCoAAOsYhqGtW7fqxIkTdo8SFQgDUYKqAACss3z5cqqCLggDUaKzKti4caPdowBA3Bs6dKjmz5+vsrIyu0eJCoSBKLJ69Wrt2LGDqgAALOD1erVlyxadOnXK7lFsRxiIIlQFAGCd5cuXy+FwUBWIMBBVqAoAwDrDhw/XN77xDaoCEQaiDlUBAFjH6/XqnXfe0enTp+0exVaEgShDVQAA1lmxYoUcDodeeuklu0exFWEgylAVAIB18vPzdeONNyb8BzDCQBSiKgAA63RWBWfOnLF7FNsQBqIQVQEAWGflypUyTVMvv/yy3aPYhjAQhTIzM3XbbbdRFQCABUaMGKF58+Yl9AcwwkCUMgyDqgAALGIYht5++22dPXvW7lFsQRiIUlQFAGCdFStWKBAI6JVXXrF7FFsQBqIUVQEAWGfUqFGaO3duwn4AIwxEsc6qYN++fXaPAgBxzzAMvfXWWzp37pzdo1iOMBDFqAoAwDorV66U3+/X5s2b7R7FcoSBKNZZFRAGACDyRo8era997WsJ+Z5LGIhyVAUAYB3DMPTnP/9Z58+ft3sUSxEGohxVAQBYZ9WqVWpra0u4qoAwEOWoCgDAOgUFBbrhhhsS7j2XMBADqAoAwDqGYejNN9+Uz+ezexTLEAZiAFUBAFhn1apVam1t1auvvmr3KJYhDMQAqgIAsM6YMWM0Z86chHrPJQzECKoCALCOYRh64403VF9fL0ny+/02TxRZhIEYQVUAANbxer1qaWnR3/3d32n27NlKS0tTZWWl3WNFDGEgRlAVAEDktba26he/+IVWrlwpSXr22We1fft2+f1+JScn2zxd5BAGYghVAQBE1gcffKCHH35YH3/8cbfvO51OjR8/3qapIo8wEEOoCgAgsubNm6dHH3201/cLCgqUmppqw0TWiN9zHnGoa1Xw+OOP2z0OAMQdh8Ohn/3sZ5Kkn//85x3fdCZp3DVz9fvtNaqs9elUQ4ta2/1KTU7SiJw0zSh0qbTQpamjcpSSFJufsR2maZp9/VB9fb1cLpd8Pp9yc3OtmAuX8cILL8jr9aq6ulqTJk2yexwAiEumaervHvtvem77EWVfvUhJGTmSpGSnQ+2BL5fNrl+7MlJ01+xirZ1VrDF5mbbM3VN/1+/YjDAJjKoAACKr/mKb/vcXK/TH5DlyzfEGg4CkbkGg59e+C2361ZYD+vrP39GPXtiphottls08WISBGMNVBQAQOVurT2v+P2/Rxk+OyJQkR2jLZMCUTFPa+MkRzf+XLdpafToic4YbYSAGcVUBAITff3xwSOt+u11nm1oU6LNAv7KAKZ1pbNG6327Xhg8PhWW+SCIMxCCqAgAIrw0fHtKPX90lSYMOAp06X2f95l1RHwgIAzGIqgAAwmdr9Wmt37wrosdYv3lXVFcGhIEYRVUAAINXf7FNP9xULqcjssdxOqRHysqjdlMhYSBGURUAwOA9/VpVWPYI9KVzD8FTr1dF9kADRBiIUVQFADA4R+qa9fzHRyIeBDoFTOn5j4/oaF2zNQcMAWEghlEVAMDAPbe9Ro4I1wM9Ob84brQhDMSwRYsWKSsri7MDABCiNn9Av9tW0++zAhcP79Thny5V894Pev1Z0653dfinS9VS23cF4DelZ7fVqM0fCHXkiCIMxLDMzEwtXbqUMAAAIdpzokG+C/3fzJdWXKqk3Hw17X6315817X5XyUNGK61wWr9ey3ehTXtPNPT72FYgDMQ4qgIACF1FrS+kn3c4HMoquVHN+z9S4GJT8Pv+Zp8ufP6ZskpujOjxI40wEOOoCgAgdJW1PiWHeD1h9oxvSP42Ne19P/i9pqqtUsCvrBk39ft1kp0OwgDCi6oAAPpWXV2turq64NenGlp6PXSoLynDipQ6epKadr0b/F7TrneVWjBFKXkF/X6d9oCp040tIR070ggDcYCqAAAuLxAIqLS0VMOGDdNXv/pVPfXUUzpzrq7vX7yErBnfUMuRSrXXn1Fb3XG1Htur7JL+nxXo1NLmH9DxI4UwEAeoCgDg8pxOp0aMGCHTNLVt2zb9+Mc/1gfvbZVphn6DgaxpcyWHU01VWzrOEDiTlTnt6yG/TlpKUsi/E0mEgTjQWRVs3LjR7lEAIKqcP39eW7Zs0ZAhQ4Lf8/v98jfWSYHQP50nZbqUMf5aNVW+o6bd7ypj/DVKynSF9BrJTofys9NCPnYkJds9AMLDMAx5vV7t27dPkyZNsnscALCUaZo6fPiwduzY0e1fhw8fliQlJXX/JN568oAczlsHdKysGd/QmZf/T0nSkK/fHfLvtwdMlRaGFiAijTAQJ7pWBY8//rjd4wBAxLS0tGjXrl0qLy8PLvrl5eXy+Tp26A8fPlwej0eGYcjj8cjj8Wjv3r1atWpV8DUWzS7R9gHefjBz0iw507NlmqYyJ80e0GsQBhARXasCwgCAeHH27NngYt+58FdVVam9vV0Oh0OTJk2Sx+PRwoULgwv/6NGj5eix0GdnZ0uS0tPT9etf/1p33nW3rnvqrZBuPBTkcErOJGVOnCVHcmrIv+7KSNGUUTmhHzeCCANxhKoAQKwKBAI6ePBgt0/6O3bs0NGjRyVJGRkZmjlzpq6//nrdf//9crvdKi0tDS7yfSkuLta//uu/at68eZo+fbok6a7ZxfrVlgMhP6ioufpDBZp9HfcdCFGSQ7p7drFSkqJryx5hII5QFQCIBRcuXFBlZWW3bn/nzp1qbGyUJI0aNUoej0d33323PB6P3G63Jk2a1Kv3D4XD4dDf/u3fdvve2lnF+uW7B/r9Gi3H9qr11OfyffC8UkdOUHpxachzBCTdOas45N+LNMJAHKEqABBtTp482e0U/44dO7R3714FAgE5nU5NnTpVbrdbt99+e3DhHzlypCWzjcnL1JrrirTxk/49xrjh09fVtOsdpY4cr2FL/j7k4zkd0urrijQmLzP0YSPMYfbjQsv6+nq5XC75fD7l5uZaMRcG6IUXXpDX61V1dTVVAQDL+P1+7du3r9fCf+LECUkdnb3b7Zbb7Q52+zNmzFBGRoatczdcbNP8f9miM40tIdcFoXA6pOHZaXr74XnKSU+J3IF66O/6zZmBOENVACDSGhsbVVFR0a3b37lzpy5cuCBJGjNmjDwej+67777g4j9+/Hg5ndHVk0tSTnqKnvG6te632yN6nIApPeN1WxoEQsGZgTh0xx13aM+ePdqxY4fdowCIYaZp6vjx47029e3bt0+maSo5OVnTpk0LftLvPM0/bNgwu0cP2YYPD2n95l0Re/0nl5XonjnjIvb6l8OZgQTGVQUAQtXe3q69e/d2O8VfXl6u06dPS5JcLpfcbrduvfVW/ehHP5LH49H06dOVlhZdd9IbqHVfLNTrN++S06GwVAadr2NXEAgFYSAOURUAuJL6+nrt3Lmz28JfWVmplpaOJ+mNGzdOHo9H999/f/AT/9ixY3tdux9v1s0Zp3HDsvRIWfmg9xB07hF4xuvW3Mn54RsyQqgJ4hRVAQDTNHXkyJFem/oOHjwoSUpNTVVJSUm3U/xut7vbffwTUf3FNj39WpWe/+SInJL8IYSCJEfH5YNrri3SE0um2b5HoL/rN2EgTnFVAZBYWltbVVVV1etufXV1HY/qHTp0aK9uf+rUqUpNDf0OeoniaF2zntteo2e31QTvVJjsdKi9yymDrl+7MlJ09+xi3TmrOGouHyQMJLjm5maNGDFCjz/+OFUBEGfq6up63Zd/165damvrWLAmTJjQbeH3eDwqLCyM+9P8kdLmD2jviQZV1PpUUevT6cYWtbT5lZaSpPzsNJUWulRa6NKUUTlRd2dBwgCoCoAYZ5qmDh061OtJfDU1NZI67rNfWlra7dr90tJS3qcRxNUECF5VUF1drcmTJ9s9DoAruHjxonbv3t1rN399fb0kKT8/X1dffbXWrFkTXPgnT56s5GTexjF4/C2KY12vKnjiiSfsHgfAF86cOXPJJ/H5/X45HA5NnjxZHo9HixcvDn7qHzVqFKf5ETHUBHGOqgCwTyAQ0IEDB3rdtKe2tlZSx/NEZs6c2a3bnzFjhrKysmyeHPGCmgCSqAoAqzQ3N3d7El95ebnKy8vV1NQkSSooKJDb7da6deuCC/+ECRMG9SQ+IFwIA3GOqgAIvxMnTvS6dr+6ulqBQEBJSUmaOnWqPB6Pli9fHryMb8SIEXaPDVwWNUECoCoABsbv96u6urrXwn/y5ElJUk5OTred/G63WyUlJbY/iQ/oRE2AoNWrV2vVqlVUBcAVNDY2aufOnd0W/oqKiuCT+IqKiuTxePTd7343uPBfddVVUfkkPiBUhIEEQFUAfMk0TR07dqzXpr79+/cHn8RXUlIit9utO+64I7jwDx061O7RgYihJkgQVAVIRG1tbZd8Et+ZM2ckSUOGDOl2it/j8WjatGlx8yQ+gJoA3VAVIN75fL5LPomvtbVVknTVVVfJ4/HogQceCC78xcXFXLsPiDCQMKgKEC9M01RNTU2vTX2ff/65pI4n8c2YMUMej0ff+ta35PF4NHPmTLlcLpsnB6IXNUECoSpArGltbQ3eorfr4n/+/HlJ0rBhw3o9kGfKlClKSbH3sbFAtKAmQC9UBYhm586d6/Ukvt27dwefxDdp0iR5PB498sgjwYW/oKCA0/xAGBAGEghVAaJBIBDo9SS+8vLybk/imzlzpmbPnq3vfe97crvdKi0tVU5Ojs2TA/GLmiDBUBXAShcvXlRlZWWvT/wNDQ2SpJEjR/Y6zT9p0iRu0QuECTUBLomqAJFy+vTpXt3+nj175Pf75XQ6NWXKFLndbi1dujR4Kd+oUaPsHhuACAMJh6oAgxUIBLR///5eN+05duyYJCkrK0tut1vz5s3TD37wg+CT+DIzM22eHMDlUBMkIKoC9Fdzc7MqKiq69fsVFRXBJ/EVFhb2umnPhAkTuEUvECWoCXBZVAW4lBMnTnRb9DufxGeappKSkjRt2jR5PB55vV653W653W7l5+fbPTaAMCAMJCCqgsTW3t5+ySfxnTp1SpKUm5srt9utW265RY899pg8Ho+mT5+u9PR0mycHECnUBAmKqiAxNDQ0BG/R27n4V1RU6OLFi5KksWPHdnsEr8fj0bhx47h2H4gT1AS4IqqC+GKapmpra3tdu79//35JUkpKikpKSuTxeLR27dpgx5+Xl2fz5ACiAWEgQVEVxK62trbgWZ2uC//Zs2clSXl5efJ4PLrtttuCi/60adOUmppq8+QAohU1QQKjKoh+58+fV3l5ebd+f9euXcEn8Y0fP77XTXvGjBnDaX4AkqgJ0A9UBdHDNE0dPny41017Dh06JElKS0tTaWmprrnmGn37298OPomPcA4gHAgDCYyqwB4tLS3BJ/F1Xfx9Pp8kafjw4br66qtlGEZwc9+UKVOUnMw/rgAig5ogwVEVRNbZs2d7XcJXVVWl9vZ2ORyO4JP4ut60Z/To0ZzmBxAW1ATol86qYPeevfLnjFJFrU+VtT6damhRa7tfqclJGpGTphmFLpUWujR1VI5Skri7XE+BQEAHDx7stfAfPXpUkpSZmanS0lJdf/31uv/+++XxeFRaWqqsrCybJwcAzgwkvP3Hz+n6dY8p77rb1PJFNkx2OtQe+PKvRdevXRkpumt2sdbOKtaYvMS81/yFCxcu+SS+xsZGSdLo0aO7fdL3eDyaOHEiT+IDYLn+rt+EgQRVf7FNT79Wpec/PiLTDEiO/n/adzokU9Kaa4v0xJJpyklPidygNjt16lSvbn/Pnj0KBAJyOp2aOnVqt4Xf7XZr5MiRdo8NAJIIA7iCrdWn9cNN5Trb1KJAn//vX57TIQ3PTtMzXrfmTo7te9T7/f5uT+LrXPyPHz8uScrOzu624Hc+iS8jI8PmyQHg8ggDuKT/+OCQfvzqLjkdGlQQ6NT5Oj9ZVqJ1c8YN/gUt0NTUdMkn8TU3N0uSxowZ0+26fbfbrfHjx/MkPgAxhw2E6GXDhx1BQApPEOj6Ous3d7xuNAUC0zR1/PjxXtfu79u3T6ZpKjk5OfgkvtWrVwcX/mHDhtk9OgBYijMDCWJr9Wmt++32iB9nw72zbKkM2tvbtXfv3l79/unTpyVJLper16a+6dOnKy0tzfJZAcAq1AQIqr/Ypvn/vGXQewT60rmH4O2H50V0U2F9fX3wSXydC39FRYVaWlokSePGjet17f7YsWO5dh9AwqEmQNDTr1VFPAhIHZXBmcYWPfV6lX66cuagX880TR09erRbt79jxw4dPHhQkpSamhp8Et8999wTvEXvkCFDBn1sAEgkhIE4d6SuuePyQYuOFzCl5z8+ov/tpokh3YegtbVVVVVVvW7aU1dXJ0kaOnSoPB6Pli9fHvzUP3XqVKWkxO9ljQBgFcJAnHtue40cDqnvMih8nF8c99GFUy/553V1dZd8El9bW5skaeLEifJ4PHr44YeDC39hYSGn+QEgQggDcazNH9DvttVEvB7oyW9Kz26r0YPzJ6n2SE2vTX2HDx+WJKWnp6u0tFRf+cpXdN999wVP8+fk5Fg7MAAkOMJAHNtzokG+C239/vn28ydV+6u/ueyfj/3RH/r9Wr4LbRo15RrVHdwpSRoxYoQ8Ho/WrFkT3Ng3efJknsQHAFGAd+I4VlHrC+nnnZkuDVv6w+7fDLTr3Nu/kSMpxL8qpqml37xfa2eNlcfj0ahRo0L7fQCAZQgDcayy1tfroUNX4kxNV/aMm7p97+ybv5TZekEj7vg/Qjp2cpJTY0qv1623lob0ewAA63F/1Th2qqGl30HgUhor3lbjp68p76Z7lT42tEsF2wOmTje2DPjYAADrEAbiWGu7f+C/e/Kgzr3xr8qcPk+5s1YM6DVa2gZ+fACAdQgDcSw1OWlAv+e/2KjTLz2t5KEFGrbogQEfPy1lYMcHAFiLMBDHRuSkKdkZ2rX5phnQmc0/V+Bik/JXPiFnSvqAjp3sdCg/m/v+A0AsIAzEsRmFrpD3DPjee04XP/9Mw29/VClDBn4FQHvAVGmha8C/DwCwDlcTxLFQF+PWU4fke/9/Ka2oRP4mnxor3+n25z2vNAj38QEA9iAMxLGpo3Lkykjp942HAhfqJZlqOVKpliOVvf48lDDgykjRlFHcSRAAYgFhII6lJDl11+xi/WrLgX7dkjh97MyQ7jJ4OUkO6e7ZxUpJooUCgFjAu3WcWzur2NKHFElSQNKds4qtPSgAYMAIA3FuTF6m1lxXpBAvKhgwp0Nac11RSI8vBgDYizCQAJ5YMk3Ds9MiHgicDml4dpqeWDwtsgcCAIQVYSAB5KSn6BmvO+KPMg6Y0jNet3LSUyJ7IABAWBEGEsTcyfn6ybKSiB7jyWUlmjs5P6LHAACEH2EggaybMy4YCMJVGXS+zpPLSnTPnHHheVEAgKUIAwlm3Zxx2nDvrLDsIejcI7Dh3lkEAQCIYYSBBDR3cr7eenieVl9bJIej474AoUhySA6HtPraIr398DyqAQCIcQ7T7Psq9Pr6erlcLvl8PuXm5loxFyxytK5Zz22v0bPbaoJ3Kkx2Oro906Dr166MFN09u1h3zirm8kEAiHL9Xb8JA5AktfkD2nuiQRW1PlXU+nS6sUUtbX6lpSQpPztNpYUulRa6NGVUDncWBIAY0d/1m9sRQ1LHrYtnFLo0o9ClO+0eBgBgKT7iAQCQ4AgDAAAkOMIAAAAJjjAAAECCIwwAAJDgCAMAACQ4wgAAAAmOMAAAQIIjDAAAkOAIAwAAJDjCAAAACY4wAABAgiMMAACQ4Pr11MLOpxzX19dHdBgAABA+net25zp+Of0KAw0NDZKkoqKiQY4FAACs1tDQIJfLddk/d5h9xQVJgUBAx44dU05OjhwOR1gHBAAAkWGaphoaGlRQUCCn8/I7A/oVBgAAQPxiAyEAAAmOMAAAQIIjDAAAkOAIAwAAJDjCAAAACY4wAABAgiMMAACQ4P5/+mlNHfpK1icAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x, y, z, m = make_vars(\"xyzm\")\n",
    "g = Graph([\n",
    "    x <= z,\n",
    "    m <= x,\n",
    "    y <= [m, z],\n",
    "])\n",
    "g.draw()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the dataset, $x$ has the effect of raising the value of $y$ by $-0.5$ by virtue of the process which simulated the data. We can quickly recover this quantity using the graph above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EstimationResult(value=-0.4732071277264369)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pqp.estimation import MultinomialEstimator\n",
    "from pqp.identification import ATE\n",
    "\n",
    "df = pd.read_csv(\"demo1.csv\")\n",
    "model = MultinomialEstimator(df)\n",
    "effect = ATE(y, x)\n",
    "\n",
    "estimand = g.identify(effect)\n",
    "model.estimate(estimand)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, what if $z$ were unobserved, would we still be able to recover the result? We first attempt this without reference to our knowledge of the data generating process. This is equivalent to directly regressing $y$ on $x$ without any controls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EstimationResult(value=0.00768827677796402)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naive_graph = Graph([\n",
    "    y <= x\n",
    "])\n",
    "naive_estimand = naive_graph.identify(effect)\n",
    "model.estimate(naive_estimand)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It turns out that in this dataset, the effect of $z$ is to exactly cancel out the effect of $x$ on $y$. So, we won't be able to estimate the effect directly. In addition, there is no sufficient adjustment set to recover the effect of $x$ on $y$. However, we can use ID to identify the estimand. Since we are taking $z$ as unobserved, we represent $x$ and $y$ as confounded in this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle E_{y} \\big[\\sum_{m} \\big({\\sum_{x} \\big({P(m, y, x) P(x) \\over P(m, x)}\\big) P(m, x = 1) \\over P(x = 1)}\\big)\\big] - E_{y} \\big[\\sum_{m} \\big({\\sum_{x} \\big({P(m, y, x) P(x) \\over P(m, x)}\\big) P(m, x = 0) \\over P(x = 0)}\\big)\\big]$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "g = Graph([\n",
    "    m <= x,\n",
    "    y <= m,\n",
    "    x & y\n",
    "])\n",
    "effect = ATE(y, x)\n",
    "estimand = g.identify(effect)\n",
    "estimand.identified_estimand.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EstimationResult(value=-0.4747611636992284)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MultinomialEstimator(df)\n",
    "result = model.estimate(estimand)\n",
    "result"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have successfully recovered the true effect. We can now use the inspection features of `pqp` to show the process which led to this result. This conventiently lists all the assumptions made during the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Processing\n",
      "\tAssume: z is on {0, 1}\n",
      "\tAssume: x is on {0, 1}\n",
      "\tAssume: m is on {0, 1}\n",
      "\tAssume: y is on {1, 2, 3}\n",
      "Identification\n",
      "\tWe will identify the average treatment effect using IDC.\n",
      "\tAssume: Noncontradictory evidence\n",
      "\tAssume: Acyclicity\n",
      "\tAssume: Positivty\n",
      "\tIDC\n",
      "\t\tInput:\n",
      "\t\tP(y| do(x))\n",
      "\t\tOutput:\n",
      "\t\tΣ_(m) [ [Σ_(x) [ [P(m, y, x) * P(x) / P(m, x)] ] * P(m, x) / P(x)] ]\n",
      "\tDerived: identified_estimand = E_(y) [ Σ_(m) [ [Σ_(x) [ [P(m, y, x) * P(x) / P(m, x)] ] * P(m, x = 1) / P(x = 1)] ] ] - E_(y) [ Σ_(m) [ [Σ_(x) [ [P(m, y, x) * P(x) / P(m, x)] ] * P(m, x = 0) / P(x = 0)] ] ]\n",
      "Fit MultinomialEstimator\n",
      "\tAssume: Multinomial likelihood\n",
      "\tAssume: Dirichlet prior\n",
      "Estimation\n",
      "\tPerforming brute force estimation using a multinomial likelihood and dirichlet prior.\n",
      "\tDerived: value = -0.4747611636992284\n"
     ]
    }
   ],
   "source": [
    "result.explain_all()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Educational Materials\n",
    "\n",
    "I created a Medium article and two explainer videos to introduce the library to the causal inference community. The Medium article is available covered more of the theoretical background for SCM inference, while the videos are more practical and focus on how to use the library.\n",
    "\n",
    "- [Medium Article](https://medium.com/@leoware/causal-inference-a-four-stage-framework-7fc2f8deafe2)\n",
    "- [First Video](https://www.loom.com/share/91dc669b931d487a84c8030c80d2391c)\n",
    "- [Second Video](https://www.loom.com/share/7d8feab2b4f54a7caa59c495a9ce9858)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "Bhattacharya, R., Nabi, R., & Shpitser, I. (2021). Semiparametric Inference For Causal Effects In Graphical Models With Hidden Variables (arXiv:2003.12659). arXiv. http://arxiv.org/abs/2003.12659\n",
    "\n",
    "\n",
    "Breitling, L. P. (2010). dagR: A suite of R functions for directed acyclic graphs. Epidemiology (Cambridge, Mass.), 21(4), 586–587. https://doi.org/10.1097/EDE.0b013e3181e09112\n",
    "\n",
    "\n",
    "Brulé, J. (2018). Whittemore: An embedded domain specific language for causal programming (arXiv:1812.11918). arXiv. https://doi.org/10.48550/arXiv.1812.11918\n",
    "\n",
    "\n",
    "Efficiently Finding Conditional Instruments for Causal Inference. (n.d.). 7.\n",
    "Identification With Surrogates—Ananke-causal documentation. (n.d.). Retrieved October 3, 2022, from https://ananke.readthedocs.io/en/latest/notebooks/identification_surrogates.html\n",
    "\n",
    "\n",
    "Knüppel, S., & Stang, A. (2010). DAG program: Identifying minimal sufficient adjustment sets. Epidemiology (Cambridge, Mass.), 21(1), 159. https://doi.org/10.1097/EDE.0b013e3181c307ce\n",
    "\n",
    "\n",
    "Leslie Myint (Director). (2020, September 13). Estimating Causal Effects: Inverse Probability Weighting. https://www.youtube.com/watch?v=PfLYPt9ur4g\n",
    "\n",
    "\n",
    "Rice U ECE (Director). (2021, October 26). Prof. Ilya Shpitser | The Proximal ID Algorithm. https://www.youtube.com/watch?v=6nZslQafmYQ\n",
    "\n",
    "\n",
    "Sharma, A., & Kiciman, E. (2020). DoWhy: An End-to-End Library for Causal Inference (arXiv:2011.04216). arXiv. https://doi.org/10.48550/arXiv.2011.04216\n",
    "\n",
    "\n",
    "Shpitser, I. (2006). Identification of Joint Interventional Distributions in Recursive Semi-Markovian Causal Models. 8.\n",
    "\n",
    "\n",
    "Shpitser, I. (2008). Complete Identi cation Methods for Causal Inference. 114.\n",
    "\n",
    "\n",
    "Shpitser, I., & Pearl, J. (n.d.). Identiﬁcation of Conditional Interventional Distributions. 8.\n",
    "\n",
    "\n",
    "Shpitser, I., Richardson, T. S., & Robins, J. M. (2012). An Efficient Algorithm for Computing Interventional Distributions in Latent Variable Causal Models (arXiv:1202.3763). arXiv. https://doi.org/10.48550/arXiv.1202.3763\n",
    "\n",
    "\n",
    "Shpitser, I., & Sherman, E. (2018). Identification of Personalized Effects Associated With Causal Pathways. Uncertainty in Artificial Intelligence: Proceedings of the ... Conference. Conference on Uncertainty in Artificial Intelligence, 2018, 198.\n",
    "\n",
    "\n",
    "Shpitser, I., VanderWeele, T., & Robins, J. M. (2012). On the Validity of Covariate Adjustment for Estimating Causal Effects (arXiv:1203.3515). arXiv. https://doi.org/10.48550/arXiv.1203.3515\n",
    "\n",
    "\n",
    "Shpitser, I., Wood-Doughty, Z., & Tchetgen, E. J. T. (2021). The Proximal ID Algorithm (arXiv:2108.06818). arXiv. https://doi.org/10.48550/arXiv.2108.06818\n",
    "\n",
    "\n",
    "Textor, J., & Liskiewicz, M. (n.d.). Adjustment Criteria in Causal Diagrams: An Algorithmic Perspective. 8.\n",
    "\n",
    "\n",
    "Textor, J., van der Zander, B., Gilthorpe, M. S., Liśkiewicz, M., & Ellison, G. T. H. (2017). Robust causal inference using directed acyclic graphs: The R package ‘dagitty.’ International Journal of Epidemiology, dyw341. https://doi.org/10.1093/ije/dyw341\n",
    "\n",
    "\n",
    "Tian, J., & Pearl, J. (n.d.). A General Identiﬁcation Condition for Causal Effects. 7.\n",
    "\n",
    "\n",
    "Tikka, S., & Karvanen, J. (n.d.). Simplifying Probabilistic Expressions in Causal Inference. 30.\n",
    "Van der Zander, B., & Liskiewicz, M. (2016). Separators and Adjustment Sets in Markov Equivalent DAGs. Proceedings of the AAAI Conference on Artificial Intelligence, 30(1). https://doi.org/10.1609/aaai.v30i1.10424\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendices"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix 1: HC and LO Applications"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HC Applications"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "induction\n",
    "\n",
    "Structural causal modeling is all about principled approaches to induction, and the four-steps model of causal inference in Pearl's framework is a paradigm for inductive reasoning. I carefully explain how inference is conceptualized within this framework, and I draw connections between the framework and predictions that result on actual datasets. I show a deep understanding of the nuances of inductive reasoning."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "algorithms\n",
    "\n",
    "I explain the tradeoffs between a number of approaches to identification. I carefully explain how each alternative works, and I provide a high-level overview of Shpitser’s identification algorithm. I use asymptotic complexity to characterize tradeoffs. I implement Shpitser’s identification algorithm.\n",
    "\n",
    "In the Technical Challenges section, I explain three algorithmic subroutines I developed for this project: the heuristic simplification algorith, the memory-sharing graph data structure, and my approach to estimation. In each case, I review the literature to characterize existing approaches, and drawing from this synthesis, I develop a novel approach. For the memory sharing graph data structure, I provide a sophisticated argument about computational complexity constraints to justify my approach."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "variables\n",
    "\n",
    "I carefully handle distinctions between treatment, outcome, and control variables. I provide a subtle discussion of the relationships between treatment and outcome variables in the structural causal modeling framework. I explain how treatment variables in a causal estimand may be converted to control variables or excluded via identification.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "probability\n",
    "\n",
    "I show a deep understanding of probabilistic expressions and how they can be manipulated via the two rules of probability. I show how an extension to the basic logic of probability (do-expressions) can be incorporated into probabilistic reasoning. I draw on deep understanding of the logic of probability to criticise Brule's (2018) approach to estimation on the basis of its failure to guarantee positivity, and a I suggest a way to fix this problem using Bayesian statistics."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "deduction\n",
    "\n",
    "The do-calculus is a framework for using formal mathematics to reason about the very hairy and complex inductive problem of causal inference. I present the key intuitions behind the do-calculus, and then leverage an algorithm based on the do-calculus to perform identification. In addition, I make use of mathematical reasoning to prove a number of small supporting points."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "organization\n",
    "\n",
    "\n",
    "Structural causal modeling is a complex framework for reasoning about inductive reasoning. I break down this highly complex and interconnected topic into a series of short digestible insights, each of which I present in a subsection. I present the idea in an order which allows the reader to build an intuition for the field.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "professionalism\n",
    "\n",
    "I present a professional report using latex. The formatting and visual presentation of the report add to its credibility. I carefully follow citation standards."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "composition\n",
    "\n",
    "I explain a complex, technically rigorous topic in a way that is accessible to someone educated in mathematics or computer science. I carefully handle jargon—using it only when necessary and being careful to define my terms. I condense most of the information I have learned over the course of a year-long literature review into a few pages of background information. I balance concision with clarity in a highly difficult explanation."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "regression\n",
    "\n",
    "I explain how regression modeling (under the name estimation) fits into the framework of structural causal modeling. I show a deep understanding of the role of regression in larger causal inference through my explanation of the role of abstract statistical estimators. Misapplication of principles of causal reasoning are one of the top reasons for poor use of regression models, and I present a report detailing how to avoid many of these.\n",
    "\n",
    "I demonstrate powerful understanding of regression through my development of an estimation technique relying on Bayesian priors."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "correlation\n",
    "\n",
    "\n",
    "Rather than referring to correlation directly, I discuss the more general notion of statistical estimation. I explain how association in the joint distribution of a dataset relates to d-separation and live paths in the causal model. I explain how statistical association can change as a result of conditioning, and I present a complete account (based on Pearl’s work) of when this occurs.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sampling\n",
    "\n",
    "\n",
    "All of the difficulties of observational research fundamentally result from biased samples. In the final deliverable, I will explain how sampling bias in a real dataset can be controlled for using structural causal models."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "observationalstudy\n",
    "\n",
    "\n",
    "I implement a complex software library aimed to help researchers working with observational data. I show a deep understanding of the pitfalls of observational research through my explanation of confounding and collider bias. I explain how identification can be used to remove biases from estimation of causal effects. I present a tool whose primary purpose is to aid in conducting better observational studies."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "modeling\n",
    "\n",
    "\n",
    "I show a deeply researched and incredibly rigorous understanding of the structural causal modeling approach to causal inference. I explain how the “moving parts” of the model relate to changes in its predictions for the data. I implement a tool to aid in using structural causal modeling on real data.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "comparisongroups\n",
    "\n",
    "\n",
    "In observational research, proper control groups are rarely available. The marginalization and control operations called for in the abstract estimator returned from identification can be interpreted as reweighting and excluding existing data in a way that synthetically generates a proper control group from available data. I will develop this analogy further in the final deliverable.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LO Applications"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CS110-ComputationalCritique\n",
    "\n",
    "Throughout the technical challenges section, I weigh the relative merits of various approaches from the literature and present sophisticated technical arguments. I explain the tradeoffs between multiple approaches to estimation and explain why I chose this one. I demonstrate similar skill in discussion of simplification."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CS110-ComputationalSolutions\n",
    "\n",
    "I best demonstrate this skill in my development of the memory-sharing graph data structure. I characterize the problem as requiring the ability to efficiently handle sequential calls to perform ancestor lookups, c-component lookups, and modifications to the graph. Given this characterization, I develop a novel approach to the problem which is both efficient and elegant. I provide a sophisticated argument about computational complexity constraints to justify my approach."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CS110-DataStructures\n",
    "\n",
    "I best demonstrate this skill in my development of the memory-sharing graph data structure. I characterize the problem as requiring the ability to efficiently handle sequential calls to perform ancestor lookups, c-component lookups, and modifications to the graph. Given this characterization, I develop a novel approach to the problem which is both efficient and elegant. I provide a sophisticated argument about computational complexity constraints to justify my approach."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CS110-CodeRedability\n",
    "\n",
    "I present code at a very high level of readablility because of my aspiration to turn this project into an open-source library. I follow standards for commenting in both Python and Rust, and I generate documentation to aid use."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CS146-GraphicalModels\n",
    "\n",
    "Structural causal models are a form of graphical model. I show a high level of understanding in the Background section, where I condense the literature on these models. I discuss how specific aspects of the graphical model (flow, connectedness) relate to conditional independence properties of the graph. I explain how modifications to the model (surgery) correspond to causal reasoning. I give clear explanations of how complex structures such as c-components and hedges affect our ability to make causal inferences.\n",
    "\n",
    "I also demonstrate this skill in my approach to the estimation problem, where I discuss the problem of marginalization and various approaches to solving it."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CS146-ProbabilityTheory\n",
    "\n",
    "I present a software library designed for the symbolic manipulation of probability expressions and corresponding causal graphs. My literature review demonstrates deep understanding, and my simplification routine is a simple but powerful tool for programmatic symbolic manipulation of probability expressions."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CS146-QuantProfessionalism\n",
    "\n",
    "I do everything I can to make my work useful to others, and I follow best practices for quantitative academic work and open source code. I present my work using Latex. I follow citaion practices. My code is available on GitHub and as an open-source distribution via PyPi. My code is well documented, commented, readable, and intended for reuse.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CS154-NumImplementation\n",
    "\n",
    "I write performant, low-level code in a systems programming language to create a fast and correct interpretation of an algorithm. Although I will cover this more thoroughly in the final deliverable, I implement a marginalization and estimation algorithm for real data. Issues of converge are pressing."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#CS146-PythonImplementation\n",
    "\n",
    "I implement a number of inference procedures and subprocedures in Python. I build with the user in mind, creating elegant interfaces to the underlying algorithms. Coming soon: I leverage my code to perform inference on simulated data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Capstone LO Applications"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "qualitydeliverables\n",
    "\n",
    "I present a concise but informative literature review, a strong characterization of the problem, a professional and appealing documentation website, a production-quality piece of software and a number of algorithmic insights."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "curation\n",
    "\n",
    "For each section, I write in a concise but not terse manner, effectively characterizing each problem, summmarizing current work in the area, and presenting my own solution along with justification. I carefully select elements from my library to demo, focusing on aspects which are most likely to engage the reader and help them understand my work."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "navigation\n",
    "\n",
    "I am well on track to complete my capstone on time. I have completed my original goal (published implementation of ID, handling of conditional effects, python bindings, extensive testing, documentation), and I have extensive work towards a number of stretch goals (estimation, medium articles, ATE and CATE routines, randomized testing and benchmarking). I am on track to finish at least a couple of these if nothing goes terribly. I present a prioritization of the next steps along with a time estimate for each."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "outcomeanalysis\n",
    "\n",
    "My two top goals for the implementation were correctness and performance, and my top goal for the python wrapper was usability. I have characterized the correctness by using hand-derived examples from the literature. I have done some work to characterize performance using computational complexity, and I am working towards performance benchmarks. I hope to better understand the usability of my interface by interacting with it in the next few weeks."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix 2: Code"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code Relating to Examples in the Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>z</th>\n",
       "      <th>x</th>\n",
       "      <th>m</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   z  x  m  y\n",
       "0  0  0  0  2\n",
       "1  1  1  0  3\n",
       "2  0  1  1  1\n",
       "3  0  0  0  2\n",
       "4  0  1  1  1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(123)\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df[\"z\"] = np.random.choice([0, 1], size=1000)\n",
    "df[\"x\"] = (0.5*df.z + np.random.random(size=1000) > 0.75).astype(int)\n",
    "df[\"m\"] = (0.5*df.x + np.random.random(size=1000) > 0.75).astype(int)\n",
    "df[\"y\"] = df.z - df.m + 2\n",
    "\n",
    "df.to_csv(\"demo1.csv\", index=False)\n",
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bbbf304047aac1d8dfa956a63cc2cea0a93c42bcd915750832b2326b8115e97d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
